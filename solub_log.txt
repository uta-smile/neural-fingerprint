Loading data...
Task params {'target_name': 'solub', 'data_file': 'data/solub.csv'}

Starting Morgan fingerprint experiment...
Starting neural fingerprint experiment...
Total number of weights in the network: 103221
max of weights 0.08886963478129936
Iteration 0 loss 1.0050140379109862 train RMSE 0.4624106732611795 Validation RMSE 0 : 0.4572495185717664 max of weights 0.09288111753657344
Iteration 10 loss 0.9999262539802559 train RMSE 0.46007068755443026 Validation RMSE 10 : 0.4555121001952427 max of weights 0.10587771029592989
Iteration 20 loss 1.006227413077896 train RMSE 0.4629588412245067 Validation RMSE 20 : 0.45698981718253073 max of weights 0.12397269552322644
Iteration 30 loss 0.985839376588924 train RMSE 0.45354078079807914 Validation RMSE 30 : 0.4507431765164757 max of weights 0.15096592405220463
Iteration 40 loss 0.951020698762781 train RMSE 0.43744070567875815 Validation RMSE 40 : 0.44055991271145684 max of weights 0.17506134539167753
Iteration 50 loss 0.9151825129458048 train RMSE 0.42085595722006314 Validation RMSE 50 : 0.43366753683427334 max of weights 0.1833869188178759
Iteration 60 loss 0.8845121475397257 train RMSE 0.40673755401007133 Validation RMSE 60 : 0.42756198312007426 max of weights 0.19225210726347783
Iteration 70 loss 0.8786572582093443 train RMSE 0.40405138999263573 Validation RMSE 70 : 0.42587581044672373 max of weights 0.20809186670966448
Iteration 80 loss 0.8962743240032245 train RMSE 0.41215589753576654 Validation RMSE 80 : 0.4274011182643382 max of weights 0.2137831516088106
Iteration 90 loss 0.877940633488765 train RMSE 0.4037250944759019 Validation RMSE 90 : 0.42383852703552893 max of weights 0.22781153858204378
Iteration 100 loss 0.8600313115045672 train RMSE 0.3954205668339533 Validation RMSE 100 : 0.42492302719196706 max of weights 0.22331726249618328
Iteration 110 loss 0.8732166119113787 train RMSE 0.4014851854210314 Validation RMSE 110 : 0.42142257565992 max of weights 0.2219536647981825
Iteration 120 loss 0.8805230238333337 train RMSE 0.4048869309432839 Validation RMSE 120 : 0.4169968710199891 max of weights 0.22266947290996306
Iteration 130 loss 0.8745231161941582 train RMSE 0.4021051286152092 Validation RMSE 130 : 0.4178055868110922 max of weights 0.2367170350448441
Iteration 140 loss 0.8638927802507772 train RMSE 0.39720175459878204 Validation RMSE 140 : 0.415210054948376 max of weights 0.24482323254316482
Iteration 150 loss 0.869562938219308 train RMSE 0.3998155871719636 Validation RMSE 150 : 0.4152766886444849 max of weights 0.26095048295116496
Iteration 160 loss 0.8476490016280663 train RMSE 0.3897136675605473 Validation RMSE 160 : 0.4154127641896932 max of weights 0.2701981044652762
Iteration 170 loss 0.8452083031222789 train RMSE 0.3885812559890232 Validation RMSE 170 : 0.4164055291742758 max of weights 0.2742279686131461
Iteration 180 loss 0.8492609587444283 train RMSE 0.39044820908445355 Validation RMSE 180 : 0.41635478146591154 max of weights 0.27308743960773946
Iteration 190 loss 0.869773542447899 train RMSE 0.3998795339858047 Validation RMSE 190 : 0.4177760057718765 max of weights 0.27494843199203933
Iteration 200 loss 0.8751269759006742 train RMSE 0.40236243303540414 Validation RMSE 200 : 0.4149159101669881 max of weights 0.2896255570305344
Iteration 210 loss 0.8587991683835868 train RMSE 0.3948279104735833 Validation RMSE 210 : 0.4120122705799967 max of weights 0.3113610509390995
Iteration 220 loss 0.8341373433572109 train RMSE 0.38344867667165705 Validation RMSE 220 : 0.41129859410117314 max of weights 0.31203502911603764
Iteration 230 loss 0.8464924491251195 train RMSE 0.38912584994642446 Validation RMSE 230 : 0.41338897417285075 max of weights 0.3075399896323078
Iteration 240 loss 0.8545783484103562 train RMSE 0.39283894881560505 Validation RMSE 240 : 0.41116514059789727 max of weights 0.31793976867821255
Iteration 250 loss 0.8697398715677979 train RMSE 0.399816898889612 Validation RMSE 250 : 0.4092336858128287 max of weights 0.3324958151467805
Iteration 260 loss 0.8711444547350753 train RMSE 0.40047234727965797 Validation RMSE 260 : 0.41278558878746313 max of weights 0.34140199713630537
Iteration 270 loss 0.8499749889726173 train RMSE 0.39071620483284464 Validation RMSE 270 : 0.4076905711621851 max of weights 0.3510033197520349
Iteration 280 loss 0.849432215874277 train RMSE 0.3904609742612823 Validation RMSE 280 : 0.4089486177737328 max of weights 0.3451268318000707
Iteration 290 loss 0.8541079616840432 train RMSE 0.3926041395333039 Validation RMSE 290 : 0.40875341412355265 max of weights 0.34423241218399425
Iteration 300 loss 0.8586238629878628 train RMSE 0.39467371213386543 Validation RMSE 300 : 0.41536072688330505 max of weights 0.3537081476129099
Iteration 310 loss 0.8578640906593131 train RMSE 0.39432377330263446 Validation RMSE 310 : 0.40757474361219004 max of weights 0.3621532187837562
Iteration 320 loss 0.8617167039095226 train RMSE 0.3961001867130306 Validation RMSE 320 : 0.4062883631896067 max of weights 0.37256196651371565
Iteration 330 loss 0.8589224979828727 train RMSE 0.3948030367328766 Validation RMSE 330 : 0.4060896131685883 max of weights 0.3794064942484155
Iteration 340 loss 0.8636898432504888 train RMSE 0.3969699498027637 Validation RMSE 340 : 0.4023851125308766 max of weights 0.3872341358488181
Iteration 350 loss 0.8784349685922875 train RMSE 0.40373244724897306 Validation RMSE 350 : 0.40633459049191195 max of weights 0.3902857806052266
Iteration 360 loss 0.8771335820531941 train RMSE 0.40314452641299775 Validation RMSE 360 : 0.4037586079903596 max of weights 0.4063740049728975
Iteration 370 loss 0.8951184514507934 train RMSE 0.4114228285655986 Validation RMSE 370 : 0.40676030264965507 max of weights 0.4198494979753718
Iteration 380 loss 0.8885716112517269 train RMSE 0.4083985294997604 Validation RMSE 380 : 0.4066568603715661 max of weights 0.4274461951451493
Iteration 390 loss 0.8723706382918959 train RMSE 0.40093112864377994 Validation RMSE 390 : 0.40662484154136325 max of weights 0.44018970261534685
Iteration 400 loss 0.8509288809318791 train RMSE 0.39105691188478325 Validation RMSE 400 : 0.401669507887898 max of weights 0.44354340165607675
Iteration 410 loss 0.8273834926300007 train RMSE 0.38021411000029814 Validation RMSE 410 : 0.40299753047388526 max of weights 0.44293176967468817
Iteration 420 loss 0.8422821493241439 train RMSE 0.3870568575429909 Validation RMSE 420 : 0.4022251093097072 max of weights 0.4465944783659819
Iteration 430 loss 0.9094386215931497 train RMSE 0.41794073427551065 Validation RMSE 430 : 0.4189486340183844 max of weights 0.45278464177701466
Iteration 440 loss 0.8882428345842632 train RMSE 0.40818797422887987 Validation RMSE 440 : 0.4058061617680087 max of weights 0.45941317411004784
Iteration 450 loss 0.8641419135224807 train RMSE 0.39709759347686996 Validation RMSE 450 : 0.4025955627279448 max of weights 0.4654737849934442
Iteration 460 loss 0.8546312065597464 train RMSE 0.39270251461064926 Validation RMSE 460 : 0.40180745814279745 max of weights 0.4719813482616401
Iteration 470 loss 0.8451003229340615 train RMSE 0.3883125565597849 Validation RMSE 470 : 0.40238643571034743 max of weights 0.47076596980770463
Iteration 480 loss 0.8519835015148648 train RMSE 0.3914804594816147 Validation RMSE 480 : 0.4000842290963706 max of weights 0.47113864038272885
Iteration 490 loss 0.8604295299527285 train RMSE 0.39535146898174717 Validation RMSE 490 : 0.4046095793048233 max of weights 0.4754341507431381
Iteration 500 loss 0.8498946018235867 train RMSE 0.39050615068511574 Validation RMSE 500 : 0.3996155927194205 max of weights 0.4790903971907324
Iteration 510 loss 0.8762658188657555 train RMSE 0.4026287192851401 Validation RMSE 510 : 0.40083442368546335 max of weights 0.5010533893498835
Iteration 520 loss 0.8941299536499937 train RMSE 0.41083921160800596 Validation RMSE 520 : 0.3995900090031683 max of weights 0.5061066874577483
Iteration 530 loss 0.8775909001730268 train RMSE 0.4032164948109601 Validation RMSE 530 : 0.39602812481712124 max of weights 0.507112143135305
Iteration 540 loss 0.8666273134071145 train RMSE 0.3981565247748846 Validation RMSE 540 : 0.39346051850576574 max of weights 0.5118056894488482
Iteration 550 loss 0.8894851387974442 train RMSE 0.4086747613575294 Validation RMSE 550 : 0.39745375575325803 max of weights 0.5199988272241333
Iteration 560 loss 0.8947720489949175 train RMSE 0.4110980946435877 Validation RMSE 560 : 0.3959193407287446 max of weights 0.5356799163009558
Iteration 570 loss 0.8895879354683383 train RMSE 0.40872533190453075 Validation RMSE 570 : 0.3935832233835234 max of weights 0.5490961476684497
Iteration 580 loss 0.8942063844814904 train RMSE 0.4108457331859459 Validation RMSE 580 : 0.39516124836872785 max of weights 0.5472906803166245
Iteration 590 loss 0.8848450175906097 train RMSE 0.4065259211009661 Validation RMSE 590 : 0.39400095602137714 max of weights 0.5449069052797374
Iteration 600 loss 0.8939706419942408 train RMSE 0.41071223540493823 Validation RMSE 600 : 0.3993109468510537 max of weights 0.5426409705933545
Iteration 610 loss 0.8875642143108311 train RMSE 0.4077787310775164 Validation RMSE 610 : 0.39621644010335144 max of weights 0.5457531444841812
Iteration 620 loss 0.9041464943244383 train RMSE 0.4154164780711613 Validation RMSE 620 : 0.404036960588261 max of weights 0.5555928816651384
Iteration 630 loss 0.8919561606851221 train RMSE 0.40981999345991 Validation RMSE 630 : 0.3951353683607428 max of weights 0.5626488797427321
Iteration 640 loss 0.8979616814623806 train RMSE 0.4125652660407469 Validation RMSE 640 : 0.3962849281623264 max of weights 0.5740509678649449
Iteration 650 loss 0.8977046255459241 train RMSE 0.41244842098751344 Validation RMSE 650 : 0.39554809163596266 max of weights 0.597551852135947
Iteration 660 loss 0.8761216441566386 train RMSE 0.4025119988261435 Validation RMSE 660 : 0.3900971737747456 max of weights 0.6249323317219012
Iteration 670 loss 0.8682664482849781 train RMSE 0.39889643497988636 Validation RMSE 670 : 0.395587259829584 max of weights 0.6357177781918562
Iteration 680 loss 0.854312321991752 train RMSE 0.3924653111305056 Validation RMSE 680 : 0.39028177614452814 max of weights 0.6167373191549799
Iteration 690 loss 0.8734507896411834 train RMSE 0.4012539080101457 Validation RMSE 690 : 0.3919982271855894 max of weights 0.6097237707943006
Iteration 700 loss 0.8953372635297222 train RMSE 0.41131752615585 Validation RMSE 700 : 0.39980968878931683 max of weights 0.6050444723393853
Iteration 710 loss 0.8936253371854104 train RMSE 0.41050517833387823 Validation RMSE 710 : 0.3982837685216828 max of weights 0.6074775439439003
Iteration 720 loss 0.8999372478316572 train RMSE 0.41341037773955386 Validation RMSE 720 : 0.392405058743735 max of weights 0.5990499542087244
Iteration 730 loss 0.900356942935953 train RMSE 0.41360834798915536 Validation RMSE 730 : 0.39599451647643724 max of weights 0.597644622443606
Iteration 740 loss 0.8514944161328593 train RMSE 0.3911286255677537 Validation RMSE 740 : 0.3893273987008901 max of weights 0.605610473000516
Iteration 750 loss 0.8356717088172042 train RMSE 0.38384122390908826 Validation RMSE 750 : 0.3881190722990004 max of weights 0.6161395587501849
Iteration 760 loss 0.8363405349468841 train RMSE 0.38415030138458856 Validation RMSE 760 : 0.38734510222472945 max of weights 0.6238403470660735
Iteration 770 loss 0.8422920845550609 train RMSE 0.3868827325561984 Validation RMSE 770 : 0.387725088040588 max of weights 0.636974684316962
Iteration 780 loss 0.8428189766567432 train RMSE 0.38711920640777425 Validation RMSE 780 : 0.3865192016158137 max of weights 0.642887057557119
Iteration 790 loss 0.8523641696132307 train RMSE 0.391508853561413 Validation RMSE 790 : 0.3874201841671634 max of weights 0.6416580385784802
Iteration 800 loss 0.8718167671488296 train RMSE 0.40046822686825134 Validation RMSE 800 : 0.390933207263878 max of weights 0.6311843034921655
Iteration 810 loss 0.8525079602877627 train RMSE 0.39158424684144577 Validation RMSE 810 : 0.38784260496934103 max of weights 0.6246856811555329
Iteration 820 loss 0.876203663196477 train RMSE 0.40248101116584106 Validation RMSE 820 : 0.39589121894538565 max of weights 0.6213198296455176
Iteration 830 loss 0.9073293073538402 train RMSE 0.4168097208803583 Validation RMSE 830 : 0.40199896395706264 max of weights 0.6185383708666518
Iteration 840 loss 0.8716322965281369 train RMSE 0.4003845268401345 Validation RMSE 840 : 0.3917755373722207 max of weights 0.627567056179684
Iteration 850 loss 0.8344891156627492 train RMSE 0.38329493867165565 Validation RMSE 850 : 0.38751957264961545 max of weights 0.6326390400260785
Iteration 860 loss 0.8380339956802245 train RMSE 0.384909839210007 Validation RMSE 860 : 0.38719861421713886 max of weights 0.6391215812534472
Iteration 870 loss 0.8457627221333514 train RMSE 0.38845287953402846 Validation RMSE 870 : 0.38821733601563374 max of weights 0.6485641037934695
Iteration 880 loss 0.8242258885538827 train RMSE 0.37854154541716206 Validation RMSE 880 : 0.38690003396407074 max of weights 0.6540138181928555
Iteration 890 loss 0.8161304321457606 train RMSE 0.37481676526053526 Validation RMSE 890 : 0.3870034083977806 max of weights 0.658883441135457
Iteration 900 loss 0.8098850194740608 train RMSE 0.3719217472722157 Validation RMSE 900 : 0.38846699774338717 max of weights 0.6595490692736926
Iteration 910 loss 0.8542559299469838 train RMSE 0.3923334254886207 Validation RMSE 910 : 0.39182702016517984 max of weights 0.6555266012858139
Iteration 920 loss 0.8490169526242812 train RMSE 0.389913479618213 Validation RMSE 920 : 0.38848916393948446 max of weights 0.6473741722950711
Iteration 930 loss 0.844991678347303 train RMSE 0.38805967713653866 Validation RMSE 930 : 0.38639882952977783 max of weights 0.6401740380302898
Iteration 940 loss 0.8356187414931768 train RMSE 0.3837483221750224 Validation RMSE 940 : 0.38270680387073674 max of weights 0.6426444903659496
Iteration 950 loss 0.8487330563773431 train RMSE 0.3897736611984624 Validation RMSE 950 : 0.3908878430698137 max of weights 0.6532306558486717
Iteration 960 loss 0.8561210742874081 train RMSE 0.39317198167266354 Validation RMSE 960 : 0.3913989054518367 max of weights 0.6603099093308608
Iteration 970 loss 0.8597704330277128 train RMSE 0.3948681199950225 Validation RMSE 970 : 0.38647691412383306 max of weights 0.6598842649226792
Iteration 980 loss 0.8654411346936306 train RMSE 0.39749238019756084 Validation RMSE 980 : 0.3883382190648835 max of weights 0.6637737632972036
Iteration 990 loss 0.8480566485502133 train RMSE 0.38949093098060916 Validation RMSE 990 : 0.3859011330449412 max of weights 0.6666460630938839
Iteration 1000 loss 0.8498959234251127 train RMSE 0.3903277964374501 Validation RMSE 1000 : 0.3893057522932153 max of weights 0.6770871079133548
Iteration 1010 loss 0.8653973471889522 train RMSE 0.39745188508061857 Validation RMSE 1010 : 0.3874537863428848 max of weights 0.6923328281212069
Iteration 1020 loss 0.8728385546433903 train RMSE 0.4008678966637684 Validation RMSE 1020 : 0.387541058245651 max of weights 0.7103995100727841
Iteration 1030 loss 0.8371353722713165 train RMSE 0.38444057598606335 Validation RMSE 1030 : 0.3835399253520835 max of weights 0.7168447575213126
Iteration 1040 loss 0.8152599513377721 train RMSE 0.3743584415026306 Validation RMSE 1040 : 0.38930527603560927 max of weights 0.7112024257978066
Iteration 1050 loss 0.8319397087884839 train RMSE 0.3820328883945968 Validation RMSE 1050 : 0.3871237849196534 max of weights 0.7099272056846799
Iteration 1060 loss 0.833298271325224 train RMSE 0.38266220582055405 Validation RMSE 1060 : 0.3876643534232915 max of weights 0.7092641937433083
Iteration 1070 loss 0.8152741340785479 train RMSE 0.3743801570403937 Validation RMSE 1070 : 0.3896344503208554 max of weights 0.7140567581786378
Iteration 1080 loss 0.803855734461892 train RMSE 0.369122946968308 Validation RMSE 1080 : 0.3906591582825976 max of weights 0.7215828010228925
Iteration 1090 loss 0.8081595744768371 train RMSE 0.37110126669580284 Validation RMSE 1090 : 0.3869169556301688 max of weights 0.7304586331886227
Iteration 1100 loss 0.8254412320328781 train RMSE 0.37903860587978955 Validation RMSE 1100 : 0.3810125615322574 max of weights 0.7363425164327879
Iteration 1110 loss 0.8622198895544844 train RMSE 0.3959687970554195 Validation RMSE 1110 : 0.3852404901762786 max of weights 0.7467994262504482
Iteration 1120 loss 0.8649053538276154 train RMSE 0.39720289318750607 Validation RMSE 1120 : 0.3898507483015233 max of weights 0.7564292762974923
Iteration 1130 loss 0.8394078364014125 train RMSE 0.38546328938692787 Validation RMSE 1130 : 0.38709187013483315 max of weights 0.7539456803751936
Iteration 1140 loss 0.8396748304554786 train RMSE 0.385590198306519 Validation RMSE 1140 : 0.38542505894423246 max of weights 0.7538726660289068
Iteration 1150 loss 0.824917558700976 train RMSE 0.37878951244698283 Validation RMSE 1150 : 0.3847792010654108 max of weights 0.7590548859001277
Iteration 1160 loss 0.8455044036714345 train RMSE 0.38826387084447367 Validation RMSE 1160 : 0.38459896984753766 max of weights 0.7658816710342448
Iteration 1170 loss 0.8493416025075826 train RMSE 0.39003521633620064 Validation RMSE 1170 : 0.38393741825815103 max of weights 0.7713706621260906
Iteration 1180 loss 0.8435221362801821 train RMSE 0.3873526254920029 Validation RMSE 1180 : 0.3834215794369313 max of weights 0.7769575358114967
Iteration 1190 loss 0.8325672038971434 train RMSE 0.38230851196984156 Validation RMSE 1190 : 0.3849225753227922 max of weights 0.7792923780728727
Iteration 1200 loss 0.8598477794078722 train RMSE 0.39486754687179 Validation RMSE 1200 : 0.38136734880416673 max of weights 0.7829425088323246
Iteration 1210 loss 0.8508261446344015 train RMSE 0.390709010517714 Validation RMSE 1210 : 0.38342917545215854 max of weights 0.7743906497137546
Iteration 1220 loss 0.8356451328023181 train RMSE 0.38372127082131713 Validation RMSE 1220 : 0.3807416616317611 max of weights 0.771229452204591
Iteration 1230 loss 0.8224004900618366 train RMSE 0.3776282666318735 Validation RMSE 1230 : 0.37972403765055396 max of weights 0.7714753735098361
Iteration 1240 loss 0.8334989136681358 train RMSE 0.3827347720850915 Validation RMSE 1240 : 0.3865588664881085 max of weights 0.772967605773717
Iteration 1250 loss 0.8599043150114637 train RMSE 0.3948857727267924 Validation RMSE 1250 : 0.38489033069184747 max of weights 0.7893319166685506
Iteration 1260 loss 0.8392570886242303 train RMSE 0.38537578364188557 Validation RMSE 1260 : 0.38243529689445693 max of weights 0.7978251922423006
Iteration 1270 loss 0.8113799714663384 train RMSE 0.37254269555482916 Validation RMSE 1270 : 0.38232849471122626 max of weights 0.8057591428915922
Iteration 1280 loss 0.805762394999902 train RMSE 0.36994412889253386 Validation RMSE 1280 : 0.3823720128996261 max of weights 0.8064267521117546
Iteration 1290 loss 0.7998290506461233 train RMSE 0.36720309974715937 Validation RMSE 1290 : 0.3859659800293623 max of weights 0.809411258477528
Iteration 1300 loss 0.8428984901083972 train RMSE 0.3870229884895364 Validation RMSE 1300 : 0.3837181078968489 max of weights 0.8044476662760319
Iteration 1310 loss 0.8853666570511869 train RMSE 0.40656784647504063 Validation RMSE 1310 : 0.3866346473290417 max of weights 0.8153307795094132
Iteration 1320 loss 0.8568455155097285 train RMSE 0.3934520278428878 Validation RMSE 1320 : 0.3820738409243128 max of weights 0.8097428226014258
Iteration 1330 loss 0.816326054547116 train RMSE 0.3747984228016432 Validation RMSE 1330 : 0.3828034537606265 max of weights 0.8005914977534869
Iteration 1340 loss 0.8563779693194852 train RMSE 0.3932415971430317 Validation RMSE 1340 : 0.3845728291041858 max of weights 0.8015377477993787
Iteration 1350 loss 0.882869623703154 train RMSE 0.40544969450077883 Validation RMSE 1350 : 0.38746183492795805 max of weights 0.8180400778215323
Iteration 1360 loss 0.8702042219100655 train RMSE 0.3996138031551986 Validation RMSE 1360 : 0.3889608869252114 max of weights 0.8259350709879824
Iteration 1370 loss 0.8494123709732428 train RMSE 0.39004493634182097 Validation RMSE 1370 : 0.37660218262650547 max of weights 0.8289936529677806
Iteration 1380 loss 0.8734787554302018 train RMSE 0.4011219960320376 Validation RMSE 1380 : 0.3810501891921618 max of weights 0.8320451857419162
Iteration 1390 loss 0.8787146485874456 train RMSE 0.4035290641028166 Validation RMSE 1390 : 0.3805736284395537 max of weights 0.8274649247870055
Iteration 1400 loss 0.846987321582905 train RMSE 0.388919148920928 Validation RMSE 1400 : 0.37976998736055934 max of weights 0.8169618433351663
Iteration 1410 loss 0.8429292294198065 train RMSE 0.3870465021968373 Validation RMSE 1410 : 0.38197839912423404 max of weights 0.8239753660169108
Iteration 1420 loss 0.8257439297406929 train RMSE 0.3791381085011868 Validation RMSE 1420 : 0.38215670962426673 max of weights 0.8295768801252255
Iteration 1430 loss 0.8106826049484991 train RMSE 0.37221089398246826 Validation RMSE 1430 : 0.38111092523912043 max of weights 0.8339055469398565
Iteration 1440 loss 0.808686906731444 train RMSE 0.3712942625695843 Validation RMSE 1440 : 0.38117339797090816 max of weights 0.8426044377659456
Iteration 1450 loss 0.8259784684935495 train RMSE 0.37924175968142027 Validation RMSE 1450 : 0.3809158148834521 max of weights 0.8424941077864531
Iteration 1460 loss 0.8416212975133472 train RMSE 0.3864390074906047 Validation RMSE 1460 : 0.38114594906112365 max of weights 0.8346677042273273
Iteration 1470 loss 0.8336815471374116 train RMSE 0.38278058548155763 Validation RMSE 1470 : 0.3825933947498358 max of weights 0.8344192544774631
Iteration 1480 loss 0.8485561134153674 train RMSE 0.38961882276044674 Validation RMSE 1480 : 0.38856969947169556 max of weights 0.8468110989475627
Iteration 1490 loss 0.8688785590207184 train RMSE 0.3989785789445373 Validation RMSE 1490 : 0.3888955432140092 max of weights 0.860141619764657
Iteration 1500 loss 0.8403158732702553 train RMSE 0.38584063034332755 Validation RMSE 1500 : 0.38182516743014344 max of weights 0.8555082080756773
Iteration 1510 loss 0.8404362233200323 train RMSE 0.38589916676867353 Validation RMSE 1510 : 0.3811157849711241 max of weights 0.8435054759312499
Iteration 1520 loss 0.8600281255840374 train RMSE 0.39491903344905427 Validation RMSE 1520 : 0.38572927044129474 max of weights 0.8400953952308099
Iteration 1530 loss 0.8407492647005286 train RMSE 0.38605100307681617 Validation RMSE 1530 : 0.38565609947303403 max of weights 0.8434674062086464
Iteration 1540 loss 0.8096642544600235 train RMSE 0.3717404348042017 Validation RMSE 1540 : 0.38237751415162075 max of weights 0.8507528453734527
Iteration 1550 loss 0.7987733377234396 train RMSE 0.3667141650041916 Validation RMSE 1550 : 0.38236227459155114 max of weights 0.857443516450581
Iteration 1560 loss 0.8068834556079497 train RMSE 0.37044443301172303 Validation RMSE 1560 : 0.3818268426505964 max of weights 0.8612924649461045
Iteration 1570 loss 0.825908550308875 train RMSE 0.3792016197102503 Validation RMSE 1570 : 0.37827290891774373 max of weights 0.8737685295811567
Iteration 1580 loss 0.818809271856915 train RMSE 0.37592770569328177 Validation RMSE 1580 : 0.38117852110210765 max of weights 0.8771768559796793
Iteration 1590 loss 0.8162877569195172 train RMSE 0.3747687034631195 Validation RMSE 1590 : 0.37802626520498755 max of weights 0.8755715535341505
Iteration 1600 loss 0.8055431798755233 train RMSE 0.36983241636077335 Validation RMSE 1600 : 0.3800435865564666 max of weights 0.8786902329010244
Iteration 1610 loss 0.7927102522082676 train RMSE 0.36391732743989785 Validation RMSE 1610 : 0.3798395798259889 max of weights 0.8882836078007442
Iteration 1620 loss 0.8017199343679305 train RMSE 0.3680574779017023 Validation RMSE 1620 : 0.3802678799595018 max of weights 0.8924246603593612
Iteration 1630 loss 0.7996713232457248 train RMSE 0.367116571210396 Validation RMSE 1630 : 0.3784389109406878 max of weights 0.8936386048998561
Iteration 1640 loss 0.813619786688277 train RMSE 0.3735428383571558 Validation RMSE 1640 : 0.37885248747912037 max of weights 0.8947769289201232
Iteration 1650 loss 0.8540420987932781 train RMSE 0.3921502430256435 Validation RMSE 1650 : 0.38267541085176277 max of weights 0.9027531464269126
Iteration 1660 loss 0.8114700296986501 train RMSE 0.37254599320700005 Validation RMSE 1660 : 0.3818127976303281 max of weights 0.9106759064721044
Iteration 1670 loss 0.7970298898105752 train RMSE 0.3658860173406885 Validation RMSE 1670 : 0.3857794316938428 max of weights 0.9227715753761705
Iteration 1680 loss 0.8048432108166788 train RMSE 0.36948130515520966 Validation RMSE 1680 : 0.3812457661849993 max of weights 0.9276487550579896
Iteration 1690 loss 0.8243503535914481 train RMSE 0.3784634031071246 Validation RMSE 1690 : 0.37747588102449603 max of weights 0.9294103464150897
Iteration 1700 loss 0.8319360240874605 train RMSE 0.3819608185309709 Validation RMSE 1700 : 0.37662915149071186 max of weights 0.9279429407799483
Iteration 1710 loss 0.8402815101713128 train RMSE 0.38580017578085274 Validation RMSE 1710 : 0.3801010283153285 max of weights 0.9183754610851644
Iteration 1720 loss 0.835938253518003 train RMSE 0.3838002553756783 Validation RMSE 1720 : 0.3763197769634775 max of weights 0.913294629335016
Iteration 1730 loss 0.8250337542068705 train RMSE 0.3787798623019706 Validation RMSE 1730 : 0.38175403743913616 max of weights 0.9099730606712264
Iteration 1740 loss 0.8130931854432967 train RMSE 0.37329265056638733 Validation RMSE 1740 : 0.38126992963536965 max of weights 0.9056806851554502
Iteration 1750 loss 0.8160512985999739 train RMSE 0.3746572110049751 Validation RMSE 1750 : 0.38354107346602495 max of weights 0.9083566620347308
Iteration 1760 loss 0.8207973138358421 train RMSE 0.37684420923275536 Validation RMSE 1760 : 0.37750090009190695 max of weights 0.9199903384333442
Iteration 1770 loss 0.8216571544107926 train RMSE 0.3772300247225259 Validation RMSE 1770 : 0.3767537797882851 max of weights 0.9337121697751222
Iteration 1780 loss 0.8328111292598918 train RMSE 0.38235193124153355 Validation RMSE 1780 : 0.3770345302977601 max of weights 0.9435581217164879
Iteration 1790 loss 0.8483570637683535 train RMSE 0.38948872910943944 Validation RMSE 1790 : 0.37898038626801067 max of weights 0.9494795992560671
Iteration 1800 loss 0.8564409492505486 train RMSE 0.3932058252763718 Validation RMSE 1800 : 0.3805058000842209 max of weights 0.9464256704772348
Iteration 1810 loss 0.8674426826135515 train RMSE 0.3982747873297502 Validation RMSE 1810 : 0.37888663478046075 max of weights 0.9423331426963548
Iteration 1820 loss 0.8786070986663328 train RMSE 0.4034189883543418 Validation RMSE 1820 : 0.3809348784551073 max of weights 0.9382705272366383
Iteration 1830 loss 0.8449445295372738 train RMSE 0.38792667240746964 Validation RMSE 1830 : 0.37826026658292516 max of weights 0.9345710226265632
Iteration 1840 loss 0.8300893657660822 train RMSE 0.38108228972790187 Validation RMSE 1840 : 0.37825672659997966 max of weights 0.939076167217494
Iteration 1850 loss 0.8193490421399446 train RMSE 0.37614193761963943 Validation RMSE 1850 : 0.37584365387131063 max of weights 0.9481278025342188
Iteration 1860 loss 0.7985332228872053 train RMSE 0.3665662554473254 Validation RMSE 1860 : 0.3789008663711129 max of weights 0.9504655451013546
Iteration 1870 loss 0.8163827269849819 train RMSE 0.37477901603504626 Validation RMSE 1870 : 0.37934862718248996 max of weights 0.9507879359881911
Iteration 1880 loss 0.848031755370348 train RMSE 0.3893334266030155 Validation RMSE 1880 : 0.38527419200299645 max of weights 0.9501718252240172
Iteration 1890 loss 0.8533081132011889 train RMSE 0.39176240945312607 Validation RMSE 1890 : 0.3797988948627358 max of weights 0.9566130713250834
Iteration 1900 loss 0.8384540552130205 train RMSE 0.3849295317532344 Validation RMSE 1900 : 0.38081094462821835 max of weights 0.9627467718676389
Iteration 1910 loss 0.8119925905631328 train RMSE 0.3727473390520998 Validation RMSE 1910 : 0.3772908363363208 max of weights 0.9620046184133595
Iteration 1920 loss 0.8116498600131379 train RMSE 0.37259039602548305 Validation RMSE 1920 : 0.3791031198088998 max of weights 0.9587410881392094
Iteration 1930 loss 0.8136046964420004 train RMSE 0.37349144266958545 Validation RMSE 1930 : 0.3778413151845622 max of weights 0.9562043695297634
Iteration 1940 loss 0.8147056484431751 train RMSE 0.373993597908054 Validation RMSE 1940 : 0.37834705435234484 max of weights 0.9582046543043632
Iteration 1950 loss 0.8348715877368819 train RMSE 0.3832756707657381 Validation RMSE 1950 : 0.37798582507841993 max of weights 0.9584444488543866
Iteration 1960 loss 0.8647008130920761 train RMSE 0.39700315202991 Validation RMSE 1960 : 0.37930933159142805 max of weights 0.9555708731848752
Iteration 1970 loss 0.8717564237018208 train RMSE 0.4002588997274855 Validation RMSE 1970 : 0.37821724710093935 max of weights 0.9547407037556196
Iteration 1980 loss 0.8404810175622398 train RMSE 0.38587266448756224 Validation RMSE 1980 : 0.3752514170753549 max of weights 0.9536968816880723
Iteration 1990 loss 0.8280433979788212 train RMSE 0.38015131902339505 Validation RMSE 1990 : 0.373486298481407 max of weights 0.957343000541915
Iteration 2000 loss 0.8365956165441523 train RMSE 0.38408420690082723 Validation RMSE 2000 : 0.37751007975483253 max of weights 0.9643934952904385
Iteration 2010 loss 0.8452353998570072 train RMSE 0.38805907310758353 Validation RMSE 2010 : 0.37699002199449483 max of weights 0.9684466001993713
Iteration 2020 loss 0.8412751439809208 train RMSE 0.38624403253206074 Validation RMSE 2020 : 0.37663327059544405 max of weights 0.9729150157924531
Iteration 2030 loss 0.8486356858566638 train RMSE 0.3896307339406491 Validation RMSE 2030 : 0.37830457382516913 max of weights 0.972157445570103
Iteration 2040 loss 0.8358302987677265 train RMSE 0.38372839345913884 Validation RMSE 2040 : 0.3772346187324581 max of weights 0.9715835135762158
Iteration 2050 loss 0.8393590072048117 train RMSE 0.385354722663407 Validation RMSE 2050 : 0.37597855383124906 max of weights 0.974840642404318
Iteration 2060 loss 0.8424738235534259 train RMSE 0.3867917071833058 Validation RMSE 2060 : 0.37634646015342 max of weights 0.9724235006503071
Iteration 2070 loss 0.8895491164177208 train RMSE 0.408455706554832 Validation RMSE 2070 : 0.3944597931258513 max of weights 0.972434142151852
Iteration 2080 loss 0.8607422193017275 train RMSE 0.3951979926090414 Validation RMSE 2080 : 0.3774577300029276 max of weights 0.9737508107909886
Iteration 2090 loss 0.8483548952177768 train RMSE 0.3894830552801843 Validation RMSE 2090 : 0.37990654225767967 max of weights 0.9768034809209426
Iteration 2100 loss 0.8328716905363384 train RMSE 0.3823597717190567 Validation RMSE 2100 : 0.37650746319673756 max of weights 0.9849480178195444
Iteration 2110 loss 0.8462788258929238 train RMSE 0.38853475474951366 Validation RMSE 2110 : 0.37634748064704804 max of weights 0.9976772273043805
Iteration 2120 loss 0.8389964050640053 train RMSE 0.3851819053866649 Validation RMSE 2120 : 0.37279940602889966 max of weights 1.0039671557665437
Iteration 2130 loss 0.8367874799871534 train RMSE 0.3841595191724987 Validation RMSE 2130 : 0.372078869025202 max of weights 1.0070080163381967
Iteration 2140 loss 0.8795778618270661 train RMSE 0.4038411582391723 Validation RMSE 2140 : 0.38242330155254284 max of weights 1.0061359362341407
Iteration 2150 loss 0.8827574185272342 train RMSE 0.40529677115596807 Validation RMSE 2150 : 0.3842091309842966 max of weights 1.0018362787525652
Iteration 2160 loss 0.8444743730766641 train RMSE 0.3876682037589039 Validation RMSE 2160 : 0.3749880037598106 max of weights 1.0013389020836356
Iteration 2170 loss 0.8503093831469006 train RMSE 0.390361468181842 Validation RMSE 2170 : 0.37672510391082864 max of weights 0.9993695022416897
Iteration 2180 loss 0.8269448952073772 train RMSE 0.37961720806918653 Validation RMSE 2180 : 0.37843530967989214 max of weights 0.9968828999248586
Iteration 2190 loss 0.8064772482286557 train RMSE 0.37020104800535514 Validation RMSE 2190 : 0.37391880375544945 max of weights 0.9967320068146076
Iteration 2200 loss 0.7935336186017401 train RMSE 0.36423857469670856 Validation RMSE 2200 : 0.373536716929422 max of weights 0.9918339534671979
Iteration 2210 loss 0.8034245585000241 train RMSE 0.3687898979396995 Validation RMSE 2210 : 0.37194567553779445 max of weights 0.9950606745128551
Iteration 2220 loss 0.782200841003639 train RMSE 0.35901551996706843 Validation RMSE 2220 : 0.37333674908041703 max of weights 0.9997449578474511
Iteration 2230 loss 0.8055396367160015 train RMSE 0.36975092028213874 Validation RMSE 2230 : 0.3733812732906047 max of weights 0.9969555550984757
Iteration 2240 loss 0.8281358073011003 train RMSE 0.3801501757228442 Validation RMSE 2240 : 0.3730900417563544 max of weights 0.9880884262163723
Iteration 2250 loss 0.8212977009774086 train RMSE 0.37701179402559204 Validation RMSE 2250 : 0.3741624924845449 max of weights 0.9815353863076137
Iteration 2260 loss 0.8158091358077508 train RMSE 0.3744854763302143 Validation RMSE 2260 : 0.37278705533250656 max of weights 0.976520974332477
Iteration 2270 loss 0.8613890193894951 train RMSE 0.39545994152240677 Validation RMSE 2270 : 0.3813754324557107 max of weights 0.9703381966695823
Iteration 2280 loss 0.8657636647607269 train RMSE 0.39748433511393594 Validation RMSE 2280 : 0.3819165005859211 max of weights 0.9633087966651318
Iteration 2290 loss 0.8098478193001242 train RMSE 0.37175315150585725 Validation RMSE 2290 : 0.373340197415303 max of weights 0.9564837551144689
Iteration 2300 loss 0.8015871444203924 train RMSE 0.36795200657594535 Validation RMSE 2300 : 0.37304363345303304 max of weights 0.9582924640005837
Iteration 2310 loss 0.8024872484271803 train RMSE 0.3683543804382213 Validation RMSE 2310 : 0.37255562606592363 max of weights 0.9584637970032149
Iteration 2320 loss 0.799372338457752 train RMSE 0.3669172994539382 Validation RMSE 2320 : 0.37291750322906114 max of weights 0.9676468787882448
Iteration 2330 loss 0.8044545865650303 train RMSE 0.36925305764633204 Validation RMSE 2330 : 0.3743748984767248 max of weights 0.9747608449667243
Iteration 2340 loss 0.7789361329786855 train RMSE 0.3575097771935951 Validation RMSE 2340 : 0.3703805615952403 max of weights 0.9803740180291776
Iteration 2350 loss 0.8014031525823044 train RMSE 0.3678353481259822 Validation RMSE 2350 : 0.38556664210280045 max of weights 0.982817694944759
Iteration 2360 loss 0.8168555636066871 train RMSE 0.3749432822864372 Validation RMSE 2360 : 0.3734876393983247 max of weights 0.9781018451216057
Iteration 2370 loss 0.829521893043 train RMSE 0.3807617410724907 Validation RMSE 2370 : 0.3771697269944055 max of weights 0.9723353998497678
Iteration 2380 loss 0.813927207236496 train RMSE 0.3735901172717649 Validation RMSE 2380 : 0.37133775545233483 max of weights 0.9652737556081911
Iteration 2390 loss 0.8002142317147735 train RMSE 0.3672857441776421 Validation RMSE 2390 : 0.37165477282173737 max of weights 0.9648902097454863
Iteration 2400 loss 0.842056753425644 train RMSE 0.38653917917507663 Validation RMSE 2400 : 0.3836220596074839 max of weights 0.9709952096451275
Iteration 2410 loss 0.827904833310828 train RMSE 0.380030233703036 Validation RMSE 2410 : 0.37965101851910266 max of weights 0.9719386994014753
Iteration 2420 loss 0.8145705216366891 train RMSE 0.37390818892147604 Validation RMSE 2420 : 0.3756413170668479 max of weights 0.9680965609997058
Iteration 2430 loss 0.8231252412849432 train RMSE 0.377854818487542 Validation RMSE 2430 : 0.37866475373345204 max of weights 0.9626125667933466
Iteration 2440 loss 0.8241341252955062 train RMSE 0.3783169674348627 Validation RMSE 2440 : 0.3782466919312497 max of weights 0.9625925645392458
Iteration 2450 loss 0.8365048351844947 train RMSE 0.38400369464050277 Validation RMSE 2450 : 0.3826126005914994 max of weights 0.9703692071269177
Iteration 2460 loss 0.8191710918291923 train RMSE 0.3760167499398188 Validation RMSE 2460 : 0.3724613993178239 max of weights 0.9783426889570734
Iteration 2470 loss 0.8319815684620988 train RMSE 0.3819075105014883 Validation RMSE 2470 : 0.3745028528940429 max of weights 0.9860399540677471
Iteration 2480 loss 0.7971172426648647 train RMSE 0.36586491594991866 Validation RMSE 2480 : 0.37191550124907835 max of weights 0.9894307384209846
Iteration 2490 loss 0.7797046744680944 train RMSE 0.35784283243519216 Validation RMSE 2490 : 0.3733645438188781 max of weights 0.9849987867884571
Iteration 2500 loss 0.8112006258125295 train RMSE 0.372339862756724 Validation RMSE 2500 : 0.3751905760623918 max of weights 0.9792853638240785
Iteration 2510 loss 0.811538286616596 train RMSE 0.3725011368963108 Validation RMSE 2510 : 0.38125360733927144 max of weights 0.9785278508084111
Iteration 2520 loss 0.7918353138568585 train RMSE 0.36344912531149437 Validation RMSE 2520 : 0.37591674710305956 max of weights 0.9815498118746094
Iteration 2530 loss 0.7732985740948589 train RMSE 0.35491246844681235 Validation RMSE 2530 : 0.37887163214411945 max of weights 0.9851875526718317
Iteration 2540 loss 0.7722322102065541 train RMSE 0.35442128758990554 Validation RMSE 2540 : 0.37656568301288135 max of weights 0.9903111233838665
Iteration 2550 loss 0.7912253582777907 train RMSE 0.36315230507481217 Validation RMSE 2550 : 0.37079665337056583 max of weights 0.9979419826817784
Iteration 2560 loss 0.8379311225599185 train RMSE 0.38465291651159944 Validation RMSE 2560 : 0.3755368702487187 max of weights 1.0057607851831634
Iteration 2570 loss 0.823279301259165 train RMSE 0.3779030281199099 Validation RMSE 2570 : 0.3746537407693473 max of weights 1.0145011208605124
Iteration 2580 loss 0.8259495000041196 train RMSE 0.37912540556288704 Validation RMSE 2580 : 0.38004591208805727 max of weights 1.011393871787761
Iteration 2590 loss 0.8281063339378317 train RMSE 0.3801317285611975 Validation RMSE 2590 : 0.37636863728944286 max of weights 1.0069537375658997
Iteration 2600 loss 0.8108973771082375 train RMSE 0.37220829823440144 Validation RMSE 2600 : 0.3737860512065942 max of weights 1.005327863938098
Iteration 2610 loss 0.8147265621250337 train RMSE 0.3739717259341381 Validation RMSE 2610 : 0.37404705539974037 max of weights 1.0078422666713893
Iteration 2620 loss 0.8122626901234643 train RMSE 0.37283279324482654 Validation RMSE 2620 : 0.373044686975284 max of weights 1.007391349658381
Iteration 2630 loss 0.8062689257539145 train RMSE 0.3700667497186561 Validation RMSE 2630 : 0.37006894796022344 max of weights 1.008391884663081
Iteration 2640 loss 0.8344109865665676 train RMSE 0.3830205896483269 Validation RMSE 2640 : 0.3784540820232248 max of weights 1.009039916271226
Iteration 2650 loss 0.8336099676816879 train RMSE 0.3826527890591073 Validation RMSE 2650 : 0.3725963808250578 max of weights 1.0121804664443752
Iteration 2660 loss 0.8194231586398442 train RMSE 0.3761177613086913 Validation RMSE 2660 : 0.3720840193785938 max of weights 1.0138083818401864
Iteration 2670 loss 0.8200839905054257 train RMSE 0.3764184230483919 Validation RMSE 2670 : 0.37233372278388216 max of weights 1.0135818591437002
Iteration 2680 loss 0.7973627103006303 train RMSE 0.3659579832287922 Validation RMSE 2680 : 0.37363202793282674 max of weights 1.0133051019636763
Iteration 2690 loss 0.813629700088279 train RMSE 0.3734435783152952 Validation RMSE 2690 : 0.37646347278812503 max of weights 1.0174825562437773
Iteration 2700 loss 0.8178937385516231 train RMSE 0.3754029605822862 Validation RMSE 2700 : 0.3749514157122303 max of weights 1.024823301822227
Iteration 2710 loss 0.8047526799976056 train RMSE 0.369348904755128 Validation RMSE 2710 : 0.3744817101389743 max of weights 1.033445170062927
Iteration 2720 loss 0.8042170976566188 train RMSE 0.3691002637257577 Validation RMSE 2720 : 0.37460082390775723 max of weights 1.0329827810966339
Iteration 2730 loss 0.7815544610237415 train RMSE 0.3586592686401655 Validation RMSE 2730 : 0.374042938205764 max of weights 1.0271058534490927
Iteration 2740 loss 0.7836851374225892 train RMSE 0.35963476009901596 Validation RMSE 2740 : 0.3752364320457085 max of weights 1.0182811243994454
Iteration 2750 loss 0.8288843196824033 train RMSE 0.38043451312211735 Validation RMSE 2750 : 0.3751739597033838 max of weights 1.0159691652622247
Iteration 2760 loss 0.8525160596961547 train RMSE 0.3913110482405815 Validation RMSE 2760 : 0.3764821880080668 max of weights 1.0203993660168904
Iteration 2770 loss 0.8154012340460423 train RMSE 0.37423687658640964 Validation RMSE 2770 : 0.3705548988343464 max of weights 1.0158810927862933
Iteration 2780 loss 0.7944416082307865 train RMSE 0.36458659985465586 Validation RMSE 2780 : 0.3741217276278461 max of weights 1.0094516927533381
Iteration 2790 loss 0.8115503980072225 train RMSE 0.3724723211813097 Validation RMSE 2790 : 0.3702895942782194 max of weights 1.0080479859890794
Iteration 2800 loss 0.8325057860009071 train RMSE 0.3821238534768116 Validation RMSE 2800 : 0.37547804210888125 max of weights 1.0173141044098242
Iteration 2810 loss 0.8116468623987526 train RMSE 0.3725161935128124 Validation RMSE 2810 : 0.37383666938287696 max of weights 1.0149024681717067
Iteration 2820 loss 0.811977727068874 train RMSE 0.37266688083481914 Validation RMSE 2820 : 0.3707271941334478 max of weights 1.0167725059660977
Iteration 2830 loss 0.8514833171598866 train RMSE 0.390848357129988 Validation RMSE 2830 : 0.37401154739463344 max of weights 1.021392551660361
Iteration 2840 loss 0.8403239378789588 train RMSE 0.38570882941722623 Validation RMSE 2840 : 0.3720815181666752 max of weights 1.0201953373961576
Iteration 2850 loss 0.8184072513743025 train RMSE 0.37561305016781 Validation RMSE 2850 : 0.3734980076794955 max of weights 1.0251332440329464
Iteration 2860 loss 0.8056000926732921 train RMSE 0.3697163466910792 Validation RMSE 2860 : 0.3718626491903113 max of weights 1.028505454260584
Iteration 2870 loss 0.7966561518061012 train RMSE 0.36559929497474764 Validation RMSE 2870 : 0.375724203387582 max of weights 1.028037646708458
Iteration 2880 loss 0.7907916410888898 train RMSE 0.36290830476468044 Validation RMSE 2880 : 0.3728859686504446 max of weights 1.0256227167635783
Iteration 2890 loss 0.8038745066033867 train RMSE 0.36892862574659385 Validation RMSE 2890 : 0.37240064366961334 max of weights 1.0268995279443933
Iteration 2900 loss 0.7998155105036407 train RMSE 0.36705245226314254 Validation RMSE 2900 : 0.3732187261866269 max of weights 1.0210319987390502
Iteration 2910 loss 0.8195018667644733 train RMSE 0.3761088300330183 Validation RMSE 2910 : 0.37423239235976924 max of weights 1.0168994990195541
Iteration 2920 loss 0.8003892568607767 train RMSE 0.3673164966305453 Validation RMSE 2920 : 0.3700814760418032 max of weights 1.0202870615729476
Iteration 2930 loss 0.8202215521629403 train RMSE 0.37643560573416723 Validation RMSE 2930 : 0.37904024539968234 max of weights 1.0240086777106097
Iteration 2940 loss 0.830330351710736 train RMSE 0.3810983100043168 Validation RMSE 2940 : 0.3754207000730334 max of weights 1.0269108927109816
Iteration 2950 loss 0.8208389447617216 train RMSE 0.3767344648397471 Validation RMSE 2950 : 0.3723786933104278 max of weights 1.0245348410013262
Iteration 2960 loss 0.8186391578049003 train RMSE 0.37572516168019815 Validation RMSE 2960 : 0.3714182439300559 max of weights 1.0178818900786801
Iteration 2970 loss 0.8406945171240083 train RMSE 0.38587780706077507 Validation RMSE 2970 : 0.37708843414480525 max of weights 1.0173617436712545
Iteration 2980 loss 0.8196650860500498 train RMSE 0.37620183875745183 Validation RMSE 2980 : 0.37776949229600215 max of weights 1.0177805921336607
Iteration 2990 loss 0.7897044656432154 train RMSE 0.3624086686965625 Validation RMSE 2990 : 0.3741247772441312 max of weights 1.0169684870952649
Iteration 3000 loss 0.7929106771720128 train RMSE 0.36387468949949897 Validation RMSE 3000 : 0.3744816415410377 max of weights 1.0140790390107077
Iteration 3010 loss 0.8121273559674038 train RMSE 0.37271588838429104 Validation RMSE 3010 : 0.3739906023241818 max of weights 1.0212514572849485
Iteration 3020 loss 0.8173095863194618 train RMSE 0.3750992353570583 Validation RMSE 3020 : 0.3729195293489007 max of weights 1.034579316430006
Iteration 3030 loss 0.8091677604383496 train RMSE 0.3713531505500651 Validation RMSE 3030 : 0.3713676362129293 max of weights 1.0380960729629634
Iteration 3040 loss 0.8129269123998282 train RMSE 0.3730848430238692 Validation RMSE 3040 : 0.37132964004109453 max of weights 1.0417835597965344
Iteration 3050 loss 0.7974362241539389 train RMSE 0.36595888550536654 Validation RMSE 3050 : 0.3733183308946688 max of weights 1.0439646962085907
Iteration 3060 loss 0.7876362497278578 train RMSE 0.3614405528646811 Validation RMSE 3060 : 0.37173642086131126 max of weights 1.0470722309016292
Iteration 3070 loss 0.7877679225128776 train RMSE 0.36149832670485044 Validation RMSE 3070 : 0.3729186624334126 max of weights 1.0494509694870857
Iteration 3080 loss 0.778577703449402 train RMSE 0.3572738138575914 Validation RMSE 3080 : 0.3705390288346842 max of weights 1.050667939917009
Iteration 3090 loss 0.7991989178369444 train RMSE 0.3667691087715147 Validation RMSE 3090 : 0.37365029477581363 max of weights 1.0555711402499353
Iteration 3100 loss 0.8197086799721653 train RMSE 0.37620932716859307 Validation RMSE 3100 : 0.3740028789881389 max of weights 1.0581361397738756
Iteration 3110 loss 0.8007634929122839 train RMSE 0.3674779751315376 Validation RMSE 3110 : 0.3756579082601083 max of weights 1.0545084678737875
Iteration 3120 loss 0.7825981859968328 train RMSE 0.35910866198966424 Validation RMSE 3120 : 0.37620445741196956 max of weights 1.0646429741126546
Iteration 3130 loss 0.7996632737701477 train RMSE 0.36696398283375836 Validation RMSE 3130 : 0.3733601518239706 max of weights 1.0656289346869214
Iteration 3140 loss 0.8055232151466354 train RMSE 0.36966766608944696 Validation RMSE 3140 : 0.37321126800372034 max of weights 1.0645270712223887
Iteration 3150 loss 0.8077859514861578 train RMSE 0.3707170746111079 Validation RMSE 3150 : 0.37211127440433267 max of weights 1.063611447928984
Iteration 3160 loss 0.8115409081954214 train RMSE 0.3724454495711393 Validation RMSE 3160 : 0.3715427177057417 max of weights 1.0682009487131392
Iteration 3170 loss 0.8226028273654534 train RMSE 0.37753241820969036 Validation RMSE 3170 : 0.3731963336244434 max of weights 1.0769348225335638
Iteration 3180 loss 0.8074490613123173 train RMSE 0.37055932082531956 Validation RMSE 3180 : 0.3769984538965124 max of weights 1.0800333735770808
Iteration 3190 loss 0.7922091908254982 train RMSE 0.3635468185867458 Validation RMSE 3190 : 0.37763773917907745 max of weights 1.0810922963096907
Iteration 3200 loss 0.7842212114902697 train RMSE 0.35986718650022875 Validation RMSE 3200 : 0.3755054416654823 max of weights 1.081701169177476
Iteration 3210 loss 0.7977660874274638 train RMSE 0.36610167173675223 Validation RMSE 3210 : 0.37070321374596366 max of weights 1.0829069458195324
Iteration 3220 loss 0.8007764391941625 train RMSE 0.3674739104415398 Validation RMSE 3220 : 0.3697618773907343 max of weights 1.0911790061195732
Iteration 3230 loss 0.8174720101895948 train RMSE 0.375146432094682 Validation RMSE 3230 : 0.3712067219680471 max of weights 1.0954318342911968
Iteration 3240 loss 0.8320777987828912 train RMSE 0.3818529714362672 Validation RMSE 3240 : 0.37309521149531594 max of weights 1.102172153836384
Iteration 3250 loss 0.8393964935560726 train RMSE 0.38522079243823143 Validation RMSE 3250 : 0.37626887807665577 max of weights 1.1030283038291397
Iteration 3260 loss 0.8423161505577575 train RMSE 0.38657046965330416 Validation RMSE 3260 : 0.3728784514687865 max of weights 1.1054109208500478
Iteration 3270 loss 0.8390367856721991 train RMSE 0.3850619615159201 Validation RMSE 3270 : 0.37217400631801484 max of weights 1.1014262040528835
Iteration 3280 loss 0.829235744982964 train RMSE 0.3805499692119939 Validation RMSE 3280 : 0.3724179688121174 max of weights 1.0945611119044845
Iteration 3290 loss 0.8194025456003554 train RMSE 0.37601715597240637 Validation RMSE 3290 : 0.37254567740925915 max of weights 1.1030273458187072
Iteration 3300 loss 0.8078619464959016 train RMSE 0.3707082856771732 Validation RMSE 3300 : 0.3713562425637187 max of weights 1.1074210450698498
Iteration 3310 loss 0.7911830785832569 train RMSE 0.3630307643225467 Validation RMSE 3310 : 0.37565250407877643 max of weights 1.1109935576272028
Iteration 3320 loss 0.815853678609001 train RMSE 0.374380081682458 Validation RMSE 3320 : 0.37773359975814713 max of weights 1.1094090212502763
Iteration 3330 loss 0.8241644230908897 train RMSE 0.3781946028124611 Validation RMSE 3330 : 0.37694322816738013 max of weights 1.1033392143609848
Iteration 3340 loss 0.8121029694926679 train RMSE 0.3726460189625642 Validation RMSE 3340 : 0.3732799008982543 max of weights 1.1084618827924146
Iteration 3350 loss 0.8080947128240432 train RMSE 0.37080290477015454 Validation RMSE 3350 : 0.3734748782016945 max of weights 1.110785823824307
Iteration 3360 loss 0.7915779538476492 train RMSE 0.36319955258819264 Validation RMSE 3360 : 0.37040973207805916 max of weights 1.1087721382952973
Iteration 3370 loss 0.7990735316117925 train RMSE 0.36665111637901493 Validation RMSE 3370 : 0.37379833288715614 max of weights 1.1038860186286987
Iteration 3380 loss 0.7925340395448219 train RMSE 0.363640780920052 Validation RMSE 3380 : 0.37293641779498005 max of weights 1.1072604105441954
Iteration 3390 loss 0.7945697240152506 train RMSE 0.3645691020906874 Validation RMSE 3390 : 0.37220288396615253 max of weights 1.1142464118558026
Iteration 3400 loss 0.808234616577339 train RMSE 0.37085423041684207 Validation RMSE 3400 : 0.37320053272082204 max of weights 1.1112495206918278
Iteration 3410 loss 0.8493855276361912 train RMSE 0.38979232795132096 Validation RMSE 3410 : 0.3740805331086223 max of weights 1.1076378981927986
Iteration 3420 loss 0.8384792249019278 train RMSE 0.38478622109830635 Validation RMSE 3420 : 0.37079063098373627 max of weights 1.1109454401914267
Iteration 3430 loss 0.8145028110566032 train RMSE 0.37375907597180796 Validation RMSE 3430 : 0.3687268357179131 max of weights 1.1182594606487732
Iteration 3440 loss 0.8205373695363464 train RMSE 0.3765425138380767 Validation RMSE 3440 : 0.3692689794153469 max of weights 1.1260810702055608
Iteration 3450 loss 0.8264534723634749 train RMSE 0.3792624785083702 Validation RMSE 3450 : 0.37195311614226517 max of weights 1.1280469402293967
Iteration 3460 loss 0.8330265652291778 train RMSE 0.38229378961093585 Validation RMSE 3460 : 0.36942547342978427 max of weights 1.1283616055499155
Iteration 3470 loss 0.8370210699615843 train RMSE 0.3841352905861408 Validation RMSE 3470 : 0.36925358654441276 max of weights 1.1291399366760795
Iteration 3480 loss 0.8407022625386761 train RMSE 0.3858272823617209 Validation RMSE 3480 : 0.37278290377906986 max of weights 1.13054276673641
Iteration 3490 loss 0.8295819199614942 train RMSE 0.38070157773514485 Validation RMSE 3490 : 0.3731995547973355 max of weights 1.1296807613765147
Iteration 3500 loss 0.8218057261091853 train RMSE 0.37713246194968425 Validation RMSE 3500 : 0.36938114477694495 max of weights 1.1237797999529102
Iteration 3510 loss 0.8303735845229526 train RMSE 0.38107667316179616 Validation RMSE 3510 : 0.3724708346311242 max of weights 1.118235648911844
Iteration 3520 loss 0.857794323994064 train RMSE 0.3936991256901613 Validation RMSE 3520 : 0.3817081428926499 max of weights 1.110486270404999
Iteration 3530 loss 0.8379866260166461 train RMSE 0.38457940980142635 Validation RMSE 3530 : 0.3707322812341938 max of weights 1.1116600816733264
Iteration 3540 loss 0.8242321576489923 train RMSE 0.3782402943176393 Validation RMSE 3540 : 0.37237216200860035 max of weights 1.1158686733336018
Iteration 3550 loss 0.8265705135703496 train RMSE 0.37932046653652207 Validation RMSE 3550 : 0.3701606724596074 max of weights 1.1234906613210403
Iteration 3560 loss 0.8363195537787927 train RMSE 0.38381112478566526 Validation RMSE 3560 : 0.36994433627201245 max of weights 1.1336974618460824
Iteration 3570 loss 0.8222969469286164 train RMSE 0.3773573409521676 Validation RMSE 3570 : 0.3659078961964391 max of weights 1.1364418682039457
Iteration 3580 loss 0.8248466228297119 train RMSE 0.3785265406062023 Validation RMSE 3580 : 0.36716974520982665 max of weights 1.1401294034010359
Iteration 3590 loss 0.8709711940600972 train RMSE 0.3997482513931411 Validation RMSE 3590 : 0.37902360359653714 max of weights 1.1415531737370734
Iteration 3600 loss 0.8613887459023288 train RMSE 0.39532886043123244 Validation RMSE 3600 : 0.38171972033583895 max of weights 1.14355294230457
Iteration 3610 loss 0.8387588996844364 train RMSE 0.3849124580534087 Validation RMSE 3610 : 0.3697637708162635 max of weights 1.1453182732325498
Iteration 3620 loss 0.8431397468912202 train RMSE 0.3869373816684623 Validation RMSE 3620 : 0.3751762800238066 max of weights 1.1426811547946694
Iteration 3630 loss 0.8211410773223449 train RMSE 0.37681674378924185 Validation RMSE 3630 : 0.3732399304169147 max of weights 1.1398747027082765
Iteration 3640 loss 0.7991210409506344 train RMSE 0.36668152934371584 Validation RMSE 3640 : 0.37056065977783803 max of weights 1.1385107849226226
Iteration 3650 loss 0.7911620301800172 train RMSE 0.3630104243606776 Validation RMSE 3650 : 0.3700623507270996 max of weights 1.1380379276373092
Iteration 3660 loss 0.7957423565348396 train RMSE 0.3651179214612224 Validation RMSE 3660 : 0.3675585604415967 max of weights 1.1457369503123935
Iteration 3670 loss 0.780749466567205 train RMSE 0.3582162124310563 Validation RMSE 3670 : 0.36959721675893353 max of weights 1.1437342930613703
Iteration 3680 loss 0.8129966661049771 train RMSE 0.3730487309092772 Validation RMSE 3680 : 0.3698266065691837 max of weights 1.136013622284394
Iteration 3690 loss 0.8116399281637168 train RMSE 0.3724286535079688 Validation RMSE 3690 : 0.3688309282317471 max of weights 1.1235846287769393
Iteration 3700 loss 0.806040985319819 train RMSE 0.3698569803491159 Validation RMSE 3700 : 0.3684657783675537 max of weights 1.1190305966401684
Iteration 3710 loss 0.8096585945224541 train RMSE 0.37151451257492807 Validation RMSE 3710 : 0.368401455168786 max of weights 1.1088788303018566
Iteration 3720 loss 0.84957997646965 train RMSE 0.3898881497002921 Validation RMSE 3720 : 0.37702655768684945 max of weights 1.102071863919007
Iteration 3730 loss 0.8404763865379731 train RMSE 0.38570734247709565 Validation RMSE 3730 : 0.37293216648561195 max of weights 1.1036594161395448
Iteration 3740 loss 0.8043154521469593 train RMSE 0.36906883268811547 Validation RMSE 3740 : 0.368215566494407 max of weights 1.1026310860232242
Iteration 3750 loss 0.8034618910827119 train RMSE 0.3686766362173074 Validation RMSE 3750 : 0.3675954930862709 max of weights 1.1074449084691282
Iteration 3760 loss 0.8025921426370614 train RMSE 0.3682674869868116 Validation RMSE 3760 : 0.36974370742766743 max of weights 1.1124544750817333
Iteration 3770 loss 0.8009934082591612 train RMSE 0.36753082179801855 Validation RMSE 3770 : 0.3677388277178336 max of weights 1.1188313199001492
Iteration 3780 loss 0.7925354927561551 train RMSE 0.3636376186213294 Validation RMSE 3780 : 0.36838470262999795 max of weights 1.1235150096004027
Iteration 3790 loss 0.7623532357828915 train RMSE 0.349741607079832 Validation RMSE 3790 : 0.3679560261629293 max of weights 1.1254906713052475
Iteration 3800 loss 0.7867498255223834 train RMSE 0.36095969077650253 Validation RMSE 3800 : 0.37245454892374513 max of weights 1.127678563450148
Iteration 3810 loss 0.8142795259746456 train RMSE 0.3736214584234948 Validation RMSE 3810 : 0.37265755375681997 max of weights 1.1201612502247236
Iteration 3820 loss 0.8141443676667057 train RMSE 0.37355782673945187 Validation RMSE 3820 : 0.3687131262165792 max of weights 1.1167986048634735
Iteration 3830 loss 0.8061625785162606 train RMSE 0.36988892815208557 Validation RMSE 3830 : 0.3674114098257807 max of weights 1.1149905302465202
Iteration 3840 loss 0.7978347572150365 train RMSE 0.36606136868683353 Validation RMSE 3840 : 0.37014566079114414 max of weights 1.1183107336444242
Iteration 3850 loss 0.816906962242798 train RMSE 0.3748353723283278 Validation RMSE 3850 : 0.37477094857339305 max of weights 1.1256003746184038
Iteration 3860 loss 0.8013894673885898 train RMSE 0.3677004999721287 Validation RMSE 3860 : 0.37119201561368526 max of weights 1.1261171018399638
Iteration 3870 loss 0.7908275447972483 train RMSE 0.3628570149838604 Validation RMSE 3870 : 0.36954619176366793 max of weights 1.1304398412166037
Iteration 3880 loss 0.8014409067160018 train RMSE 0.36775060771472384 Validation RMSE 3880 : 0.3725486028558542 max of weights 1.1353093750860748
Iteration 3890 loss 0.8119619989290321 train RMSE 0.3725875273126769 Validation RMSE 3890 : 0.374174291793271 max of weights 1.1344282696474128
Iteration 3900 loss 0.8197384505011487 train RMSE 0.3761578488308786 Validation RMSE 3900 : 0.3705937354704229 max of weights 1.1330214347384557
Iteration 3910 loss 0.8177761988181527 train RMSE 0.3752442290839994 Validation RMSE 3910 : 0.3681923871871486 max of weights 1.133428049654035
Iteration 3920 loss 0.802672829816762 train RMSE 0.3682928965060965 Validation RMSE 3920 : 0.3668201459592103 max of weights 1.1333005999075478
Iteration 3930 loss 0.7735608522781362 train RMSE 0.35489456615850185 Validation RMSE 3930 : 0.36871832109431296 max of weights 1.1272962090034926
Iteration 3940 loss 0.775836997493917 train RMSE 0.3559390056589634 Validation RMSE 3940 : 0.37023155347839043 max of weights 1.1243516223781334
Iteration 3950 loss 0.8002001631944325 train RMSE 0.36715430237043223 Validation RMSE 3950 : 0.3711043544143671 max of weights 1.1267866055015414
Iteration 3960 loss 0.7901045254200344 train RMSE 0.36251489270454235 Validation RMSE 3960 : 0.37523345927703783 max of weights 1.1312073586232694
Iteration 3970 loss 0.7747942091350639 train RMSE 0.355480908556638 Validation RMSE 3970 : 0.3735393126359066 max of weights 1.1352785361575872
Iteration 3980 loss 0.7625041218037925 train RMSE 0.34981996250600517 Validation RMSE 3980 : 0.37425394166907355 max of weights 1.1404454855518564
Iteration 3990 loss 0.7720853221358559 train RMSE 0.35422250738230515 Validation RMSE 3990 : 0.3722245789295347 max of weights 1.1506465505740127
Iteration 4000 loss 0.8106865576607166 train RMSE 0.37197979056398184 Validation RMSE 4000 : 0.36787007619401496 max of weights 1.157891215236816
Iteration 4010 loss 0.8414659447106527 train RMSE 0.38614894606043293 Validation RMSE 4010 : 0.3697696170200454 max of weights 1.1653447640937094
Iteration 4020 loss 0.820641965780516 train RMSE 0.37655596375759165 Validation RMSE 4020 : 0.37302181462241335 max of weights 1.167349659208823
Iteration 4030 loss 0.8243473109572222 train RMSE 0.37826195807011476 Validation RMSE 4030 : 0.37480927443935197 max of weights 1.168861374336918
Iteration 4040 loss 0.8164070236972255 train RMSE 0.37461803598852467 Validation RMSE 4040 : 0.3727030134615911 max of weights 1.1692212511637414
Iteration 4050 loss 0.8191683749453051 train RMSE 0.3758871416933096 Validation RMSE 4050 : 0.37266547304583775 max of weights 1.1755064028035336
Iteration 4060 loss 0.8157291765223852 train RMSE 0.37430568596020614 Validation RMSE 4060 : 0.3711808723829967 max of weights 1.1758943685717558
Iteration 4070 loss 0.8006259025795808 train RMSE 0.367348483758751 Validation RMSE 4070 : 0.36710134294397806 max of weights 1.1742838451472721
Iteration 4080 loss 0.7895308665947609 train RMSE 0.3622363691078655 Validation RMSE 4080 : 0.36655155460651545 max of weights 1.1718457495165127
Iteration 4090 loss 0.8163823801969838 train RMSE 0.37460552851519846 Validation RMSE 4090 : 0.36924680751379063 max of weights 1.1674038833497988
Iteration 4100 loss 0.8182998460840489 train RMSE 0.3754838868409226 Validation RMSE 4100 : 0.36951169715418825 max of weights 1.1686686800282298
Iteration 4110 loss 0.8026603926494817 train RMSE 0.3682821550797988 Validation RMSE 4110 : 0.36797323496535017 max of weights 1.1676517117626097
Iteration 4120 loss 0.8158466275765036 train RMSE 0.37434568172232313 Validation RMSE 4120 : 0.3691733990160642 max of weights 1.1648511326417512
Iteration 4130 loss 0.7825899446099425 train RMSE 0.3590341754132926 Validation RMSE 4130 : 0.3716318753214508 max of weights 1.1600271742241017
Iteration 4140 loss 0.8059882437673501 train RMSE 0.36979894334210817 Validation RMSE 4140 : 0.3734092849872426 max of weights 1.1718301849145771
Iteration 4150 loss 0.8035543334743246 train RMSE 0.3686717350940617 Validation RMSE 4150 : 0.37127418674235324 max of weights 1.184229317619262
Iteration 4160 loss 0.7879363182406278 train RMSE 0.3614820870871094 Validation RMSE 4160 : 0.37054063387264474 max of weights 1.195500694605909
Iteration 4170 loss 0.7898323061507954 train RMSE 0.362347847116383 Validation RMSE 4170 : 0.3696480311944599 max of weights 1.1933706301328537
Iteration 4180 loss 0.765725730054462 train RMSE 0.35124178142427215 Validation RMSE 4180 : 0.37143379473011207 max of weights 1.1938680014977083
Iteration 4190 loss 0.7819215460395486 train RMSE 0.3586915437607623 Validation RMSE 4190 : 0.36755586762214165 max of weights 1.1896323540025955
Iteration 4200 loss 0.841995344641146 train RMSE 0.38633546130364843 Validation RMSE 4200 : 0.37424746302121925 max of weights 1.1849944811165696
Iteration 4210 loss 0.8367370496492401 train RMSE 0.3839181041203456 Validation RMSE 4210 : 0.37143939090551714 max of weights 1.181995880151602
Iteration 4220 loss 0.7994815358146837 train RMSE 0.36677729726288577 Validation RMSE 4220 : 0.36690478027649953 max of weights 1.178183752409345
Iteration 4230 loss 0.7904877900368801 train RMSE 0.3626369690695036 Validation RMSE 4230 : 0.3708332482968664 max of weights 1.1693426867873802
Iteration 4240 loss 0.8171474924858205 train RMSE 0.37492172701547 Validation RMSE 4240 : 0.36975026303379493 max of weights 1.1736865184804683
Iteration 4250 loss 0.8112505449951795 train RMSE 0.3722125672565124 Validation RMSE 4250 : 0.37098885463967757 max of weights 1.1825572295173845
Iteration 4260 loss 0.7922703007332301 train RMSE 0.3634716034213205 Validation RMSE 4260 : 0.365888533904488 max of weights 1.1841977511957242
Iteration 4270 loss 0.8063234482765946 train RMSE 0.3699329594118664 Validation RMSE 4270 : 0.36709186286072215 max of weights 1.1854822920253254
Iteration 4280 loss 0.8411698647923626 train RMSE 0.3859619943491415 Validation RMSE 4280 : 0.36859078841101317 max of weights 1.193974159078755
Iteration 4290 loss 0.8209624422990927 train RMSE 0.3766560227872597 Validation RMSE 4290 : 0.36752719416342045 max of weights 1.1973587157184435
Iteration 4300 loss 0.8053197826404814 train RMSE 0.36944749505613084 Validation RMSE 4300 : 0.36946245439443504 max of weights 1.2005496806372982
Iteration 4310 loss 0.7841818214638643 train RMSE 0.3597214593049506 Validation RMSE 4310 : 0.36851666992542315 max of weights 1.1980745947112899
Iteration 4320 loss 0.7850173423149731 train RMSE 0.36010478010484404 Validation RMSE 4320 : 0.37112728627914415 max of weights 1.1911125943712395
Iteration 4330 loss 0.7687927898247989 train RMSE 0.3526475984391002 Validation RMSE 4330 : 0.3691019419527593 max of weights 1.185586543196675
Iteration 4340 loss 0.7791746032718561 train RMSE 0.35742141634305785 Validation RMSE 4340 : 0.36775599565820016 max of weights 1.1840502984023231
Iteration 4350 loss 0.7667609691161061 train RMSE 0.3517021274699041 Validation RMSE 4350 : 0.3675941978411277 max of weights 1.1752261670226485
Iteration 4360 loss 0.7911271869474095 train RMSE 0.3629128371192466 Validation RMSE 4360 : 0.3709822997344938 max of weights 1.174823552682696
Iteration 4370 loss 0.7836169693916226 train RMSE 0.3594569862482066 Validation RMSE 4370 : 0.36664380227683374 max of weights 1.1788369002465713
Iteration 4380 loss 0.8072082388588704 train RMSE 0.3703103034051854 Validation RMSE 4380 : 0.3751475931330944 max of weights 1.1850911452035027
Iteration 4390 loss 0.8079905514884518 train RMSE 0.3706819167850594 Validation RMSE 4390 : 0.36955184940767033 max of weights 1.1889925017166416
Iteration 4400 loss 0.8096152566462556 train RMSE 0.3714331594237469 Validation RMSE 4400 : 0.3691153109711196 max of weights 1.1928415254835558
Iteration 4410 loss 0.8048541361001501 train RMSE 0.3692465232562295 Validation RMSE 4410 : 0.3683378830883189 max of weights 1.198082457172
Iteration 4420 loss 0.8180279693522307 train RMSE 0.37531260402140765 Validation RMSE 4420 : 0.3726365282334797 max of weights 1.2010684040754596
Iteration 4430 loss 0.7915822820461478 train RMSE 0.3631433274488146 Validation RMSE 4430 : 0.3721216381683993 max of weights 1.1993597045168571
Iteration 4440 loss 0.7713928707510881 train RMSE 0.3538486359555312 Validation RMSE 4440 : 0.36881973888982544 max of weights 1.1991539194254168
Iteration 4450 loss 0.7799485161714852 train RMSE 0.35778112533837453 Validation RMSE 4450 : 0.3708632425580795 max of weights 1.191564626269794
Iteration 4460 loss 0.8026302724778965 train RMSE 0.3682176097441361 Validation RMSE 4460 : 0.36898607304866976 max of weights 1.199615968332859
Iteration 4470 loss 0.7998016212785078 train RMSE 0.3669126719600593 Validation RMSE 4470 : 0.3681370221762307 max of weights 1.2096369422082087
Iteration 4480 loss 0.7939097704641949 train RMSE 0.36419848553743667 Validation RMSE 4480 : 0.3662535995826537 max of weights 1.213768139011966
Iteration 4490 loss 0.7932504610749787 train RMSE 0.3639018057490502 Validation RMSE 4490 : 0.3673535328571911 max of weights 1.216636103858366
Iteration 4500 loss 0.7818259652022398 train RMSE 0.3586412106639195 Validation RMSE 4500 : 0.36881548537581343 max of weights 1.2124190547684968
Iteration 4510 loss 0.7867719259222699 train RMSE 0.36090991811180567 Validation RMSE 4510 : 0.36891806585793485 max of weights 1.210684558273739
Iteration 4520 loss 0.7883247137752086 train RMSE 0.3616257438370083 Validation RMSE 4520 : 0.3683198792798399 max of weights 1.210846666625951
Iteration 4530 loss 0.7740177261627775 train RMSE 0.35504816517070026 Validation RMSE 4530 : 0.3674526293375625 max of weights 1.2102996852092958
Iteration 4540 loss 0.7954334075359726 train RMSE 0.3649111508948463 Validation RMSE 4540 : 0.3716872791886891 max of weights 1.2130968302529035
Iteration 4550 loss 0.7977431573671864 train RMSE 0.3659743621037186 Validation RMSE 4550 : 0.3689666629596019 max of weights 1.2112845672069559
Iteration 4560 loss 0.7703696021288535 train RMSE 0.3533649617865652 Validation RMSE 4560 : 0.37011710397852177 max of weights 1.203901069747479
Iteration 4570 loss 0.7753253380598595 train RMSE 0.355638841047832 Validation RMSE 4570 : 0.3699106032597898 max of weights 1.2080309948910763
Iteration 4580 loss 0.7895916314788634 train RMSE 0.362207168209096 Validation RMSE 4580 : 0.3674333165634168 max of weights 1.2014413786329425
Iteration 4590 loss 0.7943636229867094 train RMSE 0.3644095919314064 Validation RMSE 4590 : 0.3692394014951525 max of weights 1.198055946389345
Iteration 4600 loss 0.8052431259577991 train RMSE 0.36942351517248223 Validation RMSE 4600 : 0.36983767025236697 max of weights 1.1988813381800407
Iteration 4610 loss 0.8072138918533838 train RMSE 0.3703266953006097 Validation RMSE 4610 : 0.3661143552151773 max of weights 1.2053088181505955
Iteration 4620 loss 0.8080111373704939 train RMSE 0.37069031640415384 Validation RMSE 4620 : 0.37104924036612 max of weights 1.2151669202806443
Iteration 4630 loss 0.7859374814775811 train RMSE 0.3605319063420174 Validation RMSE 4630 : 0.37258950159820087 max of weights 1.217587568559675
Iteration 4640 loss 0.7759260321539595 train RMSE 0.35592097552568663 Validation RMSE 4640 : 0.3745354399525311 max of weights 1.2181197927848884
Iteration 4650 loss 0.7741534482066453 train RMSE 0.35510281010368133 Validation RMSE 4650 : 0.37004681375924453 max of weights 1.2179242613932553
Iteration 4660 loss 0.786647387887256 train RMSE 0.36084784295460254 Validation RMSE 4660 : 0.3678481350263315 max of weights 1.2220714574402947
Iteration 4670 loss 0.7974122121202569 train RMSE 0.36578921244108337 Validation RMSE 4670 : 0.36527253672408316 max of weights 1.229889437743363
Iteration 4680 loss 0.8104730954183518 train RMSE 0.37178802922325055 Validation RMSE 4680 : 0.3666227253180615 max of weights 1.233522695618967
Iteration 4690 loss 0.8174873906928402 train RMSE 0.3750052422116461 Validation RMSE 4690 : 0.37019515660466407 max of weights 1.2432418680705157
Iteration 4700 loss 0.8175948807872182 train RMSE 0.37505875861113325 Validation RMSE 4700 : 0.3694208425313937 max of weights 1.2439074251996454
Iteration 4710 loss 0.8330260125661603 train RMSE 0.3821693562561889 Validation RMSE 4710 : 0.36704128298364636 max of weights 1.245293340734452
Iteration 4720 loss 0.8218822953283841 train RMSE 0.37704082817465817 Validation RMSE 4720 : 0.3680250450777697 max of weights 1.2393993205822351
Iteration 4730 loss 0.8192019371288155 train RMSE 0.3758047736625104 Validation RMSE 4730 : 0.3687290188897773 max of weights 1.238573766258934
Iteration 4740 loss 0.8088198608271815 train RMSE 0.37102405030216695 Validation RMSE 4740 : 0.36725691004197514 max of weights 1.2424176782970573
Iteration 4750 loss 0.7933930484481809 train RMSE 0.36392733703140595 Validation RMSE 4750 : 0.3669828279953634 max of weights 1.2450828321088068
Iteration 4760 loss 0.7867839404038777 train RMSE 0.3608830580082512 Validation RMSE 4760 : 0.37063164841390606 max of weights 1.2428640001062363
Iteration 4770 loss 0.8278175962548215 train RMSE 0.3797574715262544 Validation RMSE 4770 : 0.3778339811670448 max of weights 1.2371157111281506
Iteration 4780 loss 0.8122359087380356 train RMSE 0.3725803996159321 Validation RMSE 4780 : 0.3699765031102169 max of weights 1.2341398801405166
Iteration 4790 loss 0.7915529267379197 train RMSE 0.36306507117084785 Validation RMSE 4790 : 0.37001009751661307 max of weights 1.2406246959984506
Iteration 4800 loss 0.7919837217996851 train RMSE 0.3632611069172328 Validation RMSE 4800 : 0.36982437306474236 max of weights 1.2420652231827138
Iteration 4810 loss 0.7747595752271637 train RMSE 0.3553340565663935 Validation RMSE 4810 : 0.3667085394507209 max of weights 1.2401958770676393
Iteration 4820 loss 0.7786490794745846 train RMSE 0.3571228156241366 Validation RMSE 4820 : 0.36874243196736617 max of weights 1.2350290354173985
Iteration 4830 loss 0.7777156879753666 train RMSE 0.3566897838733714 Validation RMSE 4830 : 0.3690942594731213 max of weights 1.2356810402704372
Iteration 4840 loss 0.7872389393804876 train RMSE 0.36106873604453305 Validation RMSE 4840 : 0.36836048965160584 max of weights 1.2399684104546491
Iteration 4850 loss 0.797075545110379 train RMSE 0.3655906923572486 Validation RMSE 4850 : 0.36873969092341524 max of weights 1.2377481851859382
Iteration 4860 loss 0.8372627615997069 train RMSE 0.38408402523971724 Validation RMSE 4860 : 0.3703664406442633 max of weights 1.2422994802155896
Iteration 4870 loss 0.8082239121587569 train RMSE 0.3707284449278908 Validation RMSE 4870 : 0.36563809236668426 max of weights 1.247932093213007
Iteration 4880 loss 0.7942648292359187 train RMSE 0.3643062318896056 Validation RMSE 4880 : 0.36468324749735076 max of weights 1.255389255069082
Iteration 4890 loss 0.810700664439874 train RMSE 0.3718743289409279 Validation RMSE 4890 : 0.3671389986171284 max of weights 1.2604472206834665
Iteration 4900 loss 0.815844661068144 train RMSE 0.3742378430196432 Validation RMSE 4900 : 0.3677840789188719 max of weights 1.258525584856547
Iteration 4910 loss 0.8185207885137732 train RMSE 0.37547603554940173 Validation RMSE 4910 : 0.36550160943272175 max of weights 1.2581461704735353
Iteration 4920 loss 0.8266033435341302 train RMSE 0.37919550901364774 Validation RMSE 4920 : 0.3653087260867274 max of weights 1.2582059844859594
Iteration 4930 loss 0.8162445311261352 train RMSE 0.3744251025292202 Validation RMSE 4930 : 0.3651818006450787 max of weights 1.260282687749304
Iteration 4940 loss 0.8133812246145167 train RMSE 0.37310322100073573 Validation RMSE 4940 : 0.36883916636782393 max of weights 1.2629470535169551
Iteration 4950 loss 0.8028185667145104 train RMSE 0.36825419296138484 Validation RMSE 4950 : 0.36494286697540357 max of weights 1.256656520360608
Iteration 4960 loss 0.8359830919870032 train RMSE 0.3835204622818592 Validation RMSE 4960 : 0.37610824059332154 max of weights 1.2562257657801577
Iteration 4970 loss 0.8180714935391251 train RMSE 0.3752810122724 Validation RMSE 4970 : 0.369205197564192 max of weights 1.2464964844506679
Iteration 4980 loss 0.8133180571313738 train RMSE 0.3730839720141058 Validation RMSE 4980 : 0.3678454947888059 max of weights 1.248350425948524
Iteration 4990 loss 0.8089248830943763 train RMSE 0.37106003010992256 Validation RMSE 4990 : 0.36921337288667255 max of weights 1.2486062355410827
Iteration 5000 loss 0.8244281990227318 train RMSE 0.37820017951660057 Validation RMSE 5000 : 0.367412919097655 max of weights 1.2523904470349052
Iteration 5010 loss 0.8262069815742819 train RMSE 0.3790261660447271 Validation RMSE 5010 : 0.3660291203239379 max of weights 1.2504666391982844
Iteration 5020 loss 0.8086976325290678 train RMSE 0.3709688239487277 Validation RMSE 5020 : 0.3634676017854529 max of weights 1.2464669607937426
Iteration 5030 loss 0.8307936915749753 train RMSE 0.38112929149592173 Validation RMSE 5030 : 0.36633781898198775 max of weights 1.249893362490331
Iteration 5040 loss 0.8569009153819276 train RMSE 0.3931398164196947 Validation RMSE 5040 : 0.37463720661411654 max of weights 1.246492742005519
Iteration 5050 loss 0.8404757002245764 train RMSE 0.38557275977648475 Validation RMSE 5050 : 0.3761880228597343 max of weights 1.2430669477228082
Iteration 5060 loss 0.8380897843340458 train RMSE 0.38447946946652456 Validation RMSE 5060 : 0.3676009649111848 max of weights 1.241684584568773
Iteration 5070 loss 0.834814167886859 train RMSE 0.38297786616381135 Validation RMSE 5070 : 0.3746337580391242 max of weights 1.239218120263012
Iteration 5080 loss 0.8008832889503981 train RMSE 0.3673664256520658 Validation RMSE 5080 : 0.36724857035615316 max of weights 1.2371397667163169
Iteration 5090 loss 0.7927430539558031 train RMSE 0.36361811042941317 Validation RMSE 5090 : 0.3674145409697347 max of weights 1.2368170163196799
Iteration 5100 loss 0.790460264768117 train RMSE 0.3625647085341341 Validation RMSE 5100 : 0.365973682269747 max of weights 1.2408766173472394
Iteration 5110 loss 0.7897712592600393 train RMSE 0.3622439193117677 Validation RMSE 5110 : 0.3660001253352148 max of weights 1.2464326107110248
Iteration 5120 loss 0.7771761511621141 train RMSE 0.35644833652910085 Validation RMSE 5120 : 0.364110248755312 max of weights 1.2430030383918464
Iteration 5130 loss 0.7998692850360957 train RMSE 0.36688578024658164 Validation RMSE 5130 : 0.3653778124202008 max of weights 1.233225202994734
Iteration 5140 loss 0.795946596785734 train RMSE 0.36508376860327796 Validation RMSE 5140 : 0.3658311005293158 max of weights 1.2273172676199837
Iteration 5150 loss 0.7901293101890191 train RMSE 0.362404643871326 Validation RMSE 5150 : 0.36404840362220836 max of weights 1.2248460218223622
Iteration 5160 loss 0.8034899436579156 train RMSE 0.36854488352774234 Validation RMSE 5160 : 0.3667929197255084 max of weights 1.2196041370844084
Iteration 5170 loss 0.8302405352117627 train RMSE 0.38086296968666405 Validation RMSE 5170 : 0.37105713279827357 max of weights 1.219579443901277
Iteration 5180 loss 0.8101548500668472 train RMSE 0.37162398795225515 Validation RMSE 5180 : 0.3662122259826504 max of weights 1.219753849028781
Iteration 5190 loss 0.7932863384536499 train RMSE 0.36386409465552166 Validation RMSE 5190 : 0.3645127459871907 max of weights 1.2184228457471629
Iteration 5200 loss 0.7954046072621561 train RMSE 0.3648370402046215 Validation RMSE 5200 : 0.3646652412788624 max of weights 1.2234005858866863
Iteration 5210 loss 0.796583521996742 train RMSE 0.3653711445503991 Validation RMSE 5210 : 0.3673554321263477 max of weights 1.2348217733813867
Iteration 5220 loss 0.7884657427444126 train RMSE 0.3616320011345369 Validation RMSE 5220 : 0.3641730093281674 max of weights 1.2391669737356608
Iteration 5230 loss 0.776863409189486 train RMSE 0.35629217108162653 Validation RMSE 5230 : 0.3650012942171094 max of weights 1.2424231245452417
Iteration 5240 loss 0.7531904920716628 train RMSE 0.345390458785305 Validation RMSE 5240 : 0.3661789282569764 max of weights 1.24375291061087
Iteration 5250 loss 0.7760397635655281 train RMSE 0.3558989743887714 Validation RMSE 5250 : 0.36738642091011153 max of weights 1.2425142299592247
Iteration 5260 loss 0.806856088909811 train RMSE 0.3700723281258079 Validation RMSE 5260 : 0.3685069735336867 max of weights 1.233110634543363
Iteration 5270 loss 0.8096125239033464 train RMSE 0.37134217537812264 Validation RMSE 5270 : 0.36535176164045985 max of weights 1.2280839078611796
Iteration 5280 loss 0.790010700876103 train RMSE 0.362328261807855 Validation RMSE 5280 : 0.36343670437117803 max of weights 1.2241046585412647
Iteration 5290 loss 0.805542554873108 train RMSE 0.3694772569366063 Validation RMSE 5290 : 0.37050404855927416 max of weights 1.2269624921975868
Iteration 5300 loss 0.7938426641337983 train RMSE 0.36408812678825864 Validation RMSE 5300 : 0.3690954494209205 max of weights 1.2306985060743412
Iteration 5310 loss 0.780326867228951 train RMSE 0.3578775798568043 Validation RMSE 5310 : 0.36635366599064584 max of weights 1.2283083431418556
Iteration 5320 loss 0.7888142946664124 train RMSE 0.36179985179974955 Validation RMSE 5320 : 0.3666560886935255 max of weights 1.2316939857043976
Iteration 5330 loss 0.7918529376773525 train RMSE 0.36320282946771715 Validation RMSE 5330 : 0.36635753737505794 max of weights 1.2327317701943825
Iteration 5340 loss 0.8212993869145511 train RMSE 0.3767463623633714 Validation RMSE 5340 : 0.3736057528265612 max of weights 1.229711186998125
Iteration 5350 loss 0.806792129250059 train RMSE 0.3700604528164655 Validation RMSE 5350 : 0.3641575689390183 max of weights 1.2255122535654412
Iteration 5360 loss 0.8206633003710715 train RMSE 0.3764383210140266 Validation RMSE 5360 : 0.36558928010561176 max of weights 1.2229270728584052
Iteration 5370 loss 0.7983314773079515 train RMSE 0.36616615725719853 Validation RMSE 5370 : 0.3648858379370035 max of weights 1.2221524571192919
Iteration 5380 loss 0.7634173213001022 train RMSE 0.350096157965727 Validation RMSE 5380 : 0.3692403084888547 max of weights 1.216623698760773
Iteration 5390 loss 0.7903122455850666 train RMSE 0.36247198490939125 Validation RMSE 5390 : 0.3682050539262297 max of weights 1.2141778804492296
Iteration 5400 loss 0.797136135563918 train RMSE 0.36561801019634327 Validation RMSE 5400 : 0.3707813948491368 max of weights 1.2164719414922895
Iteration 5410 loss 0.7781060387987818 train RMSE 0.35687047424763135 Validation RMSE 5410 : 0.3665073534991536 max of weights 1.2194993942089254
Iteration 5420 loss 0.7627290279723515 train RMSE 0.34979609653484617 Validation RMSE 5420 : 0.36825988478987026 max of weights 1.222582675724558
Iteration 5430 loss 0.7572677463908197 train RMSE 0.3472763721061507 Validation RMSE 5430 : 0.36780467427914865 max of weights 1.2278593822121373
Iteration 5440 loss 0.779308925645534 train RMSE 0.357406400392849 Validation RMSE 5440 : 0.36833418041964194 max of weights 1.2377321954756382
Iteration 5450 loss 0.8200095890927059 train RMSE 0.37613704340621684 Validation RMSE 5450 : 0.36752938231233945 max of weights 1.242869041958858
Iteration 5460 loss 0.8215573747345281 train RMSE 0.37685232491321846 Validation RMSE 5460 : 0.36785407649291585 max of weights 1.2433504576502845
Iteration 5470 loss 0.8001640256804446 train RMSE 0.36699726877840566 Validation RMSE 5470 : 0.3709371936007803 max of weights 1.2427710066558957
Iteration 5480 loss 0.8132462291224668 train RMSE 0.37302082013527316 Validation RMSE 5480 : 0.37182377165098995 max of weights 1.2411769976568965
Iteration 5490 loss 0.8039481397592728 train RMSE 0.36874640086472255 Validation RMSE 5490 : 0.36719799774276635 max of weights 1.2413985648781414
Iteration 5500 loss 0.8135772587538039 train RMSE 0.3731780374724617 Validation RMSE 5500 : 0.36760952113951995 max of weights 1.248985176924333
Iteration 5510 loss 0.8109393818088515 train RMSE 0.3719610998942221 Validation RMSE 5510 : 0.3691035513758826 max of weights 1.2497006894684093
Iteration 5520 loss 0.7918385735814215 train RMSE 0.36316457635036087 Validation RMSE 5520 : 0.363626464749917 max of weights 1.2490140187038479
Iteration 5530 loss 0.788951740739436 train RMSE 0.36183627926292644 Validation RMSE 5530 : 0.3648082192084162 max of weights 1.2466446608848747
Iteration 5540 loss 0.8148715890826277 train RMSE 0.37377346634404285 Validation RMSE 5540 : 0.36608973291929053 max of weights 1.2452737452155094
Iteration 5550 loss 0.8070786221329792 train RMSE 0.3701831515414261 Validation RMSE 5550 : 0.3652248121805223 max of weights 1.2495488448015093
Iteration 5560 loss 0.7865669560841544 train RMSE 0.3607402357531119 Validation RMSE 5560 : 0.3653330773542288 max of weights 1.2445159561765122
Iteration 5570 loss 0.7886800277186158 train RMSE 0.36170667063633843 Validation RMSE 5570 : 0.3635549664836838 max of weights 1.2409954263969298
Iteration 5580 loss 0.7803487938416 train RMSE 0.35786274450430944 Validation RMSE 5580 : 0.3708443418208192 max of weights 1.2396062521907085
Iteration 5590 loss 0.8037003442214145 train RMSE 0.3686020079428782 Validation RMSE 5590 : 0.37126055040573924 max of weights 1.2528706626120987
Iteration 5600 loss 0.803077984620375 train RMSE 0.3683090446318423 Validation RMSE 5600 : 0.368625636407364 max of weights 1.265677192092244
Iteration 5610 loss 0.7862943495331242 train RMSE 0.3605866671009213 Validation RMSE 5610 : 0.36862481328223623 max of weights 1.2722965668144708
Iteration 5620 loss 0.7751349162477277 train RMSE 0.3554443932879375 Validation RMSE 5620 : 0.3666249189338488 max of weights 1.2674378041170884
Iteration 5630 loss 0.7563094138750148 train RMSE 0.3467721920059405 Validation RMSE 5630 : 0.36960465076531374 max of weights 1.265685157798706
Iteration 5640 loss 0.7861336536441635 train RMSE 0.36049638513947246 Validation RMSE 5640 : 0.3640847442553312 max of weights 1.260994783000285
Iteration 5650 loss 0.8370670730699296 train RMSE 0.3839319897255229 Validation RMSE 5650 : 0.37195562276389416 max of weights 1.2571333781428817
Iteration 5660 loss 0.8165127387028567 train RMSE 0.374479266666825 Validation RMSE 5660 : 0.36626258486129576 max of weights 1.2503935882291055
Iteration 5670 loss 0.7908096044020961 train RMSE 0.3626549009034051 Validation RMSE 5670 : 0.3666896927528747 max of weights 1.2585647930001151
Iteration 5680 loss 0.7867903507378416 train RMSE 0.36081320440006065 Validation RMSE 5680 : 0.3649992641545455 max of weights 1.2631731106518107
Iteration 5690 loss 0.8197263698573367 train RMSE 0.3759853319018931 Validation RMSE 5690 : 0.3711365517099762 max of weights 1.2699899130022516
Iteration 5700 loss 0.7942502950555048 train RMSE 0.3642576869742467 Validation RMSE 5700 : 0.36914396741365746 max of weights 1.266212754424079
Iteration 5710 loss 0.7893963400542972 train RMSE 0.36202052406749513 Validation RMSE 5710 : 0.364023136667075 max of weights 1.2592576577343002
Iteration 5720 loss 0.810964457290694 train RMSE 0.3719397846459967 Validation RMSE 5720 : 0.36477393622985954 max of weights 1.2578357359343573
Iteration 5730 loss 0.8366980733934254 train RMSE 0.38377483555635733 Validation RMSE 5730 : 0.3673575892813979 max of weights 1.2635399151671118
Iteration 5740 loss 0.8159764665994466 train RMSE 0.3742295705378163 Validation RMSE 5740 : 0.3667098897154673 max of weights 1.268631834148277
Iteration 5750 loss 0.7943242027498579 train RMSE 0.3642568073910649 Validation RMSE 5750 : 0.367370218251397 max of weights 1.2659828203780232
Iteration 5760 loss 0.7766889280868916 train RMSE 0.3561423562538544 Validation RMSE 5760 : 0.3685435538602277 max of weights 1.261481521519806
Iteration 5770 loss 0.7724664850216219 train RMSE 0.3542036100526879 Validation RMSE 5770 : 0.3674395168253367 max of weights 1.257976684547663
Iteration 5780 loss 0.7550043600620794 train RMSE 0.346174121403051 Validation RMSE 5780 : 0.3657828996940885 max of weights 1.260522301048311
Iteration 5790 loss 0.7580508531672571 train RMSE 0.3475673957955583 Validation RMSE 5790 : 0.363821357545858 max of weights 1.2636925605955802
Iteration 5800 loss 0.7555328619654502 train RMSE 0.34640639372697607 Validation RMSE 5800 : 0.3637151465747033 max of weights 1.267521940974812
Iteration 5810 loss 0.7780826031556493 train RMSE 0.3567801919512833 Validation RMSE 5810 : 0.3666497277130871 max of weights 1.2655331231138327
Iteration 5820 loss 0.7787474686701322 train RMSE 0.3570813517738119 Validation RMSE 5820 : 0.3660682344509594 max of weights 1.2652992255663833
Iteration 5830 loss 0.7926399512866399 train RMSE 0.363474215097844 Validation RMSE 5830 : 0.3695397898362734 max of weights 1.2637230443589587
Iteration 5840 loss 0.7947916593770779 train RMSE 0.3644744843397928 Validation RMSE 5840 : 0.36669246362692526 max of weights 1.2651830148696805
Iteration 5850 loss 0.8061137014921884 train RMSE 0.3696896612448283 Validation RMSE 5850 : 0.3671449019840511 max of weights 1.2666336011840174
Iteration 5860 loss 0.8111103920820921 train RMSE 0.37199134986198845 Validation RMSE 5860 : 0.3680009058158381 max of weights 1.2679510105982723
Iteration 5870 loss 0.8006817113797776 train RMSE 0.3671958914608445 Validation RMSE 5870 : 0.36931803448682143 max of weights 1.2664094250949747
Iteration 5880 loss 0.7731215949935242 train RMSE 0.3545141980240211 Validation RMSE 5880 : 0.37000722012769227 max of weights 1.2627086858301424
Iteration 5890 loss 0.7599407803277943 train RMSE 0.34844732137666606 Validation RMSE 5890 : 0.3663778418187276 max of weights 1.267971692101321
Iteration 5900 loss 0.7752228011392819 train RMSE 0.3554749326087759 Validation RMSE 5900 : 0.3679047165993155 max of weights 1.2668018783757322
Iteration 5910 loss 0.8089158957265972 train RMSE 0.3709787576629551 Validation RMSE 5910 : 0.367060112908591 max of weights 1.2680084883704117
Iteration 5920 loss 0.7987819896108951 train RMSE 0.3663139705312922 Validation RMSE 5920 : 0.36559792646070643 max of weights 1.2700260596850843
Iteration 5930 loss 0.7930125426152898 train RMSE 0.36365527912089946 Validation RMSE 5930 : 0.36412405286471855 max of weights 1.2710680220949173
Iteration 5940 loss 0.7850666588260019 train RMSE 0.360006645752447 Validation RMSE 5940 : 0.3662669482011696 max of weights 1.2731117462334303
Iteration 5950 loss 0.7724539596308783 train RMSE 0.35419524706163485 Validation RMSE 5950 : 0.36660742906862187 max of weights 1.2711464602354066
Iteration 5960 loss 0.7744607977332455 train RMSE 0.3551132869245715 Validation RMSE 5960 : 0.36757659133230436 max of weights 1.2706350979328491
Iteration 5970 loss 0.771566378605155 train RMSE 0.35378430034402103 Validation RMSE 5970 : 0.3645894709653571 max of weights 1.270568781596525
Iteration 5980 loss 0.7771683300904197 train RMSE 0.3563686026447152 Validation RMSE 5980 : 0.36642815648199495 max of weights 1.2701763524720298
Iteration 5990 loss 0.8083164217850523 train RMSE 0.37071182590169044 Validation RMSE 5990 : 0.3699295712091926 max of weights 1.2823540037069612
Iteration 6000 loss 0.7906762563078348 train RMSE 0.3625882388244916 Validation RMSE 6000 : 0.36602734002428605 max of weights 1.2786304456823934
Iteration 6010 loss 0.7686163295800634 train RMSE 0.3524245879671157 Validation RMSE 6010 : 0.36846940328104577 max of weights 1.2793852852177268
Iteration 6020 loss 0.7795148999528727 train RMSE 0.3574409116061817 Validation RMSE 6020 : 0.36752291789847036 max of weights 1.2808811650341794
Iteration 6030 loss 0.7855749181903939 train RMSE 0.3602363893330589 Validation RMSE 6030 : 0.3654084229025796 max of weights 1.275332278819313
Iteration 6040 loss 0.7894577121857466 train RMSE 0.36203064057495843 Validation RMSE 6040 : 0.36652494843400046 max of weights 1.2745039653791088
Iteration 6050 loss 0.802031166061771 train RMSE 0.36782051215172884 Validation RMSE 6050 : 0.3700298543952854 max of weights 1.2740643927888928
Iteration 6060 loss 0.8087661094565821 train RMSE 0.37091620373963724 Validation RMSE 6060 : 0.3665266277403216 max of weights 1.28133109156274
Iteration 6070 loss 0.8020532577496629 train RMSE 0.3678249120101963 Validation RMSE 6070 : 0.3708997590487829 max of weights 1.2906359492982462
Iteration 6080 loss 0.7747418450224961 train RMSE 0.35525776314860436 Validation RMSE 6080 : 0.368163043081306 max of weights 1.2922133931511213
Iteration 6090 loss 0.7693443103094944 train RMSE 0.35276838876572564 Validation RMSE 6090 : 0.3707388917043692 max of weights 1.2932315888967723
Iteration 6100 loss 0.7711964832661617 train RMSE 0.35361922514818006 Validation RMSE 6100 : 0.3663336655019401 max of weights 1.292844501201828
Iteration 6110 loss 0.778756577955999 train RMSE 0.35708576378736256 Validation RMSE 6110 : 0.3647229485326822 max of weights 1.2893550035285932
Iteration 6120 loss 0.7974439622667454 train RMSE 0.36567489046944496 Validation RMSE 6120 : 0.3640324287198351 max of weights 1.2880275460601658
Iteration 6130 loss 0.8112934225279185 train RMSE 0.37203387808372684 Validation RMSE 6130 : 0.36578106394175075 max of weights 1.297439532304758
Iteration 6140 loss 0.8155565386911062 train RMSE 0.37399431466747524 Validation RMSE 6140 : 0.36898370729079455 max of weights 1.2981470959665207
Iteration 6150 loss 0.8127422213076135 train RMSE 0.3727073579322886 Validation RMSE 6150 : 0.3666311001681393 max of weights 1.3018297969787425
Iteration 6160 loss 0.82381548804119 train RMSE 0.3778081072723277 Validation RMSE 6160 : 0.36670673181726304 max of weights 1.3072416364403554
Iteration 6170 loss 0.8111472925334464 train RMSE 0.37197864648398554 Validation RMSE 6170 : 0.3661497532901218 max of weights 1.3099270364015678
Iteration 6180 loss 0.8106196090224941 train RMSE 0.371729345044995 Validation RMSE 6180 : 0.3677297565027491 max of weights 1.3028211928807694
Iteration 6190 loss 0.7932923125867377 train RMSE 0.3637579544192876 Validation RMSE 6190 : 0.3655898193590642 max of weights 1.300329306431342
Iteration 6200 loss 0.7697655494912206 train RMSE 0.35293442093040045 Validation RMSE 6200 : 0.3665748095097979 max of weights 1.308420549284426
Iteration 6210 loss 0.7837674226090079 train RMSE 0.3593750603176962 Validation RMSE 6210 : 0.3679289090406082 max of weights 1.3103914176640288
Iteration 6220 loss 0.8147241991067804 train RMSE 0.3736092487039317 Validation RMSE 6220 : 0.37471243208978455 max of weights 1.3084240242516707
Iteration 6230 loss 0.7995754398111047 train RMSE 0.36663922325638065 Validation RMSE 6230 : 0.36544080623490466 max of weights 1.3085335026824012
Iteration 6240 loss 0.7881837008907931 train RMSE 0.36139955615489444 Validation RMSE 6240 : 0.36675048282825623 max of weights 1.3058906206883167
Iteration 6250 loss 0.784378885397807 train RMSE 0.3596469791088161 Validation RMSE 6250 : 0.3648603716977903 max of weights 1.3108560159045646
Iteration 6260 loss 0.7753068458431909 train RMSE 0.35547069899443823 Validation RMSE 6260 : 0.3645670396387118 max of weights 1.307081191443632
Iteration 6270 loss 0.775566587636255 train RMSE 0.3555891620010256 Validation RMSE 6270 : 0.3656916978574587 max of weights 1.3066574615289481
Iteration 6280 loss 0.7773107620533891 train RMSE 0.35638557097551543 Validation RMSE 6280 : 0.36673876857744236 max of weights 1.3067738133412767
Iteration 6290 loss 0.7844014060114918 train RMSE 0.3596472402522583 Validation RMSE 6290 : 0.365566256981665 max of weights 1.3032681281801146
Iteration 6300 loss 0.7999320187014447 train RMSE 0.36678752003758364 Validation RMSE 6300 : 0.36524718736655043 max of weights 1.3004747984405038
Iteration 6310 loss 0.8322986971186821 train RMSE 0.3816829082413321 Validation RMSE 6310 : 0.36728114659122146 max of weights 1.3087224067956598
Iteration 6320 loss 0.7996145776181002 train RMSE 0.36664362944371054 Validation RMSE 6320 : 0.3643499258399761 max of weights 1.314719768822687
Iteration 6330 loss 0.7923285442375939 train RMSE 0.36329206468738023 Validation RMSE 6330 : 0.3618065669845889 max of weights 1.3211995174401856
Iteration 6340 loss 0.8040121205008217 train RMSE 0.3686707602749801 Validation RMSE 6340 : 0.3650920752839099 max of weights 1.3224554010562892
Iteration 6350 loss 0.8077266646320301 train RMSE 0.3703744333317962 Validation RMSE 6350 : 0.36350228672766416 max of weights 1.3183587938771424
Iteration 6360 loss 0.8138985060024433 train RMSE 0.3732183038625738 Validation RMSE 6360 : 0.3628402716897984 max of weights 1.321936669863855
Iteration 6370 loss 0.8225564074251095 train RMSE 0.37720269964232217 Validation RMSE 6370 : 0.3646181519062068 max of weights 1.328328037231991
Iteration 6380 loss 0.812946517668816 train RMSE 0.3727733855989206 Validation RMSE 6380 : 0.36380526794428636 max of weights 1.3330639156900144
Iteration 6390 loss 0.7989640473990834 train RMSE 0.3663449972517477 Validation RMSE 6390 : 0.3642508538569444 max of weights 1.3417913616141672
Iteration 6400 loss 0.8015145178093507 train RMSE 0.3675307085070275 Validation RMSE 6400 : 0.3640220278688074 max of weights 1.3347615956024956
Iteration 6410 loss 0.8561407463857867 train RMSE 0.39266984895176515 Validation RMSE 6410 : 0.3814345604112989 max of weights 1.3302421776949491
Iteration 6420 loss 0.8148241309507176 train RMSE 0.37366106365037915 Validation RMSE 6420 : 0.36580204129551375 max of weights 1.3240656537339255
Iteration 6430 loss 0.8061400342122178 train RMSE 0.36965648964320597 Validation RMSE 6430 : 0.36896996315963276 max of weights 1.3201187634686649
Iteration 6440 loss 0.7943416646899768 train RMSE 0.36423111133175096 Validation RMSE 6440 : 0.36477980049274006 max of weights 1.3142963103339969
Iteration 6450 loss 0.8145189694460817 train RMSE 0.37352055177241933 Validation RMSE 6450 : 0.36512003590105135 max of weights 1.3102623086179541
Iteration 6460 loss 0.811674287222998 train RMSE 0.3722145249612952 Validation RMSE 6460 : 0.3629695946500396 max of weights 1.3110077901343986
Iteration 6470 loss 0.7971932373719143 train RMSE 0.36555182300276046 Validation RMSE 6470 : 0.36186658032151303 max of weights 1.3184748858541007
Iteration 6480 loss 0.8367329782906227 train RMSE 0.383741089246315 Validation RMSE 6480 : 0.3681353906062011 max of weights 1.3202916444721202
Iteration 6490 loss 0.845773273405057 train RMSE 0.387894171295136 Validation RMSE 6490 : 0.3739683921599111 max of weights 1.3231794081420747
Iteration 6500 loss 0.8165719908926686 train RMSE 0.3744516512518188 Validation RMSE 6500 : 0.36765914156000096 max of weights 1.3262517091567665
Iteration 6510 loss 0.8273778799379282 train RMSE 0.37943239372411075 Validation RMSE 6510 : 0.36663827657250464 max of weights 1.3379372586261264
Iteration 6520 loss 0.8073024659474125 train RMSE 0.37019929652177247 Validation RMSE 6520 : 0.36864022375823646 max of weights 1.342918635778479
Iteration 6530 loss 0.7907419347641473 train RMSE 0.3625802813298843 Validation RMSE 6530 : 0.36406283687746543 max of weights 1.3504177230372247
Iteration 6540 loss 0.787319115972263 train RMSE 0.3610009162918534 Validation RMSE 6540 : 0.3653862171981795 max of weights 1.3512727041327512
Iteration 6550 loss 0.7901118017164929 train RMSE 0.36228856661220876 Validation RMSE 6550 : 0.3626874528981461 max of weights 1.3563602904260057
Iteration 6560 loss 0.7708353355874059 train RMSE 0.3534148412438456 Validation RMSE 6560 : 0.36185902412366516 max of weights 1.360237500781113
Iteration 6570 loss 0.7814847553087199 train RMSE 0.3583113955015597 Validation RMSE 6570 : 0.3623426987549858 max of weights 1.3592738209241202
Iteration 6580 loss 0.7916120329982661 train RMSE 0.36296957182871764 Validation RMSE 6580 : 0.3630239383097252 max of weights 1.3543005326483022
Iteration 6590 loss 0.7839074847393699 train RMSE 0.3594268262028522 Validation RMSE 6590 : 0.3642102821400869 max of weights 1.346826835663147
Iteration 6600 loss 0.7755793458699556 train RMSE 0.3555881309955954 Validation RMSE 6600 : 0.3618205122355139 max of weights 1.3387735388437534
Iteration 6610 loss 0.812093634694631 train RMSE 0.37238678680946075 Validation RMSE 6610 : 0.36764735820733846 max of weights 1.3322653146557928
Iteration 6620 loss 0.8255053226498199 train RMSE 0.37856452257629664 Validation RMSE 6620 : 0.3669319606525559 max of weights 1.3314510377007658
Iteration 6630 loss 0.7830124896006683 train RMSE 0.359008058751681 Validation RMSE 6630 : 0.36299416386303124 max of weights 1.3241748531540274
Iteration 6640 loss 0.7868024121301681 train RMSE 0.3607536696319812 Validation RMSE 6640 : 0.3623561660000687 max of weights 1.3232968277460366
Iteration 6650 loss 0.7847373440381675 train RMSE 0.35979534267643476 Validation RMSE 6650 : 0.3627828736724363 max of weights 1.32251408530434
Iteration 6660 loss 0.7824905552423637 train RMSE 0.35875680010165817 Validation RMSE 6660 : 0.3627941955006887 max of weights 1.3262275528104495
Iteration 6670 loss 0.7782376488260805 train RMSE 0.35679269041104505 Validation RMSE 6670 : 0.36176979355281824 max of weights 1.333290819846361
Iteration 6680 loss 0.7550656114117033 train RMSE 0.34612884733000476 Validation RMSE 6680 : 0.36120366097850926 max of weights 1.3370452162187598
Iteration 6690 loss 0.7453357212583339 train RMSE 0.3416434451325306 Validation RMSE 6690 : 0.3646740585382899 max of weights 1.3327821762123726
Iteration 6700 loss 0.7750532515761177 train RMSE 0.3553114361695997 Validation RMSE 6700 : 0.3631538717328296 max of weights 1.3311261474326692
Iteration 6710 loss 0.8098420397453289 train RMSE 0.37130952401330586 Validation RMSE 6710 : 0.36695184396042463 max of weights 1.3309161219168817
Iteration 6720 loss 0.8093642240614995 train RMSE 0.37109462146166705 Validation RMSE 6720 : 0.36377863113092446 max of weights 1.336204892449122
Iteration 6730 loss 0.7733512009093497 train RMSE 0.3545335972564212 Validation RMSE 6730 : 0.3615295775906878 max of weights 1.33789486502111
Iteration 6740 loss 0.8013638543862132 train RMSE 0.3674210769664831 Validation RMSE 6740 : 0.3691529132645808 max of weights 1.3414063450424962
Iteration 6750 loss 0.7897043327925336 train RMSE 0.3620520319039063 Validation RMSE 6750 : 0.36658456992829513 max of weights 1.3425750495727817
Iteration 6760 loss 0.7773415383195111 train RMSE 0.35637626520803517 Validation RMSE 6760 : 0.3625566891604836 max of weights 1.3401860716676492
Iteration 6770 loss 0.7887480050381798 train RMSE 0.36163695700098697 Validation RMSE 6770 : 0.36449885484464545 max of weights 1.3435241937868727
Iteration 6780 loss 0.7914521367341387 train RMSE 0.3628827944263875 Validation RMSE 6780 : 0.3626827539508234 max of weights 1.3426002691701435
Iteration 6790 loss 0.8163847018793071 train RMSE 0.37435057501487834 Validation RMSE 6790 : 0.3696463379271406 max of weights 1.3383971957913807
Iteration 6800 loss 0.7920191227267751 train RMSE 0.36312979008169055 Validation RMSE 6800 : 0.3605791556162445 max of weights 1.3414069436782783
Iteration 6810 loss 0.8081004526109998 train RMSE 0.37053182461706236 Validation RMSE 6810 : 0.36283000226992207 max of weights 1.3439060259223385
Iteration 6820 loss 0.7851125306626239 train RMSE 0.3599564057715352 Validation RMSE 6820 : 0.36213822523969025 max of weights 1.3462132655703798
Iteration 6830 loss 0.7547919113181975 train RMSE 0.346001574624061 Validation RMSE 6830 : 0.3644174349413808 max of weights 1.3429371024140093
Iteration 6840 loss 0.7875314603405797 train RMSE 0.3610677023531874 Validation RMSE 6840 : 0.3645327751955584 max of weights 1.3423828337969859
Iteration 6850 loss 0.7871577556290186 train RMSE 0.36090277119698894 Validation RMSE 6850 : 0.3725267526061328 max of weights 1.339771540595687
Iteration 6860 loss 0.77543660414651 train RMSE 0.35552221783396587 Validation RMSE 6860 : 0.36485455530268396 max of weights 1.3387950065690248
Iteration 6870 loss 0.7554682442433236 train RMSE 0.34632855981792415 Validation RMSE 6870 : 0.3677730027737535 max of weights 1.3363282728341137
Iteration 6880 loss 0.7651165724861827 train RMSE 0.3507628866609826 Validation RMSE 6880 : 0.366413277365586 max of weights 1.340461566318862
Iteration 6890 loss 0.7824645528166111 train RMSE 0.35873086974112517 Validation RMSE 6890 : 0.36314536972711825 max of weights 1.3444444799619935
Iteration 6900 loss 0.8201151881381731 train RMSE 0.3760571473836647 Validation RMSE 6900 : 0.3659723939153399 max of weights 1.3497118417814606
Iteration 6910 loss 0.7966046250635227 train RMSE 0.36523753439933454 Validation RMSE 6910 : 0.3633299587303605 max of weights 1.3541418826108267
Iteration 6920 loss 0.8014427685159295 train RMSE 0.36745441521968414 Validation RMSE 6920 : 0.3706464450065245 max of weights 1.3526244807302414
Iteration 6930 loss 0.8213322045178076 train RMSE 0.37661479596368824 Validation RMSE 6930 : 0.37034686053148086 max of weights 1.3537996865464799
Iteration 6940 loss 0.8011522696356729 train RMSE 0.3673277113562942 Validation RMSE 6940 : 0.3641058013082277 max of weights 1.3593946274980209
Iteration 6950 loss 0.7990574302432293 train RMSE 0.3663657075826236 Validation RMSE 6950 : 0.36296487208635836 max of weights 1.3598901209947662
Iteration 6960 loss 0.7919482838111375 train RMSE 0.36308735780247064 Validation RMSE 6960 : 0.36453767074487975 max of weights 1.355219365701757
Iteration 6970 loss 0.7805610274613815 train RMSE 0.3578407420479405 Validation RMSE 6970 : 0.36127187649784787 max of weights 1.35085981183941
Iteration 6980 loss 0.7938478645381339 train RMSE 0.3639588394387262 Validation RMSE 6980 : 0.36734059185446855 max of weights 1.34834660113672
Iteration 6990 loss 0.8038439186201077 train RMSE 0.3685647285125262 Validation RMSE 6990 : 0.36355769834130824 max of weights 1.3516784218370153
Iteration 7000 loss 0.7967671091941039 train RMSE 0.3653063296202984 Validation RMSE 7000 : 0.36249048218466684 max of weights 1.3483682690718344
Iteration 7010 loss 0.78673869563772 train RMSE 0.360687146037642 Validation RMSE 7010 : 0.36180664387912165 max of weights 1.354094759289341
Iteration 7020 loss 0.7691404643102391 train RMSE 0.3525813251736045 Validation RMSE 7020 : 0.36184760147291695 max of weights 1.3530160855939117
Iteration 7030 loss 0.7800713415302267 train RMSE 0.3576022038845837 Validation RMSE 7030 : 0.3664505326057513 max of weights 1.353639633309295
Iteration 7040 loss 0.7961739422723805 train RMSE 0.36500391520015296 Validation RMSE 7040 : 0.3665964577235194 max of weights 1.359748658707141
Iteration 7050 loss 0.7891415107311509 train RMSE 0.3617636454765929 Validation RMSE 7050 : 0.3659778258209235 max of weights 1.362100643702397
Iteration 7060 loss 0.7852355593166959 train RMSE 0.35996570269870415 Validation RMSE 7060 : 0.36579247493167033 max of weights 1.362901387593892
Iteration 7070 loss 0.7669370723252722 train RMSE 0.3515367559695648 Validation RMSE 7070 : 0.3647019595294525 max of weights 1.3579483752965475
Iteration 7080 loss 0.7628014897462274 train RMSE 0.349628995605747 Validation RMSE 7080 : 0.3658691176063469 max of weights 1.3577268446282582
Iteration 7090 loss 0.8056425629312457 train RMSE 0.3693425661330152 Validation RMSE 7090 : 0.3642838620091332 max of weights 1.3598116065407577
Iteration 7100 loss 0.829098706186007 train RMSE 0.38013549182123646 Validation RMSE 7100 : 0.3688851200587154 max of weights 1.3612613125966042
Iteration 7110 loss 0.7972584500146159 train RMSE 0.36549090044031757 Validation RMSE 7110 : 0.36214688186128924 max of weights 1.3720243877489484
Iteration 7120 loss 0.7804523262053723 train RMSE 0.3577595275687423 Validation RMSE 7120 : 0.36461043278035 max of weights 1.3801082905755113
Iteration 7130 loss 0.781779169457681 train RMSE 0.358381316191968 Validation RMSE 7130 : 0.36038550659408203 max of weights 1.3861344977632655
Iteration 7140 loss 0.8049391121382949 train RMSE 0.36905094597259264 Validation RMSE 7140 : 0.36652902692585354 max of weights 1.3894266025405175
Iteration 7150 loss 0.7793523384237753 train RMSE 0.357267419978084 Validation RMSE 7150 : 0.3666642538964045 max of weights 1.379419985639701
Iteration 7160 loss 0.7850512745208087 train RMSE 0.35988586715586196 Validation RMSE 7160 : 0.36282185083759494 max of weights 1.36721608137894
Iteration 7170 loss 0.8143145939100095 train RMSE 0.37335055896714914 Validation RMSE 7170 : 0.3623853363308023 max of weights 1.3646425002093807
Iteration 7180 loss 0.8290846963096781 train RMSE 0.3801418143059491 Validation RMSE 7180 : 0.36556844429176916 max of weights 1.3665972117990646
Iteration 7190 loss 0.8116588203818217 train RMSE 0.3721129951330885 Validation RMSE 7190 : 0.3648224459729622 max of weights 1.370620878190904
Iteration 7200 loss 0.7825200970149837 train RMSE 0.35870239651339464 Validation RMSE 7200 : 0.36228378534110367 max of weights 1.3660840678374606
Iteration 7210 loss 0.7765999981703704 train RMSE 0.3559779292659513 Validation RMSE 7210 : 0.3654373374786628 max of weights 1.3622430565123356
Iteration 7220 loss 0.7564923635267394 train RMSE 0.3467342140229981 Validation RMSE 7220 : 0.36253136019815413 max of weights 1.3607507145912061
Iteration 7230 loss 0.7482557552065261 train RMSE 0.3429457830250174 Validation RMSE 7230 : 0.36185564209124416 max of weights 1.3635161445745363
Iteration 7240 loss 0.7497842460258137 train RMSE 0.34363987799811857 Validation RMSE 7240 : 0.36186197414308274 max of weights 1.3643158969214675
Iteration 7250 loss 0.7589650492033608 train RMSE 0.34786738958195046 Validation RMSE 7250 : 0.36125223116291183 max of weights 1.3666923467242418
Iteration 7260 loss 0.7715232619620102 train RMSE 0.35364874343525143 Validation RMSE 7260 : 0.3608617689136419 max of weights 1.362898515361023
Iteration 7270 loss 0.7817486351765732 train RMSE 0.35834510869435726 Validation RMSE 7270 : 0.3648508275014259 max of weights 1.3664053225929904
Iteration 7280 loss 0.7828409130359215 train RMSE 0.3588513877598882 Validation RMSE 7280 : 0.363690747042199 max of weights 1.3655295980100817
Iteration 7290 loss 0.7908539507813788 train RMSE 0.3625425233690642 Validation RMSE 7290 : 0.36299291602673556 max of weights 1.3695566702356956
Iteration 7300 loss 0.7974110203175659 train RMSE 0.3655618629701662 Validation RMSE 7300 : 0.36359665307048855 max of weights 1.3687907641124673
Iteration 7310 loss 0.8111104387423627 train RMSE 0.3718665617689666 Validation RMSE 7310 : 0.3674902634205983 max of weights 1.3686919633317751
Iteration 7320 loss 0.7876301220518581 train RMSE 0.36106455449026503 Validation RMSE 7320 : 0.3665294412139165 max of weights 1.3722127383447504
Iteration 7330 loss 0.7585775489419764 train RMSE 0.34769798634519133 Validation RMSE 7330 : 0.3668417076972021 max of weights 1.3703308629650137
Iteration 7340 loss 0.7555724303203922 train RMSE 0.3463122350033247 Validation RMSE 7340 : 0.3642093979687892 max of weights 1.3654951548792362
Iteration 7350 loss 0.7781834029183065 train RMSE 0.356709976345492 Validation RMSE 7350 : 0.36521087860078527 max of weights 1.3650931943069189
Iteration 7360 loss 0.8037538835381831 train RMSE 0.36847463365214617 Validation RMSE 7360 : 0.36579714360155563 max of weights 1.3710661612402562
Iteration 7370 loss 0.7975664284947384 train RMSE 0.3656259791631551 Validation RMSE 7370 : 0.3646197576850012 max of weights 1.382425334294601
Iteration 7380 loss 0.7897533461559476 train RMSE 0.3620297657977933 Validation RMSE 7380 : 0.36331268220794455 max of weights 1.3900715202641936
Iteration 7390 loss 0.7749785546798328 train RMSE 0.3552349312745225 Validation RMSE 7390 : 0.36462172775271623 max of weights 1.3901350829178023
Iteration 7400 loss 0.7664349713290236 train RMSE 0.3512948119241253 Validation RMSE 7400 : 0.363442736726739 max of weights 1.3874016990181208
Iteration 7410 loss 0.7695137403067996 train RMSE 0.35271159785936634 Validation RMSE 7410 : 0.36503469238209957 max of weights 1.388169334125561
Iteration 7420 loss 0.7637696034738483 train RMSE 0.350073789823875 Validation RMSE 7420 : 0.36206004363666344 max of weights 1.383802087537279
Iteration 7430 loss 0.7794732137311691 train RMSE 0.3573071618772976 Validation RMSE 7430 : 0.3663303428017957 max of weights 1.381937252685643
Iteration 7440 loss 0.7942433731396864 train RMSE 0.36411196990647887 Validation RMSE 7440 : 0.3660474161746607 max of weights 1.3823742591128934
Iteration 7450 loss 0.7777759864995186 train RMSE 0.3565265447862645 Validation RMSE 7450 : 0.36537230037300167 max of weights 1.3839648967825144
Iteration 7460 loss 0.7610741540803229 train RMSE 0.34883043646053247 Validation RMSE 7460 : 0.3678712259874076 max of weights 1.3897462364246156
Iteration 7470 loss 0.7837172600853604 train RMSE 0.3592551517697232 Validation RMSE 7470 : 0.3655314457927129 max of weights 1.3904410258506317
Iteration 7480 loss 0.7834574453686187 train RMSE 0.35914238116741304 Validation RMSE 7480 : 0.36513773817177725 max of weights 1.3943659824113546
Iteration 7490 loss 0.7959449171997277 train RMSE 0.3648956549338864 Validation RMSE 7490 : 0.3643211240994677 max of weights 1.3938186610757841
Iteration 7500 loss 0.8021045118723429 train RMSE 0.36772788648352556 Validation RMSE 7500 : 0.36624360467742756 max of weights 1.3949940430843204
Iteration 7510 loss 0.8116974197909862 train RMSE 0.37213738672079794 Validation RMSE 7510 : 0.3644421321596661 max of weights 1.3964393264844757
Iteration 7520 loss 0.8009600726326117 train RMSE 0.3671967628873904 Validation RMSE 7520 : 0.36859764990936045 max of weights 1.402421062999545
Iteration 7530 loss 0.7714163156566333 train RMSE 0.35359982901006376 Validation RMSE 7530 : 0.3672894273101532 max of weights 1.4030582021994986
Iteration 7540 loss 0.7649032059773693 train RMSE 0.3505971500816712 Validation RMSE 7540 : 0.36683753957348514 max of weights 1.4045848598024153
Iteration 7550 loss 0.775245976696137 train RMSE 0.3553527909126019 Validation RMSE 7550 : 0.3626923689778052 max of weights 1.4084442857503214
Iteration 7560 loss 0.7769717917493101 train RMSE 0.3561314386472622 Validation RMSE 7560 : 0.36231848743404915 max of weights 1.4077050548721548
Iteration 7570 loss 0.798279073820776 train RMSE 0.36592604622394503 Validation RMSE 7570 : 0.36262125015502544 max of weights 1.413324697569372
Iteration 7580 loss 0.8160391849046698 train RMSE 0.37408576362676665 Validation RMSE 7580 : 0.36459959164796885 max of weights 1.4193049622412597
Iteration 7590 loss 0.821413717372183 train RMSE 0.37656534783301765 Validation RMSE 7590 : 0.3675000017745607 max of weights 1.4177762854009952
Iteration 7600 loss 0.815441260602006 train RMSE 0.37382402698725875 Validation RMSE 7600 : 0.36520520019713826 max of weights 1.4236289401848505
Iteration 7610 loss 0.8214130622246192 train RMSE 0.37657249853186586 Validation RMSE 7610 : 0.3663647375374736 max of weights 1.427436596891245
Iteration 7620 loss 0.8121002146322991 train RMSE 0.3722898076581311 Validation RMSE 7620 : 0.3650002012699567 max of weights 1.4268506476665546
Iteration 7630 loss 0.8026858181766601 train RMSE 0.3679535195550086 Validation RMSE 7630 : 0.3655242456696722 max of weights 1.421181326017123
Iteration 7640 loss 0.783761995724048 train RMSE 0.35925028938607484 Validation RMSE 7640 : 0.3629156361856805 max of weights 1.4180579484190883
Iteration 7650 loss 0.7614375387323964 train RMSE 0.3489797936389733 Validation RMSE 7650 : 0.36526019616625766 max of weights 1.4138111863330405
Iteration 7660 loss 0.7823980922671361 train RMSE 0.35862167452735566 Validation RMSE 7660 : 0.3660625606450023 max of weights 1.4144395301385448
Iteration 7670 loss 0.795262750036041 train RMSE 0.3645311177679834 Validation RMSE 7670 : 0.36927447994303736 max of weights 1.415026205335573
Iteration 7680 loss 0.7762652781394068 train RMSE 0.35579356981601296 Validation RMSE 7680 : 0.36244892624428815 max of weights 1.4147725899846646
Iteration 7690 loss 0.7845127157699131 train RMSE 0.3595878378265292 Validation RMSE 7690 : 0.3638063993969295 max of weights 1.4154810926972
Iteration 7700 loss 0.7675784067709082 train RMSE 0.3517923250072052 Validation RMSE 7700 : 0.3609142611283757 max of weights 1.4156761051039328
Iteration 7710 loss 0.771863119803161 train RMSE 0.3537637368309207 Validation RMSE 7710 : 0.36440857005495103 max of weights 1.4155023980229335
Iteration 7720 loss 0.7687777018450328 train RMSE 0.3523442859319635 Validation RMSE 7720 : 0.3637683304014074 max of weights 1.412019259291318
Iteration 7730 loss 0.7777618961160282 train RMSE 0.3564729880392427 Validation RMSE 7730 : 0.36361129046283264 max of weights 1.4085292927200854
Iteration 7740 loss 0.7739741351972824 train RMSE 0.35472838080342173 Validation RMSE 7740 : 0.36241652234652333 max of weights 1.4038805856882541
Iteration 7750 loss 0.8038430632179164 train RMSE 0.3684663581867653 Validation RMSE 7750 : 0.3639376643856043 max of weights 1.4004788768948115
Iteration 7760 loss 0.8107341294371602 train RMSE 0.37163928025798926 Validation RMSE 7760 : 0.3635775350776413 max of weights 1.408758781476743
Iteration 7770 loss 0.7891375062842175 train RMSE 0.36170009482257875 Validation RMSE 7770 : 0.3627987876900925 max of weights 1.4137675499085152
Iteration 7780 loss 0.7930771578026877 train RMSE 0.36351645345194733 Validation RMSE 7780 : 0.3609269573341808 max of weights 1.420231574228537
Iteration 7790 loss 0.7948854658450921 train RMSE 0.36434489000018544 Validation RMSE 7790 : 0.3651018069887485 max of weights 1.4182245105429656
Iteration 7800 loss 0.8066008770412735 train RMSE 0.3697334304655069 Validation RMSE 7800 : 0.36094996056371403 max of weights 1.4163182483140195
Iteration 7810 loss 0.8155246845876906 train RMSE 0.37384183651177466 Validation RMSE 7810 : 0.3612915759327477 max of weights 1.4228588966941946
Iteration 7820 loss 0.8214216431164391 train RMSE 0.37655334972177934 Validation RMSE 7820 : 0.36320690896629737 max of weights 1.4269065159746548
Iteration 7830 loss 0.8077040698523853 train RMSE 0.37023398112562517 Validation RMSE 7830 : 0.36399918389300107 max of weights 1.4303598490370537
Iteration 7840 loss 0.7978699507600994 train RMSE 0.3657210041760017 Validation RMSE 7840 : 0.3619565107720805 max of weights 1.436293206054674
Iteration 7850 loss 0.8058755821788428 train RMSE 0.3694114658876373 Validation RMSE 7850 : 0.3644703958946265 max of weights 1.4263375220939993
Iteration 7860 loss 0.8357640634056364 train RMSE 0.383165466872595 Validation RMSE 7860 : 0.37363941665365336 max of weights 1.4212495200484268
Iteration 7870 loss 0.8028192021076954 train RMSE 0.36800658310442186 Validation RMSE 7870 : 0.36249973625091125 max of weights 1.4189166604953796
Iteration 7880 loss 0.7888480979055441 train RMSE 0.36157183695391437 Validation RMSE 7880 : 0.3656375430666889 max of weights 1.418699795129215
Iteration 7890 loss 0.7949945893584174 train RMSE 0.36440647071514815 Validation RMSE 7890 : 0.36056199887692014 max of weights 1.4280013129975426
Iteration 7900 loss 0.8154180851042071 train RMSE 0.3738073397821818 Validation RMSE 7900 : 0.3641166159424649 max of weights 1.4324382240305673
Iteration 7910 loss 0.8021355123256586 train RMSE 0.3676929337544933 Validation RMSE 7910 : 0.36153256919187865 max of weights 1.440007126291748
Iteration 7920 loss 0.7984047394241292 train RMSE 0.3659744613063758 Validation RMSE 7920 : 0.36074335304979455 max of weights 1.444791876703381
Iteration 7930 loss 0.8398487428914455 train RMSE 0.38503986341443897 Validation RMSE 7930 : 0.37002896195420837 max of weights 1.4440957026715777
Iteration 7940 loss 0.8305675530595874 train RMSE 0.3807602855017256 Validation RMSE 7940 : 0.3768852467004448 max of weights 1.4450313861169242
Iteration 7950 loss 0.7994316696594538 train RMSE 0.36643408425187846 Validation RMSE 7950 : 0.3628690154543483 max of weights 1.4525291710000277
Iteration 7960 loss 0.8138538939170046 train RMSE 0.3730795385274924 Validation RMSE 7960 : 0.3647604945382365 max of weights 1.4612041577375199
Iteration 7970 loss 0.7913001767892135 train RMSE 0.3627044792871898 Validation RMSE 7970 : 0.36393441123705733 max of weights 1.4667531838610084
Iteration 7980 loss 0.7730957013937202 train RMSE 0.35432777865556847 Validation RMSE 7980 : 0.36082924853610954 max of weights 1.468553796533325
Iteration 7990 loss 0.7676103633838951 train RMSE 0.3517983127703861 Validation RMSE 7990 : 0.36161910273851666 max of weights 1.4693856075968386
Iteration 8000 loss 0.7813363065207578 train RMSE 0.3581146109229763 Validation RMSE 8000 : 0.3599614325204087 max of weights 1.4709194562880301
Iteration 8010 loss 0.7618464013000412 train RMSE 0.3491449275303905 Validation RMSE 8010 : 0.3606198536509185 max of weights 1.469034650523768
Iteration 8020 loss 0.781475943175286 train RMSE 0.35817383525753477 Validation RMSE 8020 : 0.3608528986781717 max of weights 1.4670490610228495
Iteration 8030 loss 0.7765924102851043 train RMSE 0.35592813556559294 Validation RMSE 8030 : 0.3608660196146435 max of weights 1.4673097250231442
Iteration 8040 loss 0.768548336383346 train RMSE 0.3522258586343288 Validation RMSE 8040 : 0.361897129570082 max of weights 1.4634274591409642
Iteration 8050 loss 0.7651613128675434 train RMSE 0.3506582900151078 Validation RMSE 8050 : 0.35987144415944133 max of weights 1.4555916452931177
Iteration 8060 loss 0.8109221142808902 train RMSE 0.3717128268909062 Validation RMSE 8060 : 0.3666136669510105 max of weights 1.4523051429095024
Iteration 8070 loss 0.8063598146646788 train RMSE 0.3696180332885746 Validation RMSE 8070 : 0.3625518102174865 max of weights 1.4502047832816882
Iteration 8080 loss 0.7668758259446723 train RMSE 0.35144465396418584 Validation RMSE 8080 : 0.35780488835185714 max of weights 1.4459886127885495
Iteration 8090 loss 0.7751943707178253 train RMSE 0.3552711897103719 Validation RMSE 8090 : 0.35883723525613687 max of weights 1.4455302812220343
Iteration 8100 loss 0.769803824970911 train RMSE 0.352781360284749 Validation RMSE 8100 : 0.36098735244815855 max of weights 1.4429748225920787
Iteration 8110 loss 0.7688732120302775 train RMSE 0.3523504791735548 Validation RMSE 8110 : 0.3588348481976663 max of weights 1.4478376493534288
Iteration 8120 loss 0.7671379380522657 train RMSE 0.3515481221729971 Validation RMSE 8120 : 0.3591848480499469 max of weights 1.4536114750045561
Iteration 8130 loss 0.746529621092505 train RMSE 0.3420635178886747 Validation RMSE 8130 : 0.35789924507455684 max of weights 1.4529362361352876
Iteration 8140 loss 0.7550466972898436 train RMSE 0.3459765196464772 Validation RMSE 8140 : 0.3622748847553901 max of weights 1.4476034176425274
Iteration 8150 loss 0.7905047390798158 train RMSE 0.3622856813247696 Validation RMSE 8150 : 0.36109290210627387 max of weights 1.4463135479762228
Iteration 8160 loss 0.8061742131206681 train RMSE 0.3694919971925887 Validation RMSE 8160 : 0.36206537229053654 max of weights 1.4464041885861405
Iteration 8170 loss 0.7889577381178683 train RMSE 0.36158033079618096 Validation RMSE 8170 : 0.35887856405353935 max of weights 1.451120334074734
Iteration 8180 loss 0.7664327782877589 train RMSE 0.3512240019126201 Validation RMSE 8180 : 0.36023536279584306 max of weights 1.455456936004557
Iteration 8190 loss 0.7876644258967177 train RMSE 0.3609888781191416 Validation RMSE 8190 : 0.36408877307490817 max of weights 1.4586372235563012
Iteration 8200 loss 0.7840879863799832 train RMSE 0.35934205570545324 Validation RMSE 8200 : 0.36238133246601373 max of weights 1.459660866355915
Iteration 8210 loss 0.7767779438064001 train RMSE 0.35599135505859886 Validation RMSE 8210 : 0.3591091758161059 max of weights 1.4596201234789488
Iteration 8220 loss 0.7838360997261485 train RMSE 0.35924791040861337 Validation RMSE 8220 : 0.36166979998269916 max of weights 1.4627126851157817
Iteration 8230 loss 0.798102360901418 train RMSE 0.36581015697267455 Validation RMSE 8230 : 0.36379612636009184 max of weights 1.4625275383283105
Iteration 8240 loss 0.806365023771761 train RMSE 0.36960681914161575 Validation RMSE 8240 : 0.3640717793773781 max of weights 1.4646985888723663
Iteration 8250 loss 0.7885094477098004 train RMSE 0.3613832602402788 Validation RMSE 8250 : 0.3579551444270197 max of weights 1.4677405908159447
Iteration 8260 loss 0.7882341486887728 train RMSE 0.3612581640896768 Validation RMSE 8260 : 0.3595002441122903 max of weights 1.4683507822269537
Iteration 8270 loss 0.7644850355027736 train RMSE 0.35032774023917174 Validation RMSE 8270 : 0.36189778328703565 max of weights 1.4689280415198798
Iteration 8280 loss 0.7590645559166507 train RMSE 0.3478356410544602 Validation RMSE 8280 : 0.36203054097409204 max of weights 1.4679325548224196
Iteration 8290 loss 0.7833891501667716 train RMSE 0.359032641645343 Validation RMSE 8290 : 0.36204326953834604 max of weights 1.4673156383583383
Iteration 8300 loss 0.7641550805070777 train RMSE 0.3501874090870772 Validation RMSE 8300 : 0.3673032235829431 max of weights 1.4636907250954259
Iteration 8310 loss 0.7732856316777178 train RMSE 0.35439721073292163 Validation RMSE 8310 : 0.36676869295234704 max of weights 1.459317935367407
Iteration 8320 loss 0.7454048546335674 train RMSE 0.3415605389194366 Validation RMSE 8320 : 0.36714920103835347 max of weights 1.4574736957094179
Iteration 8330 loss 0.7579900125830444 train RMSE 0.34734423890314986 Validation RMSE 8330 : 0.36517144545920216 max of weights 1.4607857227867647
Iteration 8340 loss 0.788100592356054 train RMSE 0.3611917463259084 Validation RMSE 8340 : 0.3600205160438393 max of weights 1.4659825481839095
Iteration 8350 loss 0.810997733043492 train RMSE 0.3717297526721587 Validation RMSE 8350 : 0.36117096419897415 max of weights 1.4720119552227826
Iteration 8360 loss 0.7874836276099372 train RMSE 0.3609021663593946 Validation RMSE 8360 : 0.36259557969768963 max of weights 1.4785250150797615
Iteration 8370 loss 0.7940251398875978 train RMSE 0.36390262074259594 Validation RMSE 8370 : 0.3690751412396664 max of weights 1.47224897674745
Iteration 8380 loss 0.8089872489203059 train RMSE 0.3707960808531083 Validation RMSE 8380 : 0.3666860581932 max of weights 1.4672924598869326
Iteration 8390 loss 0.7923919734217438 train RMSE 0.3631580478094794 Validation RMSE 8390 : 0.36150095659527254 max of weights 1.4628768831191554
Iteration 8400 loss 0.788872934952498 train RMSE 0.3615391378415327 Validation RMSE 8400 : 0.3609056202280599 max of weights 1.463033945407574
Iteration 8410 loss 0.7775961919910328 train RMSE 0.3563429533190138 Validation RMSE 8410 : 0.35964927043566824 max of weights 1.4641289401232596
Iteration 8420 loss 0.7700789303291077 train RMSE 0.35287932385516513 Validation RMSE 8420 : 0.359209756366184 max of weights 1.4641578223159204
Iteration 8430 loss 0.7940915019068134 train RMSE 0.36393765143095136 Validation RMSE 8430 : 0.3647575091714272 max of weights 1.4726337944775112
Iteration 8440 loss 0.7925886131206937 train RMSE 0.36324799233499294 Validation RMSE 8440 : 0.3626228394385468 max of weights 1.4749882497432245
Iteration 8450 loss 0.7772395034691243 train RMSE 0.3561825904030211 Validation RMSE 8450 : 0.3591147406180295 max of weights 1.475700284397682
Iteration 8460 loss 0.7947437360542422 train RMSE 0.36423006065688207 Validation RMSE 8460 : 0.36231007611244315 max of weights 1.4823607431409676
Iteration 8470 loss 0.7563972291861303 train RMSE 0.3465774901073014 Validation RMSE 8470 : 0.36367287499418777 max of weights 1.484745864396456
Iteration 8480 loss 0.7817105239478916 train RMSE 0.35822005664637535 Validation RMSE 8480 : 0.3627657907589005 max of weights 1.4884278583638857
Iteration 8490 loss 0.7866602461925728 train RMSE 0.3604897481496336 Validation RMSE 8490 : 0.3637220320679785 max of weights 1.4929940648506503
Iteration 8500 loss 0.7714234750913448 train RMSE 0.3534794609597504 Validation RMSE 8500 : 0.3640339111560865 max of weights 1.4958393194042638
Iteration 8510 loss 0.7741557343885768 train RMSE 0.35473353154914145 Validation RMSE 8510 : 0.36315775888078 max of weights 1.4948757763123703
Iteration 8520 loss 0.7489992145853074 train RMSE 0.34314851200974134 Validation RMSE 8520 : 0.3649264805229751 max of weights 1.495644636736093
Iteration 8530 loss 0.7572019238245086 train RMSE 0.34692135487775194 Validation RMSE 8530 : 0.3599796422388025 max of weights 1.4978271536940753
Iteration 8540 loss 0.8167485246213644 train RMSE 0.37432134229825104 Validation RMSE 8540 : 0.36642883885336186 max of weights 1.5080080690510804
Iteration 8550 loss 0.8175827073979606 train RMSE 0.37470657662502904 Validation RMSE 8550 : 0.36566649689644953 max of weights 1.5110183499875174
Iteration 8560 loss 0.7823597958342112 train RMSE 0.3585038995184738 Validation RMSE 8560 : 0.3600445808809675 max of weights 1.51114974873119
Iteration 8570 loss 0.7691750696676918 train RMSE 0.3524370639254621 Validation RMSE 8570 : 0.36334596780268497 max of weights 1.5112872514080875
Iteration 8580 loss 0.7894302709449769 train RMSE 0.3617705306366606 Validation RMSE 8580 : 0.3612776767988052 max of weights 1.517057613493123
Iteration 8590 loss 0.7955794067288651 train RMSE 0.3646074764406679 Validation RMSE 8590 : 0.36313234655822113 max of weights 1.5223929092191872
Iteration 8600 loss 0.7718184190398683 train RMSE 0.35366710300268595 Validation RMSE 8600 : 0.3598954572244985 max of weights 1.5203352769652885
Iteration 8610 loss 0.790303376300523 train RMSE 0.3621661906966992 Validation RMSE 8610 : 0.36054438191009536 max of weights 1.516526250483028
Iteration 8620 loss 0.8132554822199594 train RMSE 0.3727248061527912 Validation RMSE 8620 : 0.36020192935704254 max of weights 1.5131085570838605
Iteration 8630 loss 0.8134551739430963 train RMSE 0.3728112439972875 Validation RMSE 8630 : 0.36278608135038937 max of weights 1.5070892735036525
Iteration 8640 loss 0.8015362919909393 train RMSE 0.36731511149162066 Validation RMSE 8640 : 0.3640678837855108 max of weights 1.5078839900635757
Iteration 8650 loss 0.7739877486777424 train RMSE 0.3546404671393079 Validation RMSE 8650 : 0.36057069918170986 max of weights 1.5071617627913168
Iteration 8660 loss 0.7774879691860219 train RMSE 0.3562533241558242 Validation RMSE 8660 : 0.3635235222364821 max of weights 1.509550761586469
Iteration 8670 loss 0.7472216925036024 train RMSE 0.34233477351373565 Validation RMSE 8670 : 0.3594824072783831 max of weights 1.5094813431683298
Iteration 8680 loss 0.7493071370599325 train RMSE 0.34329263028372287 Validation RMSE 8680 : 0.35862004478284265 max of weights 1.49930290380555
Iteration 8690 loss 0.7326879756513967 train RMSE 0.33564025777954404 Validation RMSE 8690 : 0.3604500972259768 max of weights 1.5044646909095596
Iteration 8700 loss 0.744395879773369 train RMSE 0.34103397988239864 Validation RMSE 8700 : 0.3592123693649133 max of weights 1.502133045736328
Iteration 8710 loss 0.7551816788005898 train RMSE 0.3459970350002662 Validation RMSE 8710 : 0.35784484709809206 max of weights 1.5021649865132956
Iteration 8720 loss 0.7626952265895917 train RMSE 0.3494471200627565 Validation RMSE 8720 : 0.3634503401634214 max of weights 1.5027727834035094
Iteration 8730 loss 0.7654348489288597 train RMSE 0.35071324322869385 Validation RMSE 8730 : 0.3603412921078943 max of weights 1.5090769162298812
Iteration 8740 loss 0.781368574873561 train RMSE 0.3580454047570669 Validation RMSE 8740 : 0.3609901143495606 max of weights 1.5181557633272713
Iteration 8750 loss 0.788569809751691 train RMSE 0.36135736357541004 Validation RMSE 8750 : 0.3616710382122973 max of weights 1.5243667791172764
Iteration 8760 loss 0.8016696730525193 train RMSE 0.36738499600910673 Validation RMSE 8760 : 0.36558618879308064 max of weights 1.5287785821915414
Iteration 8770 loss 0.7717558090271206 train RMSE 0.3536221496974712 Validation RMSE 8770 : 0.36416134783249055 max of weights 1.5323458674506087
Iteration 8780 loss 0.7443938091195881 train RMSE 0.34103250086577674 Validation RMSE 8780 : 0.3625512410337479 max of weights 1.5267725234215708
Iteration 8790 loss 0.7489481995394267 train RMSE 0.3431240494824281 Validation RMSE 8790 : 0.362778585803752 max of weights 1.5124026163691462
Iteration 8800 loss 0.7770553201366013 train RMSE 0.35605544275508566 Validation RMSE 8800 : 0.36250621906184866 max of weights 1.510691001665961
Iteration 8810 loss 0.7823988758611077 train RMSE 0.3585126429329153 Validation RMSE 8810 : 0.36281463646823126 max of weights 1.5161264251042368
Iteration 8820 loss 0.7803860755439507 train RMSE 0.3575858574075392 Validation RMSE 8820 : 0.36050126397438814 max of weights 1.5265962348360413
Iteration 8830 loss 0.7757784716837456 train RMSE 0.3554692357870578 Validation RMSE 8830 : 0.3613087548574542 max of weights 1.532031901189532
Iteration 8840 loss 0.7603185338659167 train RMSE 0.348351186875282 Validation RMSE 8840 : 0.36231579458464286 max of weights 1.5310659048918112
Iteration 8850 loss 0.7595751385812022 train RMSE 0.34800286709995837 Validation RMSE 8850 : 0.36209558062891123 max of weights 1.5289970452250667
Iteration 8860 loss 0.7637180946814546 train RMSE 0.3499139043180141 Validation RMSE 8860 : 0.36160151445998967 max of weights 1.5296284125514912
Iteration 8870 loss 0.7639944454413573 train RMSE 0.3500511867281 Validation RMSE 8870 : 0.3602361269292539 max of weights 1.5266509626313325
Iteration 8880 loss 0.7811055760246862 train RMSE 0.3579343181578925 Validation RMSE 8880 : 0.3638638394461097 max of weights 1.5287395175019007
Iteration 8890 loss 0.7874575523247339 train RMSE 0.36086158262046 Validation RMSE 8890 : 0.36242524485737104 max of weights 1.5299881627474332
Iteration 8900 loss 0.760111978867451 train RMSE 0.3482698625282125 Validation RMSE 8900 : 0.3630532286832549 max of weights 1.5307003186275934
Iteration 8910 loss 0.7591316087806296 train RMSE 0.3478113544146234 Validation RMSE 8910 : 0.36309548722689106 max of weights 1.5339850799769854
Iteration 8920 loss 0.7749349437508881 train RMSE 0.3550876635895621 Validation RMSE 8920 : 0.361179620228777 max of weights 1.5313765795503014
Iteration 8930 loss 0.7758080212875073 train RMSE 0.3554935681186528 Validation RMSE 8930 : 0.3616234262109259 max of weights 1.5347132505507084
Iteration 8940 loss 0.7937639949332925 train RMSE 0.36375988692296973 Validation RMSE 8940 : 0.36315316739011394 max of weights 1.5327629934695115
Iteration 8950 loss 0.7949755333458046 train RMSE 0.3643123655817725 Validation RMSE 8950 : 0.36072830298041364 max of weights 1.5353827145051315
Iteration 8960 loss 0.8038563173550993 train RMSE 0.36839551568460355 Validation RMSE 8960 : 0.36412652515731714 max of weights 1.5390771440164785
Iteration 8970 loss 0.7836659193203136 train RMSE 0.3591066759751419 Validation RMSE 8970 : 0.3660174260678528 max of weights 1.5444057041752048
Iteration 8980 loss 0.765359037691211 train RMSE 0.3506759948752806 Validation RMSE 8980 : 0.3682115878494221 max of weights 1.5404416076878065
Iteration 8990 loss 0.759500740400061 train RMSE 0.34797479153793365 Validation RMSE 8990 : 0.36510010771809215 max of weights 1.5361453687093143
Iteration 9000 loss 0.7673588960606551 train RMSE 0.3515844123199815 Validation RMSE 9000 : 0.36150733840839144 max of weights 1.5366095302518459
Iteration 9010 loss 0.778509155867976 train RMSE 0.35670203046937354 Validation RMSE 9010 : 0.35983140280961573 max of weights 1.5385894015366788
Iteration 9020 loss 0.800087358456067 train RMSE 0.36661997783027106 Validation RMSE 9020 : 0.36140359631294094 max of weights 1.5452616103490824
Iteration 9030 loss 0.817873878702044 train RMSE 0.374798585242063 Validation RMSE 9030 : 0.364587621898096 max of weights 1.5497156361197941
Iteration 9040 loss 0.8246990912312101 train RMSE 0.3779451581730575 Validation RMSE 9040 : 0.36601429442161487 max of weights 1.5487237005360759
Iteration 9050 loss 0.8130579051596731 train RMSE 0.37259239949849227 Validation RMSE 9050 : 0.36324299506714064 max of weights 1.5570236626970329
Iteration 9060 loss 0.8029368770609934 train RMSE 0.36793634852059587 Validation RMSE 9060 : 0.3636572459318279 max of weights 1.5596039721158057
Iteration 9070 loss 0.8017127572676461 train RMSE 0.367372542957812 Validation RMSE 9070 : 0.36327331968241694 max of weights 1.558028522934933
Iteration 9080 loss 0.7836670219920837 train RMSE 0.35906965852142114 Validation RMSE 9080 : 0.3612406702460378 max of weights 1.552439005566411
Iteration 9090 loss 0.763550085320534 train RMSE 0.3498169847725246 Validation RMSE 9090 : 0.36010114777877544 max of weights 1.550205533123774
Iteration 9100 loss 0.7519588641387769 train RMSE 0.344484813958365 Validation RMSE 9100 : 0.3640031751365428 max of weights 1.5471932087037843
Iteration 9110 loss 0.7828565589740287 train RMSE 0.35869854282182306 Validation RMSE 9110 : 0.3661684999971408 max of weights 1.5482275634587679
Iteration 9120 loss 0.7846482172830243 train RMSE 0.3595202640528422 Validation RMSE 9120 : 0.3630139230987125 max of weights 1.5417292398229676
Iteration 9130 loss 0.7634166717612403 train RMSE 0.3497540369006071 Validation RMSE 9130 : 0.35984931317341745 max of weights 1.5396453104427434
Iteration 9140 loss 0.7776633078457402 train RMSE 0.3563073587491845 Validation RMSE 9140 : 0.3616584061912086 max of weights 1.5373002059591188
Iteration 9150 loss 0.7579517695466655 train RMSE 0.34723410418966394 Validation RMSE 9150 : 0.35897262692263593 max of weights 1.5358655041135905
Iteration 9160 loss 0.7596106776377498 train RMSE 0.347997296767529 Validation RMSE 9160 : 0.36177998744370765 max of weights 1.5310224166031996
Iteration 9170 loss 0.7632532438451265 train RMSE 0.34967209103575136 Validation RMSE 9170 : 0.36172116534960674 max of weights 1.5246907032574972
Iteration 9180 loss 0.7651113838524444 train RMSE 0.3505217960684465 Validation RMSE 9180 : 0.36054859887924784 max of weights 1.523590596037334
Iteration 9190 loss 0.7597789869669593 train RMSE 0.3480625903368043 Validation RMSE 9190 : 0.3602557879697458 max of weights 1.517736228932499
Iteration 9200 loss 0.7963037641123835 train RMSE 0.36486298675289314 Validation RMSE 9200 : 0.3624057138766752 max of weights 1.513114991210533
Iteration 9210 loss 0.7831365878579332 train RMSE 0.35880583153562834 Validation RMSE 9210 : 0.36055598278916823 max of weights 1.5143163253207617
Iteration 9220 loss 0.7676170040256658 train RMSE 0.3516641081141206 Validation RMSE 9220 : 0.35996627879582566 max of weights 1.517878395798653
Iteration 9230 loss 0.7870965580139254 train RMSE 0.36063222536907796 Validation RMSE 9230 : 0.35973411209150724 max of weights 1.5286966087912492
Iteration 9240 loss 0.7923802139829291 train RMSE 0.3630571746821592 Validation RMSE 9240 : 0.3620735767245862 max of weights 1.536075614271324
Iteration 9250 loss 0.8055752323570394 train RMSE 0.36913011648894184 Validation RMSE 9250 : 0.3596508828440227 max of weights 1.5395131759884932
Iteration 9260 loss 0.8179242163601002 train RMSE 0.37481484216687144 Validation RMSE 9260 : 0.3598497414870689 max of weights 1.5356188251240632
Iteration 9270 loss 0.813973044553988 train RMSE 0.37299530235978234 Validation RMSE 9270 : 0.36072535196761557 max of weights 1.542703502546208
Iteration 9280 loss 0.7976625959464412 train RMSE 0.36548750698793986 Validation RMSE 9280 : 0.3613535961246182 max of weights 1.5494103728533641
Iteration 9290 loss 0.7856484316087726 train RMSE 0.35997365491814864 Validation RMSE 9290 : 0.35825101930620346 max of weights 1.550260995895404
Iteration 9300 loss 0.8095976439044131 train RMSE 0.37099850545455354 Validation RMSE 9300 : 0.36505493921240156 max of weights 1.5522209875364676
Iteration 9310 loss 0.8159738946654613 train RMSE 0.37393274819932526 Validation RMSE 9310 : 0.3646174351615155 max of weights 1.5523487329441723
Iteration 9320 loss 0.7923514407957777 train RMSE 0.3630591795716395 Validation RMSE 9320 : 0.3613356958960306 max of weights 1.552534641668952
Iteration 9330 loss 0.781202625517504 train RMSE 0.3579265330604541 Validation RMSE 9330 : 0.3620838178131004 max of weights 1.5563011718477857
Iteration 9340 loss 0.7949479862488684 train RMSE 0.3642578729686254 Validation RMSE 9340 : 0.36060117525350815 max of weights 1.5666114364380024
Iteration 9350 loss 0.8124670260219702 train RMSE 0.37232612873037846 Validation RMSE 9350 : 0.3638548577776442 max of weights 1.5695234396253923
Iteration 9360 loss 0.7904147754604609 train RMSE 0.3621774012091062 Validation RMSE 9360 : 0.35988499366947285 max of weights 1.5756351516118408
Iteration 9370 loss 0.8046581888422502 train RMSE 0.3687265259258228 Validation RMSE 9370 : 0.36049558330097004 max of weights 1.5767215416160982
Iteration 9380 loss 0.8415605936136785 train RMSE 0.3857004149317827 Validation RMSE 9380 : 0.3713648727745526 max of weights 1.574575921651306
Iteration 9390 loss 0.8085717108486227 train RMSE 0.37051370092732716 Validation RMSE 9390 : 0.373396710903134 max of weights 1.573013280427628
Iteration 9400 loss 0.8053829393843802 train RMSE 0.36905493411546203 Validation RMSE 9400 : 0.3606664169130764 max of weights 1.5865024163795283
Iteration 9410 loss 0.8092577276934607 train RMSE 0.3708447122579116 Validation RMSE 9410 : 0.3664582682886427 max of weights 1.591974651619213
Iteration 9420 loss 0.7838366256002727 train RMSE 0.35914839736946286 Validation RMSE 9420 : 0.360880958973225 max of weights 1.5957656986287403
Iteration 9430 loss 0.7765259651339393 train RMSE 0.3557826835386067 Validation RMSE 9430 : 0.36007932433067785 max of weights 1.5938747046313166
Iteration 9440 loss 0.77278097854824 train RMSE 0.35405655238990863 Validation RMSE 9440 : 0.3593040411732692 max of weights 1.5937795950598386
Iteration 9450 loss 0.7806091189762899 train RMSE 0.35765609854578134 Validation RMSE 9450 : 0.35906451537355205 max of weights 1.5927178807068558
Iteration 9460 loss 0.7601317846260781 train RMSE 0.3482319643483142 Validation RMSE 9460 : 0.35714858931877486 max of weights 1.58857273254926
Iteration 9470 loss 0.7806932748901929 train RMSE 0.3576881564081875 Validation RMSE 9470 : 0.3598689964451664 max of weights 1.5863335042631184
Iteration 9480 loss 0.7682461923480491 train RMSE 0.35196210419923646 Validation RMSE 9480 : 0.3601031362265048 max of weights 1.585911169244577
Iteration 9490 loss 0.7593870270793833 train RMSE 0.3478821028641266 Validation RMSE 9490 : 0.3585355966250495 max of weights 1.583239764029718
Iteration 9500 loss 0.7683198440681723 train RMSE 0.3519818151057344 Validation RMSE 9500 : 0.3587295086701784 max of weights 1.5750810705449643
Iteration 9510 loss 0.8076058779170114 train RMSE 0.3700591491361962 Validation RMSE 9510 : 0.36348481813576905 max of weights 1.5748225551812307
Iteration 9520 loss 0.7850170468446457 train RMSE 0.3596660352016398 Validation RMSE 9520 : 0.3583114956275173 max of weights 1.5698588490226668
Iteration 9530 loss 0.7606789076845812 train RMSE 0.348464589766165 Validation RMSE 9530 : 0.3554209440046397 max of weights 1.5666727607726554
Iteration 9540 loss 0.7636018237827317 train RMSE 0.34980494391037503 Validation RMSE 9540 : 0.3565124310343223 max of weights 1.5628624793041421
Iteration 9550 loss 0.7651250743769342 train RMSE 0.3504956866142307 Validation RMSE 9550 : 0.360355613919212 max of weights 1.560970925939098
Iteration 9560 loss 0.7604669574325108 train RMSE 0.34835017570326066 Validation RMSE 9560 : 0.3563964026920813 max of weights 1.5675630460131855
Iteration 9570 loss 0.754125922761074 train RMSE 0.3454310223782849 Validation RMSE 9570 : 0.35615345595605397 max of weights 1.5731311737761013
Iteration 9580 loss 0.7378482846396921 train RMSE 0.33793735707281 Validation RMSE 9580 : 0.356676273636682 max of weights 1.5716559939407493
Iteration 9590 loss 0.7543828372470787 train RMSE 0.34553775110765383 Validation RMSE 9590 : 0.35910090163983027 max of weights 1.5652583414906616
Iteration 9600 loss 0.7887160064434614 train RMSE 0.36132920834752813 Validation RMSE 9600 : 0.36004062719549496 max of weights 1.56051881963483
Iteration 9610 loss 0.798837673498365 train RMSE 0.3659883810227746 Validation RMSE 9610 : 0.35894878840014655 max of weights 1.5617904374550888
Iteration 9620 loss 0.7789893279777833 train RMSE 0.35686407937882736 Validation RMSE 9620 : 0.3558106014649025 max of weights 1.562602841906567
Iteration 9630 loss 0.7795961123785559 train RMSE 0.35714725257487034 Validation RMSE 9630 : 0.3609260395313586 max of weights 1.5621658824833728
Iteration 9640 loss 0.7793613108506279 train RMSE 0.3570344448895999 Validation RMSE 9640 : 0.36097801401798874 max of weights 1.563099055914742
Iteration 9650 loss 0.7750407509323044 train RMSE 0.3550492992196465 Validation RMSE 9650 : 0.3593343896712772 max of weights 1.5608852271083002
Iteration 9660 loss 0.7729883636753001 train RMSE 0.3541158593336476 Validation RMSE 9660 : 0.3582719294503325 max of weights 1.5646494694812874
Iteration 9670 loss 0.7741729842021562 train RMSE 0.35466538511749485 Validation RMSE 9670 : 0.35873223550198235 max of weights 1.567705078363304
Iteration 9680 loss 0.7946091479819823 train RMSE 0.364064928655056 Validation RMSE 9680 : 0.36357221277479895 max of weights 1.5653443923173271
Iteration 9690 loss 0.780729012550376 train RMSE 0.35767119892833305 Validation RMSE 9690 : 0.35782687776884 max of weights 1.5691869846972548
Iteration 9700 loss 0.7806749607935419 train RMSE 0.35764301363516016 Validation RMSE 9700 : 0.35698018222799827 max of weights 1.5698567789607047
Iteration 9710 loss 0.7757365725388269 train RMSE 0.35537407705644003 Validation RMSE 9710 : 0.3585705230954516 max of weights 1.5699010572710472
Iteration 9720 loss 0.7509026699249828 train RMSE 0.34394267943647844 Validation RMSE 9720 : 0.36233986079884845 max of weights 1.5693546088959949
Iteration 9730 loss 0.769963795877761 train RMSE 0.35271409588701447 Validation RMSE 9730 : 0.36139627281930925 max of weights 1.5663207302394502
Iteration 9740 loss 0.7705266434043126 train RMSE 0.35298018769927486 Validation RMSE 9740 : 0.36158719285308866 max of weights 1.5637274652369044
Iteration 9750 loss 0.7509905053026946 train RMSE 0.3439959380433069 Validation RMSE 9750 : 0.3608968753915948 max of weights 1.5593235080306407
Iteration 9760 loss 0.7503268192862782 train RMSE 0.34369492191419343 Validation RMSE 9760 : 0.36335266490557994 max of weights 1.5537841115691846
Iteration 9770 loss 0.7378324421305125 train RMSE 0.33794085855317296 Validation RMSE 9770 : 0.362825939904913 max of weights 1.551565454772411
Iteration 9780 loss 0.754299790016971 train RMSE 0.3455060626220674 Validation RMSE 9780 : 0.3614541116275307 max of weights 1.5550386401177119
Iteration 9790 loss 0.7818297861803674 train RMSE 0.358170623501766 Validation RMSE 9790 : 0.35827731584608863 max of weights 1.5585953238408392
Iteration 9800 loss 0.8083055645543579 train RMSE 0.37035345204202447 Validation RMSE 9800 : 0.36172875531551707 max of weights 1.5678319797166536
Iteration 9810 loss 0.7855353104339556 train RMSE 0.35986535266145026 Validation RMSE 9810 : 0.3622061801661421 max of weights 1.5734697612442514
Iteration 9820 loss 0.7943267260310671 train RMSE 0.36390828709925577 Validation RMSE 9820 : 0.3645603217929035 max of weights 1.563940671256139
Iteration 9830 loss 0.7876997758905933 train RMSE 0.3608649974254663 Validation RMSE 9830 : 0.3602786923903458 max of weights 1.5592576385878663
Iteration 9840 loss 0.7820902133252818 train RMSE 0.35828243688094313 Validation RMSE 9840 : 0.35938488278515607 max of weights 1.5577542827097803
Iteration 9850 loss 0.7899236567360688 train RMSE 0.36188346328587456 Validation RMSE 9850 : 0.362800665872475 max of weights 1.5544719051039586
Iteration 9860 loss 0.77639355757035 train RMSE 0.3556493286601969 Validation RMSE 9860 : 0.35837780985170775 max of weights 1.5570511724708864
Iteration 9870 loss 0.7622822335177414 train RMSE 0.3491549686256284 Validation RMSE 9870 : 0.3581870918171557 max of weights 1.5598533807147312
Iteration 9880 loss 0.7801644326837576 train RMSE 0.3573930856180376 Validation RMSE 9880 : 0.36179611596770817 max of weights 1.5676126854462509
Iteration 9890 loss 0.7727741460666517 train RMSE 0.35399201638390576 Validation RMSE 9890 : 0.35972217067563256 max of weights 1.5676604132902352
Iteration 9900 loss 0.7569908242100841 train RMSE 0.3467239883309686 Validation RMSE 9900 : 0.3576698318037513 max of weights 1.5739442880379282
Iteration 9910 loss 0.7623727871434954 train RMSE 0.3491943609159344 Validation RMSE 9910 : 0.35661540250650053 max of weights 1.578522860165065
Iteration 9920 loss 0.749711664295972 train RMSE 0.3433599783197566 Validation RMSE 9920 : 0.364883032327652 max of weights 1.5762755433924431
Iteration 9930 loss 0.7724693913602744 train RMSE 0.35382627640042963 Validation RMSE 9930 : 0.3624106402514731 max of weights 1.5802455708600915
Iteration 9940 loss 0.7756018565791818 train RMSE 0.3552629538011384 Validation RMSE 9940 : 0.362339194394909 max of weights 1.5825276033971225
Iteration 9950 loss 0.7627526595141382 train RMSE 0.34935256776213186 Validation RMSE 9950 : 0.3621513913664254 max of weights 1.5842669578708184
Iteration 9960 loss 0.7559852474629499 train RMSE 0.3462318953316022 Validation RMSE 9960 : 0.36010940313962797 max of weights 1.5799947425667624
Iteration 9970 loss 0.7496994615214766 train RMSE 0.34333066047754074 Validation RMSE 9970 : 0.366028119625222 max of weights 1.577860715766066
Iteration 9980 loss 0.7651364135206608 train RMSE 0.35043476526195355 Validation RMSE 9980 : 0.35740577608569807 max of weights 1.5796176806320008
Iteration 9990 loss 0.8146768545487092 train RMSE 0.37322686989396975 Validation RMSE 9990 : 0.36771108086193066 max of weights 1.587777964940705
Iteration 10000 loss 0.7956579841252551 train RMSE 0.3644796897811241 Validation RMSE 10000 : 0.3610763762905147 max of weights 1.586895962391504
Iteration 10010 loss 0.7707585363597466 train RMSE 0.3530262696113529 Validation RMSE 10010 : 0.3593056058729386 max of weights 1.5897104786955236
Iteration 10020 loss 0.7644439671499389 train RMSE 0.35012061974496256 Validation RMSE 10020 : 0.36043017465486255 max of weights 1.5923434243532113
Iteration 10030 loss 0.7924492758055078 train RMSE 0.36301903637771504 Validation RMSE 10030 : 0.36052384836860113 max of weights 1.5949123731125956
Iteration 10040 loss 0.7848652341110189 train RMSE 0.35952907195832456 Validation RMSE 10040 : 0.3624350747973903 max of weights 1.599338924203601
Iteration 10050 loss 0.7715509031177076 train RMSE 0.35339889880095976 Validation RMSE 10050 : 0.3567998456820843 max of weights 1.5954486884704238
Iteration 10060 loss 0.7888485711213706 train RMSE 0.36134971262272414 Validation RMSE 10060 : 0.35849921208505653 max of weights 1.5922014139827287
Iteration 10070 loss 0.8064723419794549 train RMSE 0.36945585203875403 Validation RMSE 10070 : 0.35984266538246196 max of weights 1.588404276941403
Iteration 10080 loss 0.8006086438704323 train RMSE 0.3667474043851716 Validation RMSE 10080 : 0.36153165663668546 max of weights 1.584979670020537
Iteration 10090 loss 0.7881597324527388 train RMSE 0.36101089969840006 Validation RMSE 10090 : 0.36255642420239265 max of weights 1.5860216904577664
Iteration 10100 loss 0.767933840578077 train RMSE 0.35170759326042017 Validation RMSE 10100 : 0.36113782001386424 max of weights 1.5852172885884097
Iteration 10110 loss 0.7649162674142208 train RMSE 0.35032615683310453 Validation RMSE 10110 : 0.36104573690538666 max of weights 1.584429072621943
Iteration 10120 loss 0.7372555421456121 train RMSE 0.3376065226229689 Validation RMSE 10120 : 0.35796107751845213 max of weights 1.5792224373335553
Iteration 10130 loss 0.7471187152697921 train RMSE 0.34213751641114 Validation RMSE 10130 : 0.3583315675811854 max of weights 1.5688219872646991
Iteration 10140 loss 0.729937140830868 train RMSE 0.3342338489149802 Validation RMSE 10140 : 0.3575933847511224 max of weights 1.576100790067999
Iteration 10150 loss 0.7459243775624417 train RMSE 0.3415960228360094 Validation RMSE 10150 : 0.3585387209574469 max of weights 1.5806325880339447
Iteration 10160 loss 0.7426211675923272 train RMSE 0.34007489306527755 Validation RMSE 10160 : 0.3573659667814402 max of weights 1.5799729891362078
Iteration 10170 loss 0.7531862010939891 train RMSE 0.3449330749691773 Validation RMSE 10170 : 0.36184582630009726 max of weights 1.588878886886243
Iteration 10180 loss 0.7586884690060046 train RMSE 0.3474718439285458 Validation RMSE 10180 : 0.3586613241795198 max of weights 1.5905489569148068
Iteration 10190 loss 0.7757319909686684 train RMSE 0.35531373562038626 Validation RMSE 10190 : 0.3597945840259451 max of weights 1.5977226107629614
Iteration 10200 loss 0.7856523517410634 train RMSE 0.35987464616184345 Validation RMSE 10200 : 0.3618533291177699 max of weights 1.5995979277289483
Iteration 10210 loss 0.7816116047378039 train RMSE 0.35801692761015613 Validation RMSE 10210 : 0.3635488652193522 max of weights 1.593967654592699
Iteration 10220 loss 0.7490465833242733 train RMSE 0.3430333034476389 Validation RMSE 10220 : 0.36243636728452194 max of weights 1.5873552862160727
Iteration 10230 loss 0.7322307407330548 train RMSE 0.33529300673737755 Validation RMSE 10230 : 0.36015876787545387 max of weights 1.575275370375211
Iteration 10240 loss 0.7492300980619407 train RMSE 0.34310689142719697 Validation RMSE 10240 : 0.36447264843144034 max of weights 1.567248823564459
Iteration 10250 loss 0.7800236515667247 train RMSE 0.3572774925259735 Validation RMSE 10250 : 0.36405057416292597 max of weights 1.572113984641207
Iteration 10260 loss 0.7827832023684742 train RMSE 0.35854573818474417 Validation RMSE 10260 : 0.365075612286601 max of weights 1.5865963392085676
Iteration 10270 loss 0.7728755520206508 train RMSE 0.3539870549129573 Validation RMSE 10270 : 0.36070567692677374 max of weights 1.6014528857797297
Iteration 10280 loss 0.7706596103376783 train RMSE 0.35297390982347854 Validation RMSE 10280 : 0.3629942549825743 max of weights 1.6095967315447497
Iteration 10290 loss 0.7523502604959176 train RMSE 0.34454175207831433 Validation RMSE 10290 : 0.36220886442896105 max of weights 1.610817648112043
Iteration 10300 loss 0.759053778524203 train RMSE 0.3476234967050175 Validation RMSE 10300 : 0.3647506623790065 max of weights 1.6096876178181991
Iteration 10310 loss 0.7572516659279371 train RMSE 0.3468033006779603 Validation RMSE 10310 : 0.3597968839029914 max of weights 1.6073705710131017
Iteration 10320 loss 0.7671569635126678 train RMSE 0.3513715551384023 Validation RMSE 10320 : 0.3611170677979206 max of weights 1.6031544997887133
Iteration 10330 loss 0.7851074884171066 train RMSE 0.35963962329353394 Validation RMSE 10330 : 0.36354892392456856 max of weights 1.6106987528454455
Iteration 10340 loss 0.7708379510493913 train RMSE 0.35307115095899755 Validation RMSE 10340 : 0.3595432404346512 max of weights 1.6108047596636415
Iteration 10350 loss 0.7502202409625367 train RMSE 0.3435746912281875 Validation RMSE 10350 : 0.3625043392662807 max of weights 1.6117939253526634
Iteration 10360 loss 0.7643464884966339 train RMSE 0.3500756263615771 Validation RMSE 10360 : 0.3615463807809112 max of weights 1.6093113215024393
Iteration 10370 loss 0.7755745831916505 train RMSE 0.35524598921845396 Validation RMSE 10370 : 0.3599003928669485 max of weights 1.6128865909374264
Iteration 10380 loss 0.7773059354904368 train RMSE 0.35604425941796664 Validation RMSE 10380 : 0.3600916022028931 max of weights 1.6179845768699077
Iteration 10390 loss 0.7880681461331013 train RMSE 0.36099650327666605 Validation RMSE 10390 : 0.3637963889225769 max of weights 1.617456832047878
Iteration 10400 loss 0.7891752216825124 train RMSE 0.3615015132398232 Validation RMSE 10400 : 0.3582616243455215 max of weights 1.6191689344175386
Iteration 10410 loss 0.7977331770777978 train RMSE 0.3654365872100946 Validation RMSE 10410 : 0.36378118822846106 max of weights 1.6221286899881686
Iteration 10420 loss 0.7731708951960918 train RMSE 0.35413554490714105 Validation RMSE 10420 : 0.361819581565817 max of weights 1.6233206861967429
Iteration 10430 loss 0.7636397108065165 train RMSE 0.34974047555979104 Validation RMSE 10430 : 0.36444548790508374 max of weights 1.6218862932770406
Iteration 10440 loss 0.7577579875740278 train RMSE 0.347029523826407 Validation RMSE 10440 : 0.3601908166434258 max of weights 1.6231975155625051
Iteration 10450 loss 0.7618420931070321 train RMSE 0.34889982210703147 Validation RMSE 10450 : 0.3599145478983857 max of weights 1.6242097697252227
Iteration 10460 loss 0.7789044960750497 train RMSE 0.35674195649080853 Validation RMSE 10460 : 0.3584504374332671 max of weights 1.625990386312854
Iteration 10470 loss 0.7964650277473604 train RMSE 0.3648122673794797 Validation RMSE 10470 : 0.3586685167811918 max of weights 1.6300911772718787
Iteration 10480 loss 0.812752704840697 train RMSE 0.37230443654767575 Validation RMSE 10480 : 0.36357111050264107 max of weights 1.6295748553905274
Iteration 10490 loss 0.8066886530502277 train RMSE 0.369516092674175 Validation RMSE 10490 : 0.3641437371938035 max of weights 1.6304433773420437
Iteration 10500 loss 0.799255650883913 train RMSE 0.36609684565306017 Validation RMSE 10500 : 0.36248364858459853 max of weights 1.6350514610963744
Iteration 10510 loss 0.7883497367688767 train RMSE 0.3610799153331268 Validation RMSE 10510 : 0.3639673454711794 max of weights 1.6356096131613045
Iteration 10520 loss 0.7811435959697478 train RMSE 0.3577616883826304 Validation RMSE 10520 : 0.3624790617411772 max of weights 1.6326200724701703
Iteration 10530 loss 0.7625471206679395 train RMSE 0.34920842820854375 Validation RMSE 10530 : 0.3600590800848577 max of weights 1.6326222362085479
Iteration 10540 loss 0.7334533226055093 train RMSE 0.335825093471246 Validation RMSE 10540 : 0.3599128691078695 max of weights 1.6306735568687885
Iteration 10550 loss 0.7452047802620139 train RMSE 0.3412336462307634 Validation RMSE 10550 : 0.3620815949549994 max of weights 1.6294440593034603
Iteration 10560 loss 0.7804115746931417 train RMSE 0.3574288448707899 Validation RMSE 10560 : 0.3675625726227964 max of weights 1.628597623252908
Iteration 10570 loss 0.7660855110889567 train RMSE 0.350837998652368 Validation RMSE 10570 : 0.3594946592184381 max of weights 1.62307473905494
Iteration 10580 loss 0.7587527188789159 train RMSE 0.347465858552852 Validation RMSE 10580 : 0.36016715876667543 max of weights 1.6212770393679155
Iteration 10590 loss 0.7652666088053184 train RMSE 0.35045950774354756 Validation RMSE 10590 : 0.36022728056804765 max of weights 1.6168099656404218
Iteration 10600 loss 0.7505259458772215 train RMSE 0.3436762577965373 Validation RMSE 10600 : 0.359734231542916 max of weights 1.614312840384539
Iteration 10610 loss 0.749885272722295 train RMSE 0.34338442603215164 Validation RMSE 10610 : 0.36086871528576153 max of weights 1.6087444311489387
Iteration 10620 loss 0.7505062206983689 train RMSE 0.3436688834954176 Validation RMSE 10620 : 0.3605155644892054 max of weights 1.6059189918391288
Iteration 10630 loss 0.7538325435633059 train RMSE 0.3451971431281731 Validation RMSE 10630 : 0.359214323043196 max of weights 1.6049223153302548
Iteration 10640 loss 0.7603999549046648 train RMSE 0.3482116973281027 Validation RMSE 10640 : 0.35919353558306405 max of weights 1.6030454041583193
Iteration 10650 loss 0.7961080012062887 train RMSE 0.3646385067487542 Validation RMSE 10650 : 0.36241868569922864 max of weights 1.6003991929395267
Iteration 10660 loss 0.7666051438447158 train RMSE 0.35106131458948364 Validation RMSE 10660 : 0.36036924544584026 max of weights 1.6019521147622164
Iteration 10670 loss 0.7605491994356068 train RMSE 0.34827566699456175 Validation RMSE 10670 : 0.35766775903781106 max of weights 1.60572334143767
Iteration 10680 loss 0.7823724528268609 train RMSE 0.3583203406390113 Validation RMSE 10680 : 0.36030126171636384 max of weights 1.6154404913412301
Iteration 10690 loss 0.7861096216039345 train RMSE 0.36003383840997205 Validation RMSE 10690 : 0.3595348946067975 max of weights 1.6231101550872769
Iteration 10700 loss 0.7970110268786572 train RMSE 0.36505713396942074 Validation RMSE 10700 : 0.3581197850760976 max of weights 1.6225587307134237
Iteration 10710 loss 0.8101557003827101 train RMSE 0.3711078570606515 Validation RMSE 10710 : 0.3594604277570673 max of weights 1.627294530246121
Iteration 10720 loss 0.7933362752009776 train RMSE 0.36336428672010956 Validation RMSE 10720 : 0.3583475394803235 max of weights 1.6401480373640924
Iteration 10730 loss 0.7738570812081276 train RMSE 0.3544035524406089 Validation RMSE 10730 : 0.3585396140307989 max of weights 1.6449692981705015
Iteration 10740 loss 0.7786422252276988 train RMSE 0.35661787909040515 Validation RMSE 10740 : 0.3576391341311235 max of weights 1.646223472268216
Iteration 10750 loss 0.8242596818087806 train RMSE 0.3776096515579931 Validation RMSE 10750 : 0.3714970972548897 max of weights 1.6435915236827017
Iteration 10760 loss 0.801607938113367 train RMSE 0.3671863049045101 Validation RMSE 10760 : 0.3616351110451559 max of weights 1.646077410529434
Iteration 10770 loss 0.788770709211158 train RMSE 0.3612725520423765 Validation RMSE 10770 : 0.3621449859310728 max of weights 1.6472343740289541
Iteration 10780 loss 0.7788532981634628 train RMSE 0.3567095063952623 Validation RMSE 10780 : 0.3614363439799734 max of weights 1.656929916066073
Iteration 10790 loss 0.7986769032230205 train RMSE 0.3658365207545151 Validation RMSE 10790 : 0.3605534775275605 max of weights 1.6697315703755162
Iteration 10800 loss 0.8055008974640384 train RMSE 0.36897906298180405 Validation RMSE 10800 : 0.36033186268820333 max of weights 1.6765820326333862
Iteration 10810 loss 0.7831239250886082 train RMSE 0.3586800581671605 Validation RMSE 10810 : 0.3573202205083299 max of weights 1.685352421964915
Iteration 10820 loss 0.8133139713414193 train RMSE 0.3725660528546766 Validation RMSE 10820 : 0.3614896513221598 max of weights 1.6858609094796357
Iteration 10830 loss 0.8182557202661577 train RMSE 0.37483235228469186 Validation RMSE 10830 : 0.3673843844044672 max of weights 1.687369568859669
Iteration 10840 loss 0.7797860635422358 train RMSE 0.3571244428733967 Validation RMSE 10840 : 0.36242733619389633 max of weights 1.688558418752851
Iteration 10850 loss 0.8001079164949345 train RMSE 0.3664816190110346 Validation RMSE 10850 : 0.3595238383205359 max of weights 1.7012562601782588
Iteration 10860 loss 0.7847238683601991 train RMSE 0.3594092289327578 Validation RMSE 10860 : 0.36223095397109 max of weights 1.7048389216014403
Iteration 10870 loss 0.7601219179134022 train RMSE 0.34808767631813964 Validation RMSE 10870 : 0.35696660347180453 max of weights 1.7086242848031872
Iteration 10880 loss 0.7683463843279573 train RMSE 0.35186686603768796 Validation RMSE 10880 : 0.35796713220650145 max of weights 1.708829445491467
Iteration 10890 loss 0.7687450652468518 train RMSE 0.3520521149509567 Validation RMSE 10890 : 0.3554292310923486 max of weights 1.7111943262110598
Iteration 10900 loss 0.7589101894958259 train RMSE 0.3475218278365936 Validation RMSE 10900 : 0.35531181761524494 max of weights 1.7109196805918228
Iteration 10910 loss 0.7587708354890238 train RMSE 0.3474565778644818 Validation RMSE 10910 : 0.3559594210762586 max of weights 1.7070668039324317
Iteration 10920 loss 0.7744092587854364 train RMSE 0.3546494426566001 Validation RMSE 10920 : 0.3586258804227559 max of weights 1.7039327600803125
Iteration 10930 loss 0.7709570377450973 train RMSE 0.3530614367196765 Validation RMSE 10930 : 0.3599105820327733 max of weights 1.7012533181755984
Iteration 10940 loss 0.7570519849256476 train RMSE 0.34665740904807746 Validation RMSE 10940 : 0.35600948955963574 max of weights 1.698117139666061
Iteration 10950 loss 0.7765815551572753 train RMSE 0.35563491355553667 Validation RMSE 10950 : 0.35943979804474974 max of weights 1.6939921225535814
Iteration 10960 loss 0.7934078532778625 train RMSE 0.3633793990270039 Validation RMSE 10960 : 0.36022746702417774 max of weights 1.6951754585818444
Iteration 10970 loss 0.7515958403180406 train RMSE 0.3441361396769112 Validation RMSE 10970 : 0.3566517684356824 max of weights 1.689588205069808
Iteration 10980 loss 0.7540860367298344 train RMSE 0.34528397584995485 Validation RMSE 10980 : 0.3561448590889221 max of weights 1.687099445562169
Iteration 10990 loss 0.7525832197475445 train RMSE 0.344587825306294 Validation RMSE 10990 : 0.35654684351266563 max of weights 1.6825199063846148
Iteration 11000 loss 0.752162818704023 train RMSE 0.34438870882932693 Validation RMSE 11000 : 0.35891216294858524 max of weights 1.6817165987763225
Iteration 11010 loss 0.7573570390880519 train RMSE 0.3467757361086234 Validation RMSE 11010 : 0.3558433303451325 max of weights 1.6887871561444836
Iteration 11020 loss 0.7399592961079656 train RMSE 0.3387695298146227 Validation RMSE 11020 : 0.3544937874518594 max of weights 1.6915630707967237
Iteration 11030 loss 0.7306988609195622 train RMSE 0.33450560377618926 Validation RMSE 11030 : 0.3596675031011805 max of weights 1.6858305221510363
Iteration 11040 loss 0.7543444256589568 train RMSE 0.3453770375419037 Validation RMSE 11040 : 0.3564630838459224 max of weights 1.6813493244815725
Iteration 11050 loss 0.7889654305494266 train RMSE 0.361296442615735 Validation RMSE 11050 : 0.3624254917120948 max of weights 1.6793671500678313
Iteration 11060 loss 0.7950767423706301 train RMSE 0.3641126072849192 Validation RMSE 11060 : 0.3586421330178098 max of weights 1.6833724895100044
Iteration 11070 loss 0.7620784111432265 train RMSE 0.34893889592587163 Validation RMSE 11070 : 0.3553302696170473 max of weights 1.6844315677032395
Iteration 11080 loss 0.7873775178270033 train RMSE 0.36058195519493064 Validation RMSE 11080 : 0.3625325123136575 max of weights 1.6864744001333665
Iteration 11090 loss 0.7727330870066247 train RMSE 0.35383821536327115 Validation RMSE 11090 : 0.3591310863533082 max of weights 1.6881060870967879
Iteration 11100 loss 0.762445774749137 train RMSE 0.34910961428912823 Validation RMSE 11100 : 0.35702682734914565 max of weights 1.683650357701253
Iteration 11110 loss 0.7673205680929229 train RMSE 0.3513611464475361 Validation RMSE 11110 : 0.3568075716221754 max of weights 1.6862736792660127
Iteration 11120 loss 0.7711579165460591 train RMSE 0.35313028844273714 Validation RMSE 11120 : 0.3561127789488878 max of weights 1.6850026553867499
Iteration 11130 loss 0.8015203545790884 train RMSE 0.36709858146401403 Validation RMSE 11130 : 0.3638234873408889 max of weights 1.6792041937929643
Iteration 11140 loss 0.7813442675257365 train RMSE 0.3578099352599833 Validation RMSE 11140 : 0.3557715131379838 max of weights 1.6784215202015142
Iteration 11150 loss 0.7787729624120038 train RMSE 0.35662760887062933 Validation RMSE 11150 : 0.3558220233575311 max of weights 1.6793100103826124
Iteration 11160 loss 0.7654797877062268 train RMSE 0.3505122092725237 Validation RMSE 11160 : 0.35706803942074095 max of weights 1.6798868223404075
Iteration 11170 loss 0.7407500169607711 train RMSE 0.33912924322568816 Validation RMSE 11170 : 0.35943346249910074 max of weights 1.6765276588937195
Iteration 11180 loss 0.7695470174763344 train RMSE 0.35238098519628364 Validation RMSE 11180 : 0.35768661031063875 max of weights 1.676230614969838
Iteration 11190 loss 0.7617622472423211 train RMSE 0.3488069690932895 Validation RMSE 11190 : 0.3616761625270034 max of weights 1.674409986237327
Iteration 11200 loss 0.7532000017429893 train RMSE 0.344876384491378 Validation RMSE 11200 : 0.3581606090837259 max of weights 1.6741247009033735
Iteration 11210 loss 0.7396691319424366 train RMSE 0.33864891505285954 Validation RMSE 11210 : 0.36257248894745736 max of weights 1.6720279618323226
Iteration 11220 loss 0.7405535366326443 train RMSE 0.3390519728389134 Validation RMSE 11220 : 0.36024475012118173 max of weights 1.6713277988697537
Iteration 11230 loss 0.7602660636281013 train RMSE 0.34811079459586813 Validation RMSE 11230 : 0.35780294438258986 max of weights 1.6690537845336413
Iteration 11240 loss 0.7955163055664128 train RMSE 0.36432783709930916 Validation RMSE 11240 : 0.36101956435702043 max of weights 1.67283449677609
Iteration 11250 loss 0.780496217703337 train RMSE 0.3574180101938954 Validation RMSE 11250 : 0.3569317775137518 max of weights 1.6762837175269598
Iteration 11260 loss 0.7805686536100298 train RMSE 0.35744091207656636 Validation RMSE 11260 : 0.3634462514473374 max of weights 1.6738259947902854
Iteration 11270 loss 0.8028868142802915 train RMSE 0.36771277557139803 Validation RMSE 11270 : 0.36436813902776116 max of weights 1.6717397782842067
Iteration 11280 loss 0.7854402389635633 train RMSE 0.3596856964120446 Validation RMSE 11280 : 0.3570368628128324 max of weights 1.6729583467902471
Iteration 11290 loss 0.7762770445374412 train RMSE 0.3554674226485703 Validation RMSE 11290 : 0.3555282489885574 max of weights 1.6766384645196055
Iteration 11300 loss 0.7846621700043888 train RMSE 0.3593204024983123 Validation RMSE 11300 : 0.36207228396898955 max of weights 1.6789288641741962
Iteration 11310 loss 0.7671038561860819 train RMSE 0.35123538301911367 Validation RMSE 11310 : 0.3560281061813236 max of weights 1.682753450928049
Iteration 11320 loss 0.7640573945637403 train RMSE 0.34983676962468024 Validation RMSE 11320 : 0.35969311785097147 max of weights 1.6912911906837076
Iteration 11330 loss 0.7700465888941779 train RMSE 0.3525991911860599 Validation RMSE 11330 : 0.3586583906443005 max of weights 1.700758185560827
Iteration 11340 loss 0.7623397455980636 train RMSE 0.3490516049129125 Validation RMSE 11340 : 0.3571408772484033 max of weights 1.7045050676201041
Iteration 11350 loss 0.749934431810005 train RMSE 0.34333896303814676 Validation RMSE 11350 : 0.35479557376224613 max of weights 1.7085128366527826
Iteration 11360 loss 0.7387639883113803 train RMSE 0.3381914535832122 Validation RMSE 11360 : 0.35495789668724165 max of weights 1.7070310733538834
Iteration 11370 loss 0.7467909078511396 train RMSE 0.341878717887012 Validation RMSE 11370 : 0.35819304848485695 max of weights 1.7089462552871189
Iteration 11380 loss 0.7575026251168739 train RMSE 0.3468042762715524 Validation RMSE 11380 : 0.3601232656674084 max of weights 1.7155948484162402
Iteration 11390 loss 0.7532508105751021 train RMSE 0.34484571317893414 Validation RMSE 11390 : 0.35990800585449906 max of weights 1.7157475657587948
Iteration 11400 loss 0.752632014420104 train RMSE 0.34456173603552875 Validation RMSE 11400 : 0.36095172222906263 max of weights 1.7135103429949692
Iteration 11410 loss 0.7413900604686304 train RMSE 0.33938206191002623 Validation RMSE 11410 : 0.35851386110687505 max of weights 1.7107636313834609
Iteration 11420 loss 0.7399394460408699 train RMSE 0.33871011648540544 Validation RMSE 11420 : 0.3624219716081318 max of weights 1.7118371336154468
Iteration 11430 loss 0.7721194111722003 train RMSE 0.3535180661543619 Validation RMSE 11430 : 0.3576324695713024 max of weights 1.71870598548725
Iteration 11440 loss 0.8032680846310215 train RMSE 0.36784975756718424 Validation RMSE 11440 : 0.3650213706554009 max of weights 1.7249913859039048
Iteration 11450 loss 0.7744223534831285 train RMSE 0.35458202678754 Validation RMSE 11450 : 0.3570519131480399 max of weights 1.7228034404644723
Iteration 11460 loss 0.7543320951955187 train RMSE 0.3453364704090779 Validation RMSE 11460 : 0.358922865660156 max of weights 1.7234560566926607
Iteration 11470 loss 0.7603826780354181 train RMSE 0.3481236314832732 Validation RMSE 11470 : 0.35765919447615185 max of weights 1.7220199646840255
Iteration 11480 loss 0.7814637285885744 train RMSE 0.35783485089591616 Validation RMSE 11480 : 0.3597494925464845 max of weights 1.7204986391356358
Iteration 11490 loss 0.7624324555400954 train RMSE 0.3490713734946409 Validation RMSE 11490 : 0.3641658391511348 max of weights 1.7206094309988254
Iteration 11500 loss 0.7632220471917581 train RMSE 0.3494290359059821 Validation RMSE 11500 : 0.35668488344745 max of weights 1.7167032385008352
Iteration 11510 loss 0.7881920294247416 train RMSE 0.36091202395486705 Validation RMSE 11510 : 0.35738274617808313 max of weights 1.713251752655695
Iteration 11520 loss 0.7938385414772215 train RMSE 0.36350541721953855 Validation RMSE 11520 : 0.35973806660530594 max of weights 1.7098010983675604
Iteration 11530 loss 0.7775712939486629 train RMSE 0.3560107722356517 Validation RMSE 11530 : 0.3587118320945163 max of weights 1.7122417493172801
Iteration 11540 loss 0.7663527044538277 train RMSE 0.35084746434755065 Validation RMSE 11540 : 0.35913026288772393 max of weights 1.713971789096025
Iteration 11550 loss 0.7549329145984744 train RMSE 0.3455958702187728 Validation RMSE 11550 : 0.3600717509492858 max of weights 1.7147383593981274
Iteration 11560 loss 0.7384512138086625 train RMSE 0.3380213820268372 Validation RMSE 11560 : 0.3582398793859043 max of weights 1.7165897768140945
Iteration 11570 loss 0.7259346301152928 train RMSE 0.33226516722530314 Validation RMSE 11570 : 0.3576077215965631 max of weights 1.7121430696042501
Iteration 11580 loss 0.7324527158602426 train RMSE 0.3352561855682529 Validation RMSE 11580 : 0.35856255911937734 max of weights 1.7098162372694248
Iteration 11590 loss 0.727394087428869 train RMSE 0.3329360961366884 Validation RMSE 11590 : 0.35655866300179656 max of weights 1.713575467295565
Iteration 11600 loss 0.7393698307362894 train RMSE 0.3384510204680713 Validation RMSE 11600 : 0.3568605000402326 max of weights 1.718568341448818
Iteration 11610 loss 0.7438372077916596 train RMSE 0.3404978630052163 Validation RMSE 11610 : 0.35867473707921793 max of weights 1.7154307255144008
Iteration 11620 loss 0.7577892356846114 train RMSE 0.34691714447145805 Validation RMSE 11620 : 0.3583628229963265 max of weights 1.729041333330425
Iteration 11630 loss 0.7652240839495233 train RMSE 0.3503418189789621 Validation RMSE 11630 : 0.35744242793835523 max of weights 1.7322148013627132
Iteration 11640 loss 0.7761292975803237 train RMSE 0.3553577008544299 Validation RMSE 11640 : 0.35850151014352777 max of weights 1.7355979492304705
Iteration 11650 loss 0.7908294766801856 train RMSE 0.3621178137619617 Validation RMSE 11650 : 0.3626623497600669 max of weights 1.7313790786905745
Iteration 11660 loss 0.7709526759056605 train RMSE 0.3529732495220515 Validation RMSE 11660 : 0.3621656841535367 max of weights 1.7286291834722551
Iteration 11670 loss 0.7385428655818032 train RMSE 0.3380593320062931 Validation RMSE 11670 : 0.3614351330906689 max of weights 1.7266542555536917
Iteration 11680 loss 0.7376927776906329 train RMSE 0.3376628331205554 Validation RMSE 11680 : 0.35963501441197593 max of weights 1.7090669255044697
Iteration 11690 loss 0.7620484153205339 train RMSE 0.3488596006196847 Validation RMSE 11690 : 0.3640440473551735 max of weights 1.7015416285903668
Iteration 11700 loss 0.78065608921921 train RMSE 0.3574219881825498 Validation RMSE 11700 : 0.36273401148810025 max of weights 1.7053651317016385
Iteration 11710 loss 0.7845133527258463 train RMSE 0.3591962225802544 Validation RMSE 11710 : 0.3631623559891323 max of weights 1.7212914723351338
Iteration 11720 loss 0.7707398676108862 train RMSE 0.3528594062385795 Validation RMSE 11720 : 0.3591912418645811 max of weights 1.72760977690169
Iteration 11730 loss 0.7549102540649134 train RMSE 0.3455804251600445 Validation RMSE 11730 : 0.36080300561839507 max of weights 1.7288296874521698
Iteration 11740 loss 0.7411314500259223 train RMSE 0.33923442562327427 Validation RMSE 11740 : 0.35919275355711205 max of weights 1.7232592592905702
Iteration 11750 loss 0.7444670145899193 train RMSE 0.34077087005079276 Validation RMSE 11750 : 0.3610080179610307 max of weights 1.722712840283094
Iteration 11760 loss 0.7479116186924304 train RMSE 0.3423648178710781 Validation RMSE 11760 : 0.35782592893079135 max of weights 1.7219480188900589
Iteration 11770 loss 0.7646562180967039 train RMSE 0.35007979905427783 Validation RMSE 11770 : 0.3608554022458032 max of weights 1.7209135511102034
Iteration 11780 loss 0.7811924906407532 train RMSE 0.35769357006355307 Validation RMSE 11780 : 0.36163423141975437 max of weights 1.7257026234103865
Iteration 11790 loss 0.7611786882598491 train RMSE 0.3484800130352443 Validation RMSE 11790 : 0.3595152784073327 max of weights 1.7205146236974824
Iteration 11800 loss 0.7501431858119963 train RMSE 0.34339377736009835 Validation RMSE 11800 : 0.3621465460875798 max of weights 1.7111449816360464
Iteration 11810 loss 0.7707592204578154 train RMSE 0.35288580136043796 Validation RMSE 11810 : 0.3606854089071409 max of weights 1.7016310909063694
Iteration 11820 loss 0.7761481094829387 train RMSE 0.3553662921856645 Validation RMSE 11820 : 0.3612737568475872 max of weights 1.697811896060387
Iteration 11830 loss 0.777882672887327 train RMSE 0.35616678584692324 Validation RMSE 11830 : 0.3587205103945409 max of weights 1.704984228219678
Iteration 11840 loss 0.7805072752147465 train RMSE 0.357371830909523 Validation RMSE 11840 : 0.36202606966393697 max of weights 1.7051576284094945
Iteration 11850 loss 0.78520991422816 train RMSE 0.35953166935799413 Validation RMSE 11850 : 0.3579084185614942 max of weights 1.7064060820193117
Iteration 11860 loss 0.7822034217498287 train RMSE 0.35814990122033846 Validation RMSE 11860 : 0.3614979849283404 max of weights 1.7205400263600155
Iteration 11870 loss 0.7587160781197242 train RMSE 0.34734103481800266 Validation RMSE 11870 : 0.35914018887554827 max of weights 1.726334843036653
Iteration 11880 loss 0.7457016625251432 train RMSE 0.34134322277183804 Validation RMSE 11880 : 0.361348537697103 max of weights 1.726746520984729
Iteration 11890 loss 0.7451708723322958 train RMSE 0.3410956680871006 Validation RMSE 11890 : 0.3574357355169157 max of weights 1.7218614074028546
Iteration 11900 loss 0.7527402572039545 train RMSE 0.34456897619682647 Validation RMSE 11900 : 0.3566924401344965 max of weights 1.7207703766932418
Iteration 11910 loss 0.7766817841690826 train RMSE 0.35557892952647624 Validation RMSE 11910 : 0.3564049202281155 max of weights 1.7225521143675226
Iteration 11920 loss 0.7969994248203294 train RMSE 0.36491530112714465 Validation RMSE 11920 : 0.3583741576559858 max of weights 1.726758898905539
Iteration 11930 loss 0.8044855650542648 train RMSE 0.3683593173390295 Validation RMSE 11930 : 0.3619054920086551 max of weights 1.7324688382727707
Iteration 11940 loss 0.7904813574728468 train RMSE 0.361916304440387 Validation RMSE 11940 : 0.36227482200744854 max of weights 1.7391258938738472
Iteration 11950 loss 0.787067687320406 train RMSE 0.3603476505133198 Validation RMSE 11950 : 0.3631025638367438 max of weights 1.7418347018672686
Iteration 11960 loss 0.7843882420614051 train RMSE 0.3591206707685419 Validation RMSE 11960 : 0.36138042520926833 max of weights 1.7416785755410047
Iteration 11970 loss 0.7768066561244834 train RMSE 0.3556311095908831 Validation RMSE 11970 : 0.3609971386144655 max of weights 1.7394741731760264
Iteration 11980 loss 0.7587813670865268 train RMSE 0.34734245315983314 Validation RMSE 11980 : 0.35817518203972126 max of weights 1.7422267484359422
Iteration 11990 loss 0.7274195968129201 train RMSE 0.3329132023110409 Validation RMSE 11990 : 0.3599147563323397 max of weights 1.7417105763684484
Iteration 12000 loss 0.74442246502278 train RMSE 0.34073535232052166 Validation RMSE 12000 : 0.3610153713900783 max of weights 1.7412751823524628
Iteration 12010 loss 0.7644750989777439 train RMSE 0.34995479834943327 Validation RMSE 12010 : 0.3644797495809588 max of weights 1.7388579418838708
Iteration 12020 loss 0.7525196818535165 train RMSE 0.3444565024732554 Validation RMSE 12020 : 0.3581064222287212 max of weights 1.7366391772766188
Iteration 12030 loss 0.7524038000346123 train RMSE 0.34440263496378826 Validation RMSE 12030 : 0.35904626257094996 max of weights 1.737555651102995
Iteration 12040 loss 0.7446539280196814 train RMSE 0.3408361060082318 Validation RMSE 12040 : 0.3571394723943132 max of weights 1.733761709747282
Iteration 12050 loss 0.7450320454368546 train RMSE 0.3410124286628987 Validation RMSE 12050 : 0.35884133210093333 max of weights 1.7297213889189214
Iteration 12060 loss 0.738725772815934 train RMSE 0.3381157206115354 Validation RMSE 12060 : 0.35819026348629573 max of weights 1.7186243220062962
Iteration 12070 loss 0.7426959444130246 train RMSE 0.3399401018225375 Validation RMSE 12070 : 0.3583103532287847 max of weights 1.7157495061494328
Iteration 12080 loss 0.7339405137873456 train RMSE 0.3359085357165471 Validation RMSE 12080 : 0.35650014213672276 max of weights 1.7138149283179858
Iteration 12090 loss 0.7500982497331304 train RMSE 0.34333546169039375 Validation RMSE 12090 : 0.35654597199444016 max of weights 1.7124748888859187
Iteration 12100 loss 0.7643233926800845 train RMSE 0.3498806116572589 Validation RMSE 12100 : 0.35700566365246106 max of weights 1.7137037071126224
Iteration 12110 loss 0.7480208211117332 train RMSE 0.3423783479351352 Validation RMSE 12110 : 0.35726432778626793 max of weights 1.7153880381534323
Iteration 12120 loss 0.7614682540062881 train RMSE 0.34856750231875006 Validation RMSE 12120 : 0.3561172981178315 max of weights 1.7195233639268748
Iteration 12130 loss 0.7742919612845182 train RMSE 0.3544666863138728 Validation RMSE 12130 : 0.3600295052672363 max of weights 1.7296659569998263
Iteration 12140 loss 0.7881074647709784 train RMSE 0.36082343650759574 Validation RMSE 12140 : 0.35744358194385983 max of weights 1.7364932357235663
Iteration 12150 loss 0.8019169593605929 train RMSE 0.3671860445119665 Validation RMSE 12150 : 0.35755314643594127 max of weights 1.7391229397941652
Iteration 12160 loss 0.8091521028314216 train RMSE 0.37051603658936855 Validation RMSE 12160 : 0.3588782298003219 max of weights 1.7504211094955706
Iteration 12170 loss 0.7892907883671616 train RMSE 0.361371463003257 Validation RMSE 12170 : 0.3576351200488769 max of weights 1.757258134171847
Iteration 12180 loss 0.7716387554723406 train RMSE 0.353254306653034 Validation RMSE 12180 : 0.35615950995864304 max of weights 1.7572066311408876
Iteration 12190 loss 0.7821704672757905 train RMSE 0.35810620839434193 Validation RMSE 12190 : 0.3580655177938389 max of weights 1.7542439713007287
Iteration 12200 loss 0.8232102481617818 train RMSE 0.376989123011017 Validation RMSE 12200 : 0.3706876710316777 max of weights 1.7506304602109883
Iteration 12210 loss 0.7878573251441658 train RMSE 0.3607232044566703 Validation RMSE 12210 : 0.35853765637313856 max of weights 1.7525481889919563
Iteration 12220 loss 0.7764743441268396 train RMSE 0.35547769496818266 Validation RMSE 12220 : 0.36082232265732017 max of weights 1.7534434667410246
Iteration 12230 loss 0.7774053379195739 train RMSE 0.35590748095145225 Validation RMSE 12230 : 0.35790223670029947 max of weights 1.7631083685187865
Iteration 12240 loss 0.795703544885754 train RMSE 0.36433271976139026 Validation RMSE 12240 : 0.3590161235158638 max of weights 1.7715369845440148
Iteration 12250 loss 0.7947357351015768 train RMSE 0.36388263676697824 Validation RMSE 12250 : 0.35883817250030675 max of weights 1.7778796602018607
Iteration 12260 loss 0.7790620431825545 train RMSE 0.35666663463714376 Validation RMSE 12260 : 0.35668031133446243 max of weights 1.7827309043378332
Iteration 12270 loss 0.8166404473980365 train RMSE 0.37395270823034343 Validation RMSE 12270 : 0.36208358161512316 max of weights 1.7807997797729687
Iteration 12280 loss 0.8124298084898395 train RMSE 0.37200610807023154 Validation RMSE 12280 : 0.36909309373459814 max of weights 1.7829355299529113
Iteration 12290 loss 0.7723227684037828 train RMSE 0.3535504024361525 Validation RMSE 12290 : 0.3588216673043851 max of weights 1.7922549078539969
Iteration 12300 loss 0.7843683868672933 train RMSE 0.3590994989530013 Validation RMSE 12300 : 0.35754698393387285 max of weights 1.8021122164486831
Iteration 12310 loss 0.7711623598685008 train RMSE 0.3530266346361694 Validation RMSE 12310 : 0.358857920262279 max of weights 1.806753006437168
Iteration 12320 loss 0.7462350741337699 train RMSE 0.3415551977295917 Validation RMSE 12320 : 0.3548484830820275 max of weights 1.807409344625064
Iteration 12330 loss 0.7473050928124619 train RMSE 0.34204083281489334 Validation RMSE 12330 : 0.35500896052721664 max of weights 1.8069416157511708
Iteration 12340 loss 0.7574927863754009 train RMSE 0.34673017127614236 Validation RMSE 12340 : 0.3536883354034266 max of weights 1.8097222548491718
Iteration 12350 loss 0.7448973732465118 train RMSE 0.3409303221763274 Validation RMSE 12350 : 0.35558995560422113 max of weights 1.8104574296471982
Iteration 12360 loss 0.7591537987068606 train RMSE 0.3474890572310925 Validation RMSE 12360 : 0.3553843789362447 max of weights 1.8088124607053253
Iteration 12370 loss 0.7679101164070252 train RMSE 0.35151633525540965 Validation RMSE 12370 : 0.35750362984632994 max of weights 1.8081535844192889
Iteration 12380 loss 0.7583497862493509 train RMSE 0.34711693081178 Validation RMSE 12380 : 0.3566479103255585 max of weights 1.8069184380711363
Iteration 12390 loss 0.747834331285731 train RMSE 0.3422699402488936 Validation RMSE 12390 : 0.35408576068871644 max of weights 1.8026786416607918
Iteration 12400 loss 0.783662443418642 train RMSE 0.35875041873587 Validation RMSE 12400 : 0.3605809113999256 max of weights 1.8017649009511438
Iteration 12410 loss 0.7784363268745013 train RMSE 0.35634984315369733 Validation RMSE 12410 : 0.3565221398875999 max of weights 1.8017712077120822
Iteration 12420 loss 0.7416193115154196 train RMSE 0.3394041573782355 Validation RMSE 12420 : 0.3524904700130759 max of weights 1.795863823286815
Iteration 12430 loss 0.7523438098183716 train RMSE 0.34433793722305056 Validation RMSE 12430 : 0.3536718431712499 max of weights 1.793817898169011
Iteration 12440 loss 0.754847135840167 train RMSE 0.3454845522136522 Validation RMSE 12440 : 0.3557981153963489 max of weights 1.790047709022652
Iteration 12450 loss 0.7548821360035795 train RMSE 0.3454985244752576 Validation RMSE 12450 : 0.35574212156362156 max of weights 1.7934679087020036
Iteration 12460 loss 0.7557172863279307 train RMSE 0.34587797011862875 Validation RMSE 12460 : 0.3538442814233724 max of weights 1.7987518407319392
Iteration 12470 loss 0.7323692077693184 train RMSE 0.3351323034991587 Validation RMSE 12470 : 0.35148089562684925 max of weights 1.7978130882896217
Iteration 12480 loss 0.7380009243925332 train RMSE 0.3377190909487544 Validation RMSE 12480 : 0.35904066860801814 max of weights 1.7923425947835199
Iteration 12490 loss 0.7633920992089646 train RMSE 0.3493914694817819 Validation RMSE 12490 : 0.35519130142485783 max of weights 1.7903201096104948
Iteration 12500 loss 0.7849584617725526 train RMSE 0.35930979748522457 Validation RMSE 12500 : 0.35749163390211086 max of weights 1.7909061951497018
Iteration 12510 loss 0.7759890167802803 train RMSE 0.3551921368037429 Validation RMSE 12510 : 0.3540794889337313 max of weights 1.7969663804073175
Iteration 12520 loss 0.7499271443853983 train RMSE 0.34320752280063077 Validation RMSE 12520 : 0.3537179713167909 max of weights 1.8009646275006455
Iteration 12530 loss 0.7714185576874619 train RMSE 0.35309640062770004 Validation RMSE 12530 : 0.35912993271700344 max of weights 1.8056874281888158
Iteration 12540 loss 0.7587776552274502 train RMSE 0.3472735747705203 Validation RMSE 12540 : 0.3560832733426634 max of weights 1.8064359469592195
Iteration 12550 loss 0.7524820534299153 train RMSE 0.34438175035672514 Validation RMSE 12550 : 0.35505792222754096 max of weights 1.804869851834283
Iteration 12560 loss 0.7624961015819801 train RMSE 0.34899716134220216 Validation RMSE 12560 : 0.3555985964747333 max of weights 1.8039874734049062
Iteration 12570 loss 0.7788617110165268 train RMSE 0.35652622849332793 Validation RMSE 12570 : 0.3586071813915047 max of weights 1.800324233744282
Iteration 12580 loss 0.797761654296098 train RMSE 0.3652221733863709 Validation RMSE 12580 : 0.36146777583775375 max of weights 1.7996562146356918
Iteration 12590 loss 0.769716098766187 train RMSE 0.3523146343200859 Validation RMSE 12590 : 0.3532851066909579 max of weights 1.8021866449945962
Iteration 12600 loss 0.7729234975911625 train RMSE 0.3537927251064717 Validation RMSE 12600 : 0.35462390245545794 max of weights 1.8020009345525072
Iteration 12610 loss 0.7550790436610112 train RMSE 0.34558020503013576 Validation RMSE 12610 : 0.35568303521851014 max of weights 1.8010112259076665
Iteration 12620 loss 0.7398363494310457 train RMSE 0.33856731179644645 Validation RMSE 12620 : 0.3559536932224689 max of weights 1.7975907725596105
Iteration 12630 loss 0.7654875084167589 train RMSE 0.35037499476762946 Validation RMSE 12630 : 0.35597125230798854 max of weights 1.7974679810824417
Iteration 12640 loss 0.7502859845785937 train RMSE 0.34338410679337356 Validation RMSE 12640 : 0.36278199991665544 max of weights 1.795713179024929
Iteration 12650 loss 0.7532629166844635 train RMSE 0.3447654927453299 Validation RMSE 12650 : 0.3600580783166873 max of weights 1.7941524532434883
Iteration 12660 loss 0.7383190821456305 train RMSE 0.3378839115640603 Validation RMSE 12660 : 0.36403644089753207 max of weights 1.7910391916437627
Iteration 12670 loss 0.7460828392908512 train RMSE 0.341453996658754 Validation RMSE 12670 : 0.3574461131798646 max of weights 1.791848355333463
Iteration 12680 loss 0.7693953270780313 train RMSE 0.35217025961579207 Validation RMSE 12680 : 0.3567804003817888 max of weights 1.7931112085300502
Iteration 12690 loss 0.7889125599949746 train RMSE 0.36115047710214343 Validation RMSE 12690 : 0.35745193577381473 max of weights 1.79941613351111
Iteration 12700 loss 0.7708802241179658 train RMSE 0.35285097693900097 Validation RMSE 12700 : 0.35669582814461176 max of weights 1.7999183588183176
Iteration 12710 loss 0.7787687913623667 train RMSE 0.35647139553719537 Validation RMSE 12710 : 0.3634223844592483 max of weights 1.7955489738718513
Iteration 12720 loss 0.7945263538108204 train RMSE 0.3637267747420858 Validation RMSE 12720 : 0.3623751650197884 max of weights 1.7980484357167594
Iteration 12730 loss 0.773494575246794 train RMSE 0.3540475883411577 Validation RMSE 12730 : 0.35521479828081365 max of weights 1.800816646988286
Iteration 12740 loss 0.7665944551042294 train RMSE 0.35087170904928194 Validation RMSE 12740 : 0.3539902056369775 max of weights 1.801352126716463
Iteration 12750 loss 0.7564592720354373 train RMSE 0.34620118581047743 Validation RMSE 12750 : 0.35476761469625867 max of weights 1.8038059411927587
Iteration 12760 loss 0.7462998722476958 train RMSE 0.34152189852435894 Validation RMSE 12760 : 0.3537397490703557 max of weights 1.804493773345548
Iteration 12770 loss 0.7676633839697518 train RMSE 0.3513577425153157 Validation RMSE 12770 : 0.3624006482636291 max of weights 1.8102507592001
Iteration 12780 loss 0.7601895302332597 train RMSE 0.34792237523171027 Validation RMSE 12780 : 0.3578653980593941 max of weights 1.8184970606194097
Iteration 12790 loss 0.7535599096866651 train RMSE 0.3448730118435874 Validation RMSE 12790 : 0.35441647087839817 max of weights 1.8203718881696092
Iteration 12800 loss 0.7619880254718703 train RMSE 0.34874590509646924 Validation RMSE 12800 : 0.3567440239318068 max of weights 1.8273993733273903
Iteration 12810 loss 0.7267456187180867 train RMSE 0.33252165786757454 Validation RMSE 12810 : 0.3554885521377199 max of weights 1.8266583898795414
Iteration 12820 loss 0.7434716086367272 train RMSE 0.3402151254215189 Validation RMSE 12820 : 0.35581831359788896 max of weights 1.8296358609436165
Iteration 12830 loss 0.7430669549774663 train RMSE 0.3400266198971753 Validation RMSE 12830 : 0.35683230976086183 max of weights 1.83370931246845
Iteration 12840 loss 0.7399615647702977 train RMSE 0.33859783519934017 Validation RMSE 12840 : 0.3577820748711401 max of weights 1.8343747931493177
Iteration 12850 loss 0.7423097918270695 train RMSE 0.3396752214987566 Validation RMSE 12850 : 0.35761914875648776 max of weights 1.8302009334043445
Iteration 12860 loss 0.7234822586471882 train RMSE 0.3310032261305957 Validation RMSE 12860 : 0.3596727190216112 max of weights 1.8278472627051918
Iteration 12870 loss 0.7325117556205054 train RMSE 0.33515884438030513 Validation RMSE 12870 : 0.35560550241872263 max of weights 1.8283271519086
Iteration 12880 loss 0.7811600674934507 train RMSE 0.357545565686575 Validation RMSE 12880 : 0.358834248692786 max of weights 1.8340292084993006
Iteration 12890 loss 0.7894233200845856 train RMSE 0.3613509684565087 Validation RMSE 12890 : 0.3604691804804998 max of weights 1.837455002402669
Iteration 12900 loss 0.7601021855234794 train RMSE 0.34786297264821275 Validation RMSE 12900 : 0.3556768943456708 max of weights 1.8368953973429978
Iteration 12910 loss 0.7458043463789884 train RMSE 0.34128197506169583 Validation RMSE 12910 : 0.3582563335428654 max of weights 1.8360455408584175
Iteration 12920 loss 0.7614109355106484 train RMSE 0.348470435550093 Validation RMSE 12920 : 0.35505105705487555 max of weights 1.8370648997318382
Iteration 12930 loss 0.7773929489082623 train RMSE 0.3558303590488776 Validation RMSE 12930 : 0.35813663760239955 max of weights 1.8385719540886143
Iteration 12940 loss 0.7532022946397066 train RMSE 0.3446910783092067 Validation RMSE 12940 : 0.3563579163001823 max of weights 1.8350408136069292
Iteration 12950 loss 0.7587883336090149 train RMSE 0.34725535583849143 Validation RMSE 12950 : 0.3552714661117079 max of weights 1.8296461999128864
Iteration 12960 loss 0.7827213946433481 train RMSE 0.35826643110685946 Validation RMSE 12960 : 0.3575233230072213 max of weights 1.8250040330390893
Iteration 12970 loss 0.7706144571362092 train RMSE 0.35269078603770504 Validation RMSE 12970 : 0.3569711447630369 max of weights 1.819887025015322
Iteration 12980 loss 0.7654242624881435 train RMSE 0.3502916418734164 Validation RMSE 12980 : 0.35859031376760936 max of weights 1.8204310199786726
Iteration 12990 loss 0.7493183772463422 train RMSE 0.3428832582927075 Validation RMSE 12990 : 0.35536706066978446 max of weights 1.8209227371863896
Iteration 13000 loss 0.7497525558530448 train RMSE 0.34308740168900675 Validation RMSE 13000 : 0.3577027712241222 max of weights 1.8205302279750346
Iteration 13010 loss 0.7239128537297569 train RMSE 0.33120758057085453 Validation RMSE 13010 : 0.3556981800250537 max of weights 1.82051720958516
Iteration 13020 loss 0.729493158898975 train RMSE 0.3337769980441708 Validation RMSE 13020 : 0.3549339205687999 max of weights 1.8110724068873754
Iteration 13030 loss 0.72445438483463 train RMSE 0.3314544765758507 Validation RMSE 13030 : 0.3564302069196192 max of weights 1.8156510907916548
Iteration 13040 loss 0.7240801524837572 train RMSE 0.33129129722389233 Validation RMSE 13040 : 0.35512296240918617 max of weights 1.8204181411718032
Iteration 13050 loss 0.7368805344910111 train RMSE 0.33718591087455557 Validation RMSE 13050 : 0.3533878097872253 max of weights 1.8259085973618012
Iteration 13060 loss 0.754475840006071 train RMSE 0.3452768247584983 Validation RMSE 13060 : 0.3577259101573849 max of weights 1.8294093672646417
Iteration 13070 loss 0.760726736587083 train RMSE 0.3481573661700942 Validation RMSE 13070 : 0.355984494020933 max of weights 1.8385832122708248
Iteration 13080 loss 0.7704407618092415 train RMSE 0.35262816591041074 Validation RMSE 13080 : 0.3571137215439805 max of weights 1.8483019891727777
Iteration 13090 loss 0.7709493021060073 train RMSE 0.3528592197788431 Validation RMSE 13090 : 0.3571676451048878 max of weights 1.8548477815137399
Iteration 13100 loss 0.7830684297379037 train RMSE 0.3584363580526564 Validation RMSE 13100 : 0.36146526392963224 max of weights 1.8589096759312722
Iteration 13110 loss 0.7560465779580214 train RMSE 0.34600375228650593 Validation RMSE 13110 : 0.35942765904659446 max of weights 1.861657541324742
Iteration 13120 loss 0.7295356158171757 train RMSE 0.33380254906938694 Validation RMSE 13120 : 0.3583192936031439 max of weights 1.8583257384658602
Iteration 13130 loss 0.7350889663767772 train RMSE 0.33635019416768797 Validation RMSE 13130 : 0.35982853034016 max of weights 1.843957133764836
Iteration 13140 loss 0.7627394926111176 train RMSE 0.34906663254804804 Validation RMSE 13140 : 0.36033936611001577 max of weights 1.8416651704452998
Iteration 13150 loss 0.773962899613626 train RMSE 0.3542279527330642 Validation RMSE 13150 : 0.3600525060737487 max of weights 1.8477111728212554
Iteration 13160 loss 0.7708536096181242 train RMSE 0.3527959126254278 Validation RMSE 13160 : 0.35770068854330533 max of weights 1.8595678692909479
Iteration 13170 loss 0.7586617363411368 train RMSE 0.34718834451942515 Validation RMSE 13170 : 0.35696901120682684 max of weights 1.8637249961296576
Iteration 13180 loss 0.742910079342615 train RMSE 0.3399402488366302 Validation RMSE 13180 : 0.35855598392240384 max of weights 1.8635190711741974
Iteration 13190 loss 0.7368656551502076 train RMSE 0.3371561233883048 Validation RMSE 13190 : 0.3578934748147727 max of weights 1.859748258086549
Iteration 13200 loss 0.7416075401985553 train RMSE 0.3393428483586528 Validation RMSE 13200 : 0.3585003052219449 max of weights 1.8609025207076846
Iteration 13210 loss 0.7470813869652622 train RMSE 0.34187302058341346 Validation RMSE 13210 : 0.35667538328050263 max of weights 1.8584072799007316
Iteration 13220 loss 0.7659721057588167 train RMSE 0.3505729790216139 Validation RMSE 13220 : 0.36003259131093485 max of weights 1.8600558029661518
Iteration 13230 loss 0.772602109239711 train RMSE 0.35362606324275536 Validation RMSE 13230 : 0.3582675508687782 max of weights 1.8623762838488527
Iteration 13240 loss 0.7514678611032397 train RMSE 0.3438952763656939 Validation RMSE 13240 : 0.35813253581983717 max of weights 1.8622555107875682
Iteration 13250 loss 0.752520302271801 train RMSE 0.3443737036742137 Validation RMSE 13250 : 0.3591974004771343 max of weights 1.8663809466248726
Iteration 13260 loss 0.7679063390214107 train RMSE 0.35145633854387953 Validation RMSE 13260 : 0.35805844934360087 max of weights 1.8654984437827953
Iteration 13270 loss 0.7731539442313786 train RMSE 0.3538705189952094 Validation RMSE 13270 : 0.3598014518269775 max of weights 1.868394700231607
Iteration 13280 loss 0.7779287000887274 train RMSE 0.35606758752853274 Validation RMSE 13280 : 0.3584761943385683 max of weights 1.8674617717873159
Iteration 13290 loss 0.7766019477340214 train RMSE 0.3554526496869887 Validation RMSE 13290 : 0.3575870266743752 max of weights 1.8665428313794694
Iteration 13300 loss 0.7863528877891252 train RMSE 0.3599362305067955 Validation RMSE 13300 : 0.3593962901805542 max of weights 1.8645562385307983
Iteration 13310 loss 0.7732905047618664 train RMSE 0.3539300964517486 Validation RMSE 13310 : 0.3609519546194881 max of weights 1.8704070675479647
Iteration 13320 loss 0.7518695812198549 train RMSE 0.34406681970404424 Validation RMSE 13320 : 0.3616943521212408 max of weights 1.8691919094589096
Iteration 13330 loss 0.7415565321916063 train RMSE 0.3393135670461686 Validation RMSE 13330 : 0.3603619575086634 max of weights 1.8671872738868116
Iteration 13340 loss 0.7460536125129387 train RMSE 0.3413799354146794 Validation RMSE 13340 : 0.3566132561168334 max of weights 1.8679430926121874
Iteration 13350 loss 0.7560186566564299 train RMSE 0.34595730328075186 Validation RMSE 13350 : 0.3552145127265806 max of weights 1.860058766956345
Iteration 13360 loss 0.7783252774856207 train RMSE 0.3562138297895588 Validation RMSE 13360 : 0.35625878216037754 max of weights 1.864188420296427
Iteration 13370 loss 0.7967000845207214 train RMSE 0.36465985317285365 Validation RMSE 13370 : 0.3584065087192782 max of weights 1.8718975912207647
Iteration 13380 loss 0.8010477978075976 train RMSE 0.3666592601205836 Validation RMSE 13380 : 0.36151888532247567 max of weights 1.8728198256413493
Iteration 13390 loss 0.7793345539840035 train RMSE 0.3566687931428229 Validation RMSE 13390 : 0.3589961061730134 max of weights 1.8842415382232867
Iteration 13400 loss 0.7825434824623958 train RMSE 0.3581482788213579 Validation RMSE 13400 : 0.3614772341038664 max of weights 1.8875697670009377
Iteration 13410 loss 0.7868942577658705 train RMSE 0.36015322446098774 Validation RMSE 13410 : 0.3621887808304971 max of weights 1.8858923757614294
Iteration 13420 loss 0.7636689709362787 train RMSE 0.3494682908859935 Validation RMSE 13420 : 0.35820176295896294 max of weights 1.8806239981441868
Iteration 13430 loss 0.7413866273037103 train RMSE 0.3392181221782844 Validation RMSE 13430 : 0.35678897375355867 max of weights 1.8822010329876442
Iteration 13440 loss 0.7229685083805394 train RMSE 0.3307414796222986 Validation RMSE 13440 : 0.3604245398719875 max of weights 1.8830747216582775
Iteration 13450 loss 0.7522323491458559 train RMSE 0.34420349442936254 Validation RMSE 13450 : 0.3618906973875872 max of weights 1.8839687488382584
Iteration 13460 loss 0.7582456265213254 train RMSE 0.3469681772985702 Validation RMSE 13460 : 0.3608771480241081 max of weights 1.8789629572140298
Iteration 13470 loss 0.7407920606639402 train RMSE 0.33893940478933193 Validation RMSE 13470 : 0.3572655127449097 max of weights 1.8773736491316644
Iteration 13480 loss 0.7544623760520185 train RMSE 0.34522838335548967 Validation RMSE 13480 : 0.35969150846604653 max of weights 1.8747485480076138
Iteration 13490 loss 0.738747665004352 train RMSE 0.3379974066993733 Validation RMSE 13490 : 0.3569216680367053 max of weights 1.8695506471657648
Iteration 13500 loss 0.7430522230217581 train RMSE 0.33998119917693737 Validation RMSE 13500 : 0.3593684095267163 max of weights 1.864550047595729
Iteration 13510 loss 0.735529507759951 train RMSE 0.3365256029422337 Validation RMSE 13510 : 0.35778574284204334 max of weights 1.855454242902389
Iteration 13520 loss 0.73072637563954 train RMSE 0.3343115450260921 Validation RMSE 13520 : 0.35677885314704033 max of weights 1.8539816953912107
Iteration 13530 loss 0.7231793539404169 train RMSE 0.3308325675436676 Validation RMSE 13530 : 0.3556257082195219 max of weights 1.8470421819579619
Iteration 13540 loss 0.7500335552494886 train RMSE 0.34318103260135613 Validation RMSE 13540 : 0.3557660706044334 max of weights 1.8478668510146794
Iteration 13550 loss 0.7457245644686213 train RMSE 0.3411992918268815 Validation RMSE 13550 : 0.35443992775435434 max of weights 1.8521294315878458
Iteration 13560 loss 0.7438207194816211 train RMSE 0.34032333986753266 Validation RMSE 13560 : 0.35574047545212456 max of weights 1.859956992266397
Iteration 13570 loss 0.7673716474428849 train RMSE 0.3511630843367774 Validation RMSE 13570 : 0.35545481504938714 max of weights 1.8691541530192097
Iteration 13580 loss 0.7791226089803169 train RMSE 0.3565648406220387 Validation RMSE 13580 : 0.35914840467264586 max of weights 1.8744478983594477
Iteration 13590 loss 0.7919715368223691 train RMSE 0.36248416265503125 Validation RMSE 13590 : 0.3564752163643959 max of weights 1.8777934371131622
Iteration 13600 loss 0.8057604386840763 train RMSE 0.3688337403942497 Validation RMSE 13600 : 0.3570958265683972 max of weights 1.872906759711501
Iteration 13610 loss 0.8067013440871751 train RMSE 0.3692657546733775 Validation RMSE 13610 : 0.35783963660931484 max of weights 1.8804679330961582
Iteration 13620 loss 0.7872080305963616 train RMSE 0.36029022123346593 Validation RMSE 13620 : 0.35710770374064116 max of weights 1.886145841355896
Iteration 13630 loss 0.7730662305996153 train RMSE 0.35379001326114906 Validation RMSE 13630 : 0.35458350990116333 max of weights 1.887106531042166
Iteration 13640 loss 0.7911661560621637 train RMSE 0.36212115555223423 Validation RMSE 13640 : 0.35943911915363885 max of weights 1.8843972557222424
Iteration 13650 loss 0.8072045039173894 train RMSE 0.36950310121038427 Validation RMSE 13650 : 0.36267515934836553 max of weights 1.882225796883078
Iteration 13660 loss 0.7873171036371068 train RMSE 0.36034881080999176 Validation RMSE 13660 : 0.3568158757740996 max of weights 1.883575875105353
Iteration 13670 loss 0.7769016069069994 train RMSE 0.3555495153352968 Validation RMSE 13670 : 0.35827979317240216 max of weights 1.8875926676508552
Iteration 13680 loss 0.7894640698262884 train RMSE 0.3613320658127805 Validation RMSE 13680 : 0.3564407856415052 max of weights 1.9014505664335302
Iteration 13690 loss 0.8013487296939843 train RMSE 0.36680381552251967 Validation RMSE 13690 : 0.3591810119071121 max of weights 1.9072049941185643
Iteration 13700 loss 0.7874991626622567 train RMSE 0.36042542862669597 Validation RMSE 13700 : 0.35715876106114747 max of weights 1.9081918318849023
Iteration 13710 loss 0.7928032192566747 train RMSE 0.36286136559999693 Validation RMSE 13710 : 0.3559590910795833 max of weights 1.9054910381269432
Iteration 13720 loss 0.827541772644307 train RMSE 0.3788395635526598 Validation RMSE 13720 : 0.3639599634984987 max of weights 1.9009111593097407
Iteration 13730 loss 0.800464883850166 train RMSE 0.3663688378837075 Validation RMSE 13730 : 0.3685867136647987 max of weights 1.9015171567318134
Iteration 13740 loss 0.7798975987307786 train RMSE 0.35691016201408204 Validation RMSE 13740 : 0.3556081470242275 max of weights 1.9145056966852734
Iteration 13750 loss 0.7819153448341991 train RMSE 0.35784395275420305 Validation RMSE 13750 : 0.35796155041368116 max of weights 1.9215039945155954
Iteration 13760 loss 0.759926096325352 train RMSE 0.3477262530665713 Validation RMSE 13760 : 0.35637077501781655 max of weights 1.9267439557070831
Iteration 13770 loss 0.743594320390046 train RMSE 0.34020881545233744 Validation RMSE 13770 : 0.35393604276555635 max of weights 1.9262139979266217
Iteration 13780 loss 0.7467613437806193 train RMSE 0.3416638172590602 Validation RMSE 13780 : 0.35335559786214865 max of weights 1.9278097835162118
Iteration 13790 loss 0.7580455121961863 train RMSE 0.3468568662449294 Validation RMSE 13790 : 0.3551378302592073 max of weights 1.9302228910755823
Iteration 13800 loss 0.7438962205210529 train RMSE 0.3403443001283454 Validation RMSE 13800 : 0.3546285489609758 max of weights 1.925624985198557
Iteration 13810 loss 0.765694578543991 train RMSE 0.3503698227805801 Validation RMSE 13810 : 0.3548139906380943 max of weights 1.9227525746700955
Iteration 13820 loss 0.7623608741794422 train RMSE 0.348836870092467 Validation RMSE 13820 : 0.3558620240487536 max of weights 1.9200901662378265
Iteration 13830 loss 0.7470895361678429 train RMSE 0.3418093400854971 Validation RMSE 13830 : 0.3531696698188651 max of weights 1.9195968023762267
Iteration 13840 loss 0.7444252401119953 train RMSE 0.3405740362057575 Validation RMSE 13840 : 0.352980332174562 max of weights 1.915375628924935
Iteration 13850 loss 0.7804700270024912 train RMSE 0.35715912677792305 Validation RMSE 13850 : 0.35949847751422914 max of weights 1.9183186137518629
Iteration 13860 loss 0.7606445585275717 train RMSE 0.3480383559640055 Validation RMSE 13860 : 0.35331854028236365 max of weights 1.9160920642794192
Iteration 13870 loss 0.7411104092079104 train RMSE 0.33904739724971666 Validation RMSE 13870 : 0.3508224337139791 max of weights 1.9100356554854092
Iteration 13880 loss 0.7478870611483542 train RMSE 0.34216526345724574 Validation RMSE 13880 : 0.35186686056471883 max of weights 1.905588590723374
Iteration 13890 loss 0.7544348186839137 train RMSE 0.34517260885276607 Validation RMSE 13890 : 0.35495180061436665 max of weights 1.9001773799333068
Iteration 13900 loss 0.7582513256620902 train RMSE 0.3469262745606068 Validation RMSE 13900 : 0.3529521212059351 max of weights 1.9023921907876933
Iteration 13910 loss 0.755168019273303 train RMSE 0.3455031501247637 Validation RMSE 13910 : 0.3512747848885757 max of weights 1.9062730956379204
Iteration 13920 loss 0.7325447268996745 train RMSE 0.33508877790018543 Validation RMSE 13920 : 0.35163667706496377 max of weights 1.9022955880765555
Iteration 13930 loss 0.7466688884376731 train RMSE 0.3415813527207442 Validation RMSE 13930 : 0.3545855403628013 max of weights 1.896870123990148
Iteration 13940 loss 0.7794043901174268 train RMSE 0.3566363710630514 Validation RMSE 13940 : 0.35662198722822086 max of weights 1.8943266541121726
Iteration 13950 loss 0.7823401951640186 train RMSE 0.35798955600406146 Validation RMSE 13950 : 0.35349650097414176 max of weights 1.895955615792014
Iteration 13960 loss 0.7711842499356201 train RMSE 0.3528633003738091 Validation RMSE 13960 : 0.35162668114234896 max of weights 1.900629956614254
Iteration 13970 loss 0.7561801776775812 train RMSE 0.345961941115458 Validation RMSE 13970 : 0.35350262636212154 max of weights 1.9075599210779677
Iteration 13980 loss 0.7634807491233924 train RMSE 0.3493161178598881 Validation RMSE 13980 : 0.3556705242462117 max of weights 1.9116349703928395
Iteration 13990 loss 0.7581201488579588 train RMSE 0.3468449172522765 Validation RMSE 13990 : 0.3545999384621796 max of weights 1.91108429879986
Iteration 14000 loss 0.7529520366319599 train RMSE 0.34447268877168646 Validation RMSE 14000 : 0.3530319853388337 max of weights 1.9106021260267179
Iteration 14010 loss 0.7576299845945775 train RMSE 0.3466303305841708 Validation RMSE 14010 : 0.35407962265459053 max of weights 1.9077504614311211
Iteration 14020 loss 0.7812668013860273 train RMSE 0.35750366104221154 Validation RMSE 14020 : 0.357015877959216 max of weights 1.9024907334587486
Iteration 14030 loss 0.7860867005127572 train RMSE 0.3597194426037773 Validation RMSE 14030 : 0.3552635265717671 max of weights 1.9048769473685554
Iteration 14040 loss 0.7777571186339813 train RMSE 0.3558870925497912 Validation RMSE 14040 : 0.35270235832969027 max of weights 1.9079209905684476
Iteration 14050 loss 0.77333771552562 train RMSE 0.3538570835200685 Validation RMSE 14050 : 0.353501800062585 max of weights 1.905700210143299
Iteration 14060 loss 0.7553377448619835 train RMSE 0.3455704324835042 Validation RMSE 14060 : 0.35703719694518116 max of weights 1.9039012401532163
Iteration 14070 loss 0.7622291218169017 train RMSE 0.3487458305184479 Validation RMSE 14070 : 0.35575501921745617 max of weights 1.9013258484701028
Iteration 14080 loss 0.7633445344927079 train RMSE 0.3492660903972348 Validation RMSE 14080 : 0.3546179989573859 max of weights 1.9013310133391763
Iteration 14090 loss 0.7479432686960708 train RMSE 0.34218175564410913 Validation RMSE 14090 : 0.35870526044485945 max of weights 1.9002200184040425
Iteration 14100 loss 0.7551347015145823 train RMSE 0.3454990342228638 Validation RMSE 14100 : 0.3590346300534434 max of weights 1.89770657744582
Iteration 14110 loss 0.7416583780140271 train RMSE 0.33929452592574166 Validation RMSE 14110 : 0.3598257087948358 max of weights 1.896622655768565
Iteration 14120 loss 0.761751550282448 train RMSE 0.3485338903114183 Validation RMSE 14120 : 0.3583534349990593 max of weights 1.8983981855907868
Iteration 14130 loss 0.788736898772965 train RMSE 0.360946952496967 Validation RMSE 14130 : 0.3567859275159871 max of weights 1.9013173061628108
Iteration 14140 loss 0.8024705339027232 train RMSE 0.3672664669823096 Validation RMSE 14140 : 0.355539668113586 max of weights 1.9054508602070457
Iteration 14150 loss 0.7809083810022621 train RMSE 0.35733431744843214 Validation RMSE 14150 : 0.3565673531565939 max of weights 1.9026284377160076
Iteration 14160 loss 0.781868492334454 train RMSE 0.35777326839884854 Validation RMSE 14160 : 0.35754070325086124 max of weights 1.8980244929918995
Iteration 14170 loss 0.7785631847041555 train RMSE 0.3562551603290753 Validation RMSE 14170 : 0.3557640300744385 max of weights 1.9019700451026527
Iteration 14180 loss 0.7702152262173587 train RMSE 0.3524125049966448 Validation RMSE 14180 : 0.35410947894419204 max of weights 1.9060580528158935
Iteration 14190 loss 0.7720715905335825 train RMSE 0.3532649127717433 Validation RMSE 14190 : 0.3565618645041009 max of weights 1.906796230511865
Iteration 14200 loss 0.7537637528723904 train RMSE 0.3448346559656033 Validation RMSE 14200 : 0.3530066816600063 max of weights 1.9104182259580846
Iteration 14210 loss 0.743599353605896 train RMSE 0.3401571793184614 Validation RMSE 14210 : 0.35311723966673286 max of weights 1.9138480556372417
Iteration 14220 loss 0.7660845191453253 train RMSE 0.35051058569349647 Validation RMSE 14220 : 0.35571229118586034 max of weights 1.9213035010764257
Iteration 14230 loss 0.7587358209552236 train RMSE 0.34713163492598925 Validation RMSE 14230 : 0.3546100773916958 max of weights 1.927171958408033
Iteration 14240 loss 0.7448398233264724 train RMSE 0.340737633682616 Validation RMSE 14240 : 0.35179812241007524 max of weights 1.9317066732410668
Iteration 14250 loss 0.7564300142047664 train RMSE 0.34606601885195426 Validation RMSE 14250 : 0.3541755835365478 max of weights 1.9378536632233607
Iteration 14260 loss 0.7281002716596707 train RMSE 0.3330248880705822 Validation RMSE 14260 : 0.3582167902657072 max of weights 1.9383583038127918
Iteration 14270 loss 0.7465552726803216 train RMSE 0.34151742400278795 Validation RMSE 14270 : 0.3552139599740411 max of weights 1.9444557789354202
Iteration 14280 loss 0.745931448100263 train RMSE 0.341228887878774 Validation RMSE 14280 : 0.3556412230113036 max of weights 1.9454733266382036
Iteration 14290 loss 0.7408704505702969 train RMSE 0.33890152712105465 Validation RMSE 14290 : 0.3565166056626911 max of weights 1.9410326370914206
Iteration 14300 loss 0.7313193354211074 train RMSE 0.33450160623917913 Validation RMSE 14300 : 0.35455521687230923 max of weights 1.9372439371292685
Iteration 14310 loss 0.7226408639648072 train RMSE 0.33050023808864365 Validation RMSE 14310 : 0.3625278690846886 max of weights 1.9373630917175724
Iteration 14320 loss 0.7433125668607684 train RMSE 0.3400153341765807 Validation RMSE 14320 : 0.35199228997532833 max of weights 1.9399741498353804
Iteration 14330 loss 0.7912680315588408 train RMSE 0.362082676990347 Validation RMSE 14330 : 0.35996218501039073 max of weights 1.9472635785263706
Iteration 14340 loss 0.7811928533384406 train RMSE 0.3574525011639899 Validation RMSE 14340 : 0.3567788207966519 max of weights 1.9478323217088631
Iteration 14350 loss 0.7532802942099159 train RMSE 0.344610800342141 Validation RMSE 14350 : 0.35473207341581475 max of weights 1.9487484736724383
Iteration 14360 loss 0.7462536738346189 train RMSE 0.341373086016339 Validation RMSE 14360 : 0.356303785425767 max of weights 1.9467969887400072
Iteration 14370 loss 0.7706033585576834 train RMSE 0.35258529157655366 Validation RMSE 14370 : 0.35481014994572374 max of weights 1.9496383101509238
Iteration 14380 loss 0.7659024845877916 train RMSE 0.35042237618998473 Validation RMSE 14380 : 0.3554210784858915 max of weights 1.9484026991919923
Iteration 14390 loss 0.7520672088458199 train RMSE 0.3440504928186355 Validation RMSE 14390 : 0.3525444160327657 max of weights 1.9392281269784002
Iteration 14400 loss 0.7605463410585983 train RMSE 0.34794769054331737 Validation RMSE 14400 : 0.3538285523605788 max of weights 1.9330402793968997
Iteration 14410 loss 0.7743490389750405 train RMSE 0.3542993161815545 Validation RMSE 14410 : 0.3559817803678963 max of weights 1.9292044995348778
Iteration 14420 loss 0.7682891963487238 train RMSE 0.35150476921880475 Validation RMSE 14420 : 0.3579390477402591 max of weights 1.9270607108252744
Iteration 14430 loss 0.7637468628044131 train RMSE 0.3494080763706623 Validation RMSE 14430 : 0.35805949766198514 max of weights 1.9308979222247773
Iteration 14440 loss 0.7437846488799273 train RMSE 0.340226041058926 Validation RMSE 14440 : 0.35534307592689407 max of weights 1.9306120828934807
Iteration 14450 loss 0.7483587973018764 train RMSE 0.34233635638485416 Validation RMSE 14450 : 0.3558229111858463 max of weights 1.9290254463403689
Iteration 14460 loss 0.7234524480057862 train RMSE 0.3308860328148925 Validation RMSE 14460 : 0.3534085260323117 max of weights 1.924971456287867
Iteration 14470 loss 0.7382949514289584 train RMSE 0.33771139470909145 Validation RMSE 14470 : 0.35329422986587217 max of weights 1.913961558527685
Iteration 14480 loss 0.7215897068494739 train RMSE 0.3300248814981517 Validation RMSE 14480 : 0.35407848741658515 max of weights 1.9069655173212368
Iteration 14490 loss 0.7312834054895523 train RMSE 0.3344918032422461 Validation RMSE 14490 : 0.3546383976453859 max of weights 1.8984976597635963
Iteration 14500 loss 0.7432142675379592 train RMSE 0.3399825895405197 Validation RMSE 14500 : 0.3531620484184043 max of weights 1.8915498622239728
Iteration 14510 loss 0.7586567338738792 train RMSE 0.34708430690310543 Validation RMSE 14510 : 0.35708290617492233 max of weights 1.9004315113883115
Iteration 14520 loss 0.7671652137335607 train RMSE 0.3510064109415779 Validation RMSE 14520 : 0.35492006910749463 max of weights 1.9097628354889615
Iteration 14530 loss 0.777308728144193 train RMSE 0.3556747669327742 Validation RMSE 14530 : 0.35745456575924983 max of weights 1.9187197751068212
Iteration 14540 loss 0.7775579254967239 train RMSE 0.3557869137571262 Validation RMSE 14540 : 0.35871539519608303 max of weights 1.9212320117043518
Iteration 14550 loss 0.7702254966156608 train RMSE 0.35241740790489307 Validation RMSE 14550 : 0.3595034543929879 max of weights 1.917184346662424
Iteration 14560 loss 0.7418183136312657 train RMSE 0.3393457737402802 Validation RMSE 14560 : 0.3585558148049096 max of weights 1.910820057415869
Iteration 14570 loss 0.7265737572378023 train RMSE 0.33232521816495575 Validation RMSE 14570 : 0.3574147760330726 max of weights 1.9013482803187687
Iteration 14580 loss 0.740925701300964 train RMSE 0.33891867856565766 Validation RMSE 14580 : 0.3618472105145378 max of weights 1.88778655367969
Iteration 14590 loss 0.7731876926718856 train RMSE 0.35376254084327624 Validation RMSE 14590 : 0.3604776324244062 max of weights 1.8863451135495481
Iteration 14600 loss 0.7710427903151383 train RMSE 0.35277191708426714 Validation RMSE 14600 : 0.36015850179593467 max of weights 1.8971120152110028
Iteration 14610 loss 0.7576238568517428 train RMSE 0.3465954918081251 Validation RMSE 14610 : 0.3558805699517173 max of weights 1.9161694666487752
Iteration 14620 loss 0.7550519915591501 train RMSE 0.34541625410717924 Validation RMSE 14620 : 0.357452352213611 max of weights 1.9252965885158002
Iteration 14630 loss 0.7359821951828773 train RMSE 0.33663792034155604 Validation RMSE 14630 : 0.3577814977775968 max of weights 1.928353698661667
Iteration 14640 loss 0.740031672897817 train RMSE 0.33849984645184156 Validation RMSE 14640 : 0.3594469895332916 max of weights 1.927830802530529
Iteration 14650 loss 0.7448435872163593 train RMSE 0.34072067364164804 Validation RMSE 14650 : 0.3567822001165325 max of weights 1.927109295258894
Iteration 14660 loss 0.7548012604735047 train RMSE 0.3453135823087766 Validation RMSE 14660 : 0.35704440450201125 max of weights 1.92109230797907
Iteration 14670 loss 0.7682897656405842 train RMSE 0.3515259998089362 Validation RMSE 14670 : 0.3604090676422312 max of weights 1.9251726908591391
Iteration 14680 loss 0.7600775900966091 train RMSE 0.34774584129971664 Validation RMSE 14680 : 0.35570700078890877 max of weights 1.9266532723986074
Iteration 14690 loss 0.7406969888708568 train RMSE 0.3388212054664985 Validation RMSE 14690 : 0.357460728650011 max of weights 1.927505027098416
Iteration 14700 loss 0.7536684013805409 train RMSE 0.3447899612403917 Validation RMSE 14700 : 0.357218020512161 max of weights 1.929541258405249
Iteration 14710 loss 0.7691933433731696 train RMSE 0.3519356710155639 Validation RMSE 14710 : 0.3563061503497057 max of weights 1.9283490988455034
Iteration 14720 loss 0.7712053142872028 train RMSE 0.3528591132558163 Validation RMSE 14720 : 0.35654992282580533 max of weights 1.927987924009228
Iteration 14730 loss 0.7784997301875436 train RMSE 0.3562137343479796 Validation RMSE 14730 : 0.35923138989229764 max of weights 1.9204873060445922
Iteration 14740 loss 0.7800613698020101 train RMSE 0.35692763806506167 Validation RMSE 14740 : 0.35564784657789783 max of weights 1.9144307552485358
Iteration 14750 loss 0.7834181089305641 train RMSE 0.3584720574685748 Validation RMSE 14750 : 0.35922769152418293 max of weights 1.9139953717971425
Iteration 14760 loss 0.7592730978847477 train RMSE 0.3473650904338365 Validation RMSE 14760 : 0.35711868067562497 max of weights 1.9191961098499015
Iteration 14770 loss 0.7456151641547318 train RMSE 0.34107293590833054 Validation RMSE 14770 : 0.3586123742714192 max of weights 1.9165745408858816
Iteration 14780 loss 0.7414403152539834 train RMSE 0.33914645598531 Validation RMSE 14780 : 0.356824518820607 max of weights 1.914211673499367
Iteration 14790 loss 0.7484316327413708 train RMSE 0.34236016721349527 Validation RMSE 14790 : 0.35628482027805425 max of weights 1.9094861253223072
Iteration 14800 loss 0.7667975228269156 train RMSE 0.35080356456914835 Validation RMSE 14800 : 0.35402214190428066 max of weights 1.9029837039778754
Iteration 14810 loss 0.7822861899279652 train RMSE 0.35791983050754045 Validation RMSE 14810 : 0.35438730728818585 max of weights 1.910511976111566
Iteration 14820 loss 0.7957586810647862 train RMSE 0.364111248410566 Validation RMSE 14820 : 0.3584554955219234 max of weights 1.9196644733550594
Iteration 14830 loss 0.7965593672960583 train RMSE 0.36447759339925573 Validation RMSE 14830 : 0.36117644973431756 max of weights 1.9284315631541726
Iteration 14840 loss 0.7778114797616263 train RMSE 0.3558528316959547 Validation RMSE 14840 : 0.3571555171774972 max of weights 1.9393623285364945
Iteration 14850 loss 0.7782468019807154 train RMSE 0.3560578395091536 Validation RMSE 14850 : 0.3602990156665982 max of weights 1.9417289707736591
Iteration 14860 loss 0.780531882990437 train RMSE 0.35711144514148924 Validation RMSE 14860 : 0.35987694008249954 max of weights 1.935973421343088
Iteration 14870 loss 0.7608919668068318 train RMSE 0.3480762703537581 Validation RMSE 14870 : 0.35640866282100164 max of weights 1.9347250881333065
Iteration 14880 loss 0.7302790578795195 train RMSE 0.33399094302145943 Validation RMSE 14880 : 0.35512906758185514 max of weights 1.9389099584958172
Iteration 14890 loss 0.7303876705682373 train RMSE 0.33403816855404656 Validation RMSE 14890 : 0.35907616593231567 max of weights 1.9398579581763804
Iteration 14900 loss 0.758277480067136 train RMSE 0.3468678560382897 Validation RMSE 14900 : 0.3646659325916928 max of weights 1.9395545903778402
Iteration 14910 loss 0.7486060808258788 train RMSE 0.3424186390972767 Validation RMSE 14910 : 0.35721508234418825 max of weights 1.9336233108672307
Iteration 14920 loss 0.739605687237967 train RMSE 0.33827709126319766 Validation RMSE 14920 : 0.3561220234786221 max of weights 1.9337925256237238
Iteration 14930 loss 0.7456072725958922 train RMSE 0.3410353672463541 Validation RMSE 14930 : 0.3571749708723912 max of weights 1.9277208216093935
Iteration 14940 loss 0.7359013384767822 train RMSE 0.3365699983805008 Validation RMSE 14940 : 0.35655354101407366 max of weights 1.9230497207879618
Iteration 14950 loss 0.7340275441399682 train RMSE 0.3357140746191559 Validation RMSE 14950 : 0.3565873254155592 max of weights 1.9140577178315834
Iteration 14960 loss 0.7316790973667932 train RMSE 0.33463665835508233 Validation RMSE 14960 : 0.35631140964543606 max of weights 1.9055806142784517
Iteration 14970 loss 0.7294936703720017 train RMSE 0.3336281702769747 Validation RMSE 14970 : 0.35492994561337504 max of weights 1.902005325002366
Iteration 14980 loss 0.7289333028712687 train RMSE 0.33336009687927554 Validation RMSE 14980 : 0.35431937934805496 max of weights 1.8977475617269046
Iteration 14990 loss 0.7628741756402277 train RMSE 0.34897138446744363 Validation RMSE 14990 : 0.3562689233033932 max of weights 1.895229112703002
Iteration 15000 loss 0.7480964625973376 train RMSE 0.3421734021967047 Validation RMSE 15000 : 0.35512177633453973 max of weights 1.8967686942009436
Iteration 15010 loss 0.7503107106522983 train RMSE 0.3431939248183317 Validation RMSE 15010 : 0.35473024499642114 max of weights 1.901937470384564
Iteration 15020 loss 0.7716479804471581 train RMSE 0.3530129244186833 Validation RMSE 15020 : 0.3564309137960651 max of weights 1.9156569995843298
Iteration 15030 loss 0.7835676820596535 train RMSE 0.35848947247840535 Validation RMSE 15030 : 0.35970703216732436 max of weights 1.925669791351561
Iteration 15040 loss 0.7924081659081698 train RMSE 0.3625661012956751 Validation RMSE 15040 : 0.35635769274320017 max of weights 1.9244922926968036
Iteration 15050 loss 0.8068159230417594 train RMSE 0.3691955990435426 Validation RMSE 15050 : 0.356920298547659 max of weights 1.9261045734825566
Iteration 15060 loss 0.7936267264865828 train RMSE 0.36312348872245787 Validation RMSE 15060 : 0.35637582957632935 max of weights 1.9389323167073271
Iteration 15070 loss 0.7748260511399273 train RMSE 0.3544698808519813 Validation RMSE 15070 : 0.35572051589006637 max of weights 1.9426423550217486
Iteration 15080 loss 0.7754863514678454 train RMSE 0.35478136988684933 Validation RMSE 15080 : 0.3542762617529867 max of weights 1.942719699809396
Iteration 15090 loss 0.8096490509720811 train RMSE 0.37050241193180344 Validation RMSE 15090 : 0.3642342966438084 max of weights 1.9387352217603597
Iteration 15100 loss 0.7969495623655496 train RMSE 0.3646599228155842 Validation RMSE 15100 : 0.3574439641821781 max of weights 1.9390592057487044
Iteration 15110 loss 0.7811624096148203 train RMSE 0.3573891186490654 Validation RMSE 15110 : 0.35719440781642287 max of weights 1.938471438376705
Iteration 15120 loss 0.7747950604520386 train RMSE 0.35445551822178684 Validation RMSE 15120 : 0.3561783346887928 max of weights 1.9471909240772012
Iteration 15130 loss 0.7943519539023433 train RMSE 0.3634573174010522 Validation RMSE 15130 : 0.3565757673519232 max of weights 1.9587643657475806
Iteration 15140 loss 0.7979350745210394 train RMSE 0.3651053653146587 Validation RMSE 15140 : 0.357603266265883 max of weights 1.9624248766148207
Iteration 15150 loss 0.7784069513082743 train RMSE 0.35611573345756575 Validation RMSE 15150 : 0.3544052219968446 max of weights 1.9619844322272664
Iteration 15160 loss 0.7996202983250897 train RMSE 0.3658721762314184 Validation RMSE 15160 : 0.35570148309578625 max of weights 1.95795341100757
Iteration 15170 loss 0.8140112496082416 train RMSE 0.3724862794202312 Validation RMSE 15170 : 0.3635853036941144 max of weights 1.9539757545414904
Iteration 15180 loss 0.7788883355415323 train RMSE 0.3563183535214253 Validation RMSE 15180 : 0.36206285420967615 max of weights 1.9538520518093723
Iteration 15190 loss 0.7774973818777621 train RMSE 0.35568447638180073 Validation RMSE 15190 : 0.35486969593096684 max of weights 1.9692117401057898
Iteration 15200 loss 0.779324658885772 train RMSE 0.3565293139035121 Validation RMSE 15200 : 0.35987700895484026 max of weights 1.9752596412130123
Iteration 15210 loss 0.7480247775053965 train RMSE 0.34212498930694063 Validation RMSE 15210 : 0.3531777808281475 max of weights 1.9775298503937304
Iteration 15220 loss 0.74284917127739 train RMSE 0.33973711186023814 Validation RMSE 15220 : 0.3528287018884515 max of weights 1.9759217082268796
Iteration 15230 loss 0.7448525444645203 train RMSE 0.3406618477228666 Validation RMSE 15230 : 0.35089748063242604 max of weights 1.9800083504738881
Iteration 15240 loss 0.7468112531863071 train RMSE 0.34156197880417505 Validation RMSE 15240 : 0.35205481873443906 max of weights 1.9798008011931008
Iteration 15250 loss 0.7410792829168268 train RMSE 0.3389261270456981 Validation RMSE 15250 : 0.35115613915746996 max of weights 1.9766412852896171
Iteration 15260 loss 0.7654640183202517 train RMSE 0.35014247666099446 Validation RMSE 15260 : 0.354536617713812 max of weights 1.976343249525186
Iteration 15270 loss 0.7594068699013261 train RMSE 0.3473587441923825 Validation RMSE 15270 : 0.35492628515266855 max of weights 1.9769660597990824
Iteration 15280 loss 0.7443399062951948 train RMSE 0.34042472976528476 Validation RMSE 15280 : 0.35241927954002783 max of weights 1.9757357527704218
Iteration 15290 loss 0.748608447755287 train RMSE 0.34238194949018913 Validation RMSE 15290 : 0.3539750512777348 max of weights 1.9724845087509697
Iteration 15300 loss 0.7713141081508886 train RMSE 0.3528342154306221 Validation RMSE 15300 : 0.35660687895359383 max of weights 1.9750216315002553
Iteration 15310 loss 0.7443112774068246 train RMSE 0.3404069072432423 Validation RMSE 15310 : 0.3521654136188342 max of weights 1.9701711800357535
Iteration 15320 loss 0.7445048198055515 train RMSE 0.3404974644501175 Validation RMSE 15320 : 0.35099733208485895 max of weights 1.967255346093484
Iteration 15330 loss 0.7473072209273787 train RMSE 0.34178638600230754 Validation RMSE 15330 : 0.35187572925001986 max of weights 1.9632599350376458
Iteration 15340 loss 0.7474875997666165 train RMSE 0.34186433704010594 Validation RMSE 15340 : 0.3540750740367758 max of weights 1.961869850809086
Iteration 15350 loss 0.7550447749976851 train RMSE 0.3453392925395762 Validation RMSE 15350 : 0.3520280193379255 max of weights 1.9683561139548789
Iteration 15360 loss 0.7468653522369514 train RMSE 0.34157383753696263 Validation RMSE 15360 : 0.3502009138764061 max of weights 1.9700655611857025
Iteration 15370 loss 0.729927764806312 train RMSE 0.3337746492586262 Validation RMSE 15370 : 0.3525713436617482 max of weights 1.9648320314704815
Iteration 15380 loss 0.7508751818708106 train RMSE 0.3434039498157597 Validation RMSE 15380 : 0.3529937300388425 max of weights 1.9597001304978228
Iteration 15390 loss 0.7772795249131075 train RMSE 0.3555476243872728 Validation RMSE 15390 : 0.3540930811361489 max of weights 1.957201620906184
Iteration 15400 loss 0.782496934402906 train RMSE 0.35795344778248644 Validation RMSE 15400 : 0.3525982151187225 max of weights 1.9598758014256077
Iteration 15410 loss 0.7656788919978921 train RMSE 0.35022128253111423 Validation RMSE 15410 : 0.3505399749263927 max of weights 1.963500535547153
Iteration 15420 loss 0.7698372828945229 train RMSE 0.35213623842930813 Validation RMSE 15420 : 0.3561237397774565 max of weights 1.9690077893292375
Iteration 15430 loss 0.754965286563155 train RMSE 0.34528569757049704 Validation RMSE 15430 : 0.354536085532925 max of weights 1.9722658337744798
Iteration 15440 loss 0.7451020453259912 train RMSE 0.3407440442742984 Validation RMSE 15440 : 0.3533598138876131 max of weights 1.9698715793394015
Iteration 15450 loss 0.7496695137370308 train RMSE 0.34285082894824154 Validation RMSE 15450 : 0.35270867499220254 max of weights 1.9705257478630793
Iteration 15460 loss 0.7568700675723977 train RMSE 0.3461678956940186 Validation RMSE 15460 : 0.3525929372691754 max of weights 1.9673059628779614
Iteration 15470 loss 0.785939436572557 train RMSE 0.3595422949778383 Validation RMSE 15470 : 0.3577819624113609 max of weights 1.961835366124565
Iteration 15480 loss 0.7760088946802854 train RMSE 0.3549724567670584 Validation RMSE 15480 : 0.3525733848003498 max of weights 1.9635490732556942
Iteration 15490 loss 0.7813937274851739 train RMSE 0.3574524091115751 Validation RMSE 15490 : 0.35267315683095807 max of weights 1.9658013257799531
Iteration 15500 loss 0.7735835710598031 train RMSE 0.3538615460868816 Validation RMSE 15500 : 0.3532428932611246 max of weights 1.9629349547293333
Iteration 15510 loss 0.7453780280334875 train RMSE 0.340878599063037 Validation RMSE 15510 : 0.35733847343247294 max of weights 1.9607603255845099
Iteration 15520 loss 0.7601658046430704 train RMSE 0.3476851967010309 Validation RMSE 15520 : 0.3541729555944684 max of weights 1.9619838882159577
Iteration 15530 loss 0.7487347474013569 train RMSE 0.34243228335065107 Validation RMSE 15530 : 0.3563137444667125 max of weights 1.9631198454737184
Iteration 15540 loss 0.7409631855999526 train RMSE 0.33886298954773614 Validation RMSE 15540 : 0.3541329983364968 max of weights 1.9637865459956894
Iteration 15550 loss 0.734644342954798 train RMSE 0.3359564838919815 Validation RMSE 15550 : 0.35703716227384374 max of weights 1.961907117904131
Iteration 15560 loss 0.7411205424360537 train RMSE 0.33893558125910944 Validation RMSE 15560 : 0.3574713720221568 max of weights 1.9629417293499176
Iteration 15570 loss 0.7643979476147237 train RMSE 0.3496401939693751 Validation RMSE 15570 : 0.354661682058158 max of weights 1.9634744290554824
Iteration 15580 loss 0.7960000605723341 train RMSE 0.36418005885223004 Validation RMSE 15580 : 0.3560226399041671 max of weights 1.9673105012524716
Iteration 15590 loss 0.7979571225350374 train RMSE 0.36507956259239727 Validation RMSE 15590 : 0.35390759637666735 max of weights 1.9681592126352512
Iteration 15600 loss 0.7811322198731764 train RMSE 0.3573268142667052 Validation RMSE 15600 : 0.3584100168055681 max of weights 1.9608127378783329
Iteration 15610 loss 0.7932009500766979 train RMSE 0.36288300967681864 Validation RMSE 15610 : 0.35889002613765814 max of weights 1.9579184993053034
Iteration 15620 loss 0.7713241049980968 train RMSE 0.3528195474965892 Validation RMSE 15620 : 0.35293666823296993 max of weights 1.9610952290866441
Iteration 15630 loss 0.762948534262905 train RMSE 0.34896530189199937 Validation RMSE 15630 : 0.352046526133156 max of weights 1.9664006517417816
Iteration 15640 loss 0.7697369399771186 train RMSE 0.3520871146739838 Validation RMSE 15640 : 0.35671722887464885 max of weights 1.9688019578468154
Iteration 15650 loss 0.7539337305553855 train RMSE 0.3448105035873052 Validation RMSE 15650 : 0.35170869450070263 max of weights 1.9699533661141986
Iteration 15660 loss 0.7471994214080248 train RMSE 0.34171415141070144 Validation RMSE 15660 : 0.35398026539921557 max of weights 1.9755466534288602
Iteration 15670 loss 0.7623890166609518 train RMSE 0.3487098098511253 Validation RMSE 15670 : 0.3545553958176415 max of weights 1.9841781050858176
Iteration 15680 loss 0.7640766583775078 train RMSE 0.3494881882082147 Validation RMSE 15680 : 0.35229483738378775 max of weights 1.9887014561166707
Iteration 15690 loss 0.7444186277796415 train RMSE 0.34044062062808983 Validation RMSE 15690 : 0.3516249192812734 max of weights 1.9978030280805554
Iteration 15700 loss 0.7356712932276603 train RMSE 0.33641026925179435 Validation RMSE 15700 : 0.3502703951393689 max of weights 2.000064108700236
Iteration 15710 loss 0.732710183928722 train RMSE 0.33504221316581756 Validation RMSE 15710 : 0.3544766917525556 max of weights 2.001195879881599
Iteration 15720 loss 0.7389280583778598 train RMSE 0.33790145855600917 Validation RMSE 15720 : 0.35474613717537784 max of weights 2.0060026155383355
Iteration 15730 loss 0.7408738601110298 train RMSE 0.33879344162777464 Validation RMSE 15730 : 0.35473784514874235 max of weights 2.003003597093114
Iteration 15740 loss 0.7386097548078416 train RMSE 0.3377509370561305 Validation RMSE 15740 : 0.35702281917193085 max of weights 1.9992211840703982
Iteration 15750 loss 0.7297450338721209 train RMSE 0.33366584851646236 Validation RMSE 15750 : 0.3544263454854163 max of weights 1.9951331708678066
Iteration 15760 loss 0.7325628538842637 train RMSE 0.3349584813433073 Validation RMSE 15760 : 0.3594799702754928 max of weights 1.9959303330836964
Iteration 15770 loss 0.7657704850042313 train RMSE 0.35024181530304516 Validation RMSE 15770 : 0.35265930956676356 max of weights 1.9999387399698423
Iteration 15780 loss 0.7882378667236055 train RMSE 0.3605812480800606 Validation RMSE 15780 : 0.3578464896794482 max of weights 2.0060402370602106
Iteration 15790 loss 0.7785980881944097 train RMSE 0.3561523239400379 Validation RMSE 15790 : 0.3549272679810143 max of weights 2.0046317004277956
Iteration 15800 loss 0.7549412043958783 train RMSE 0.3452681609129558 Validation RMSE 15800 : 0.35559382238270903 max of weights 2.001915698800568
Iteration 15810 loss 0.7519194045773311 train RMSE 0.34387893372613926 Validation RMSE 15810 : 0.3538138407472501 max of weights 2.0012224079465217
Iteration 15820 loss 0.7773113151146023 train RMSE 0.35556992895018996 Validation RMSE 15820 : 0.3556105472092214 max of weights 2.002239176492642
Iteration 15830 loss 0.7599378824932762 train RMSE 0.34756961710799894 Validation RMSE 15830 : 0.35845389519523 max of weights 2.000551212526755
Iteration 15840 loss 0.7493697118911301 train RMSE 0.3427039575298738 Validation RMSE 15840 : 0.3521712336044651 max of weights 1.994318412194796
Iteration 15850 loss 0.7692751057988337 train RMSE 0.3518626278946858 Validation RMSE 15850 : 0.3532075043056283 max of weights 1.9911106844602513
Iteration 15860 loss 0.7762076324533131 train RMSE 0.35505302088384866 Validation RMSE 15860 : 0.35481187473115317 max of weights 1.9873900980761634
Iteration 15870 loss 0.7692006010889516 train RMSE 0.351819416779308 Validation RMSE 15870 : 0.35631045163704056 max of weights 1.9870006261462476
Iteration 15880 loss 0.7636494632338436 train RMSE 0.3492609156414937 Validation RMSE 15880 : 0.356931190209846 max of weights 1.988886170530681
Iteration 15890 loss 0.7453120849420343 train RMSE 0.34082578068834857 Validation RMSE 15890 : 0.3555213256981044 max of weights 1.9910764444139446
Iteration 15900 loss 0.7373581224025729 train RMSE 0.33717462909680507 Validation RMSE 15900 : 0.354274296461828 max of weights 1.9905911936371197
Iteration 15910 loss 0.7221186296578337 train RMSE 0.33016730593067495 Validation RMSE 15910 : 0.35296389840664927 max of weights 1.9862962495998966
Iteration 15920 loss 0.7366591371572947 train RMSE 0.33685023361731736 Validation RMSE 15920 : 0.35390490848326245 max of weights 1.9809579824547532
Iteration 15930 loss 0.7249812676559141 train RMSE 0.3314839075820541 Validation RMSE 15930 : 0.352515126174886 max of weights 1.9756687534757438
Iteration 15940 loss 0.7371606946027316 train RMSE 0.3370919426032232 Validation RMSE 15940 : 0.35360014364641257 max of weights 1.970701902818206
Iteration 15950 loss 0.7458156811631956 train RMSE 0.3410709259065784 Validation RMSE 15950 : 0.3540968189899216 max of weights 1.9606107250387363
Iteration 15960 loss 0.7586025850706323 train RMSE 0.3469531359534159 Validation RMSE 15960 : 0.3544181254204194 max of weights 1.9707377374455612
Iteration 15970 loss 0.7674227824523511 train RMSE 0.3510162336760946 Validation RMSE 15970 : 0.35413706775363296 max of weights 1.9667372968070116
Iteration 15980 loss 0.774629925526605 train RMSE 0.3543306133417139 Validation RMSE 15980 : 0.3561414292477059 max of weights 1.9729309735204867
Iteration 15990 loss 0.7811331207410432 train RMSE 0.35732131991883204 Validation RMSE 15990 : 0.35836009286364984 max of weights 1.9720782291428194
Iteration 16000 loss 0.7620692881629166 train RMSE 0.3485540843768345 Validation RMSE 16000 : 0.3575869760114046 max of weights 1.9676985287636162
Iteration 16010 loss 0.732702401612022 train RMSE 0.3350390096861302 Validation RMSE 16010 : 0.3579474739585178 max of weights 1.9600191984992585
Iteration 16020 loss 0.7274972693812298 train RMSE 0.33263696561848133 Validation RMSE 16020 : 0.3561939104596461 max of weights 1.9484042985320957
Iteration 16030 loss 0.7437451805027616 train RMSE 0.3401020433578439 Validation RMSE 16030 : 0.35931717004076524 max of weights 1.9373732421512655
Iteration 16040 loss 0.770470995765307 train RMSE 0.3523993352151918 Validation RMSE 16040 : 0.35856810255294125 max of weights 1.9384478009882136
Iteration 16050 loss 0.7685229226018466 train RMSE 0.35150125934534204 Validation RMSE 16050 : 0.35859504317365387 max of weights 1.9524419369435884
Iteration 16060 loss 0.7594963188275652 train RMSE 0.347347561798369 Validation RMSE 16060 : 0.35546058942861464 max of weights 1.9606500804776958
Iteration 16070 loss 0.7506448941012104 train RMSE 0.34328086395243035 Validation RMSE 16070 : 0.35665906931961033 max of weights 1.9615347908798604
Iteration 16080 loss 0.7327111910081546 train RMSE 0.33502456058818864 Validation RMSE 16080 : 0.3549423414084612 max of weights 1.9562476816200183
Iteration 16090 loss 0.7386401473401175 train RMSE 0.3377549026804856 Validation RMSE 16090 : 0.35884182417077615 max of weights 1.957445475906594
Iteration 16100 loss 0.7391635098392887 train RMSE 0.33800470798609755 Validation RMSE 16100 : 0.3540473134034592 max of weights 1.958240810876743
Iteration 16110 loss 0.7559832174376414 train RMSE 0.34575407905373856 Validation RMSE 16110 : 0.3571977203292193 max of weights 1.9594983749947161
Iteration 16120 loss 0.7697597943657268 train RMSE 0.35209573820177753 Validation RMSE 16120 : 0.3577033830253157 max of weights 1.9686087507081202
Iteration 16130 loss 0.7530947412002388 train RMSE 0.3444212907518347 Validation RMSE 16130 : 0.35532638151609264 max of weights 1.9703997632198393
Iteration 16140 loss 0.7396905449970056 train RMSE 0.33824536749961887 Validation RMSE 16140 : 0.3568748214283105 max of weights 1.9694245664275214
Iteration 16150 loss 0.7568377331309445 train RMSE 0.34613769567845176 Validation RMSE 16150 : 0.35534913218073927 max of weights 1.9669317464295941
Iteration 16160 loss 0.7745415166189418 train RMSE 0.35428216679623026 Validation RMSE 16160 : 0.35831493419189075 max of weights 1.962354666197023
Iteration 16170 loss 0.7692919412177609 train RMSE 0.3518638344884533 Validation RMSE 16170 : 0.35523800290607876 max of weights 1.9595418196045946
Iteration 16180 loss 0.7726961259125478 train RMSE 0.35342723147078664 Validation RMSE 16180 : 0.35852214850967035 max of weights 1.9556654546208831
Iteration 16190 loss 0.7789798964534578 train RMSE 0.356314758421128 Validation RMSE 16190 : 0.35497144310359496 max of weights 1.9506572878892225
Iteration 16200 loss 0.7745418242143259 train RMSE 0.35427264443000916 Validation RMSE 16200 : 0.35798482073651744 max of weights 1.9610043190051065
Iteration 16210 loss 0.7500824078828068 train RMSE 0.343018270763524 Validation RMSE 16210 : 0.35450911286609077 max of weights 1.9652979641041857
Iteration 16220 loss 0.742458391497592 train RMSE 0.3395018480782048 Validation RMSE 16220 : 0.35678782989209484 max of weights 1.96283830674801
Iteration 16230 loss 0.740154804646792 train RMSE 0.33844146320709345 Validation RMSE 16230 : 0.35472727787732694 max of weights 1.9558567133241465
Iteration 16240 loss 0.7438171521988787 train RMSE 0.3401222526918134 Validation RMSE 16240 : 0.35380151147507005 max of weights 1.947557922789545
Iteration 16250 loss 0.7636667374620428 train RMSE 0.3492497395461486 Validation RMSE 16250 : 0.35355076576608996 max of weights 1.9431696800815865
Iteration 16260 loss 0.7835617945155298 train RMSE 0.358392080959727 Validation RMSE 16260 : 0.35539322246863475 max of weights 1.9490280115807035
Iteration 16270 loss 0.7864006696220587 train RMSE 0.3596956383552102 Validation RMSE 16270 : 0.35720052724217893 max of weights 1.957489448006861
Iteration 16280 loss 0.7834450037886073 train RMSE 0.3583347953097764 Validation RMSE 16280 : 0.35903921311517883 max of weights 1.9688454502905635
Iteration 16290 loss 0.7764686584945574 train RMSE 0.35512626126919145 Validation RMSE 16290 : 0.35770462693834476 max of weights 1.9793608789217745
Iteration 16300 loss 0.7730831476032863 train RMSE 0.35357426262779046 Validation RMSE 16300 : 0.35883953893597825 max of weights 1.9829912373377814
Iteration 16310 loss 0.7673133173848367 train RMSE 0.3509188783910887 Validation RMSE 16310 : 0.35892272174680445 max of weights 1.9793848240440843
Iteration 16320 loss 0.745161269281688 train RMSE 0.34072810227574396 Validation RMSE 16320 : 0.3550856238677617 max of weights 1.980992284343076
Iteration 16330 loss 0.7118925993529656 train RMSE 0.32541918323567137 Validation RMSE 16330 : 0.35624566942459285 max of weights 1.9822224836259836
Iteration 16340 loss 0.7241607079700586 train RMSE 0.3310613967587337 Validation RMSE 16340 : 0.3581217200027943 max of weights 1.9821995173329234
Iteration 16350 loss 0.7472332667759377 train RMSE 0.3416720982726664 Validation RMSE 16350 : 0.36321216114010135 max of weights 1.9791160064959619
Iteration 16360 loss 0.7418380252325903 train RMSE 0.3391925372729751 Validation RMSE 16360 : 0.35561571460909397 max of weights 1.9739592623788251
Iteration 16370 loss 0.7463364927318475 train RMSE 0.34126161132844995 Validation RMSE 16370 : 0.35606957091272645 max of weights 1.974679061858998
Iteration 16380 loss 0.7451904077376829 train RMSE 0.3407341514973001 Validation RMSE 16380 : 0.3551778081786183 max of weights 1.9697095887294254
Iteration 16390 loss 0.7422914711672894 train RMSE 0.33940242968532625 Validation RMSE 16390 : 0.3555623103555796 max of weights 1.9657106633648387
Iteration 16400 loss 0.735959271500488 train RMSE 0.3364937800431463 Validation RMSE 16400 : 0.3552951159939093 max of weights 1.9542585349630193
Iteration 16410 loss 0.7307474227534813 train RMSE 0.3340939938286543 Validation RMSE 16410 : 0.3552788616197634 max of weights 1.9481550305449067
Iteration 16420 loss 0.7238842613617377 train RMSE 0.3309297017911538 Validation RMSE 16420 : 0.3542069947693313 max of weights 1.9449316114791366
Iteration 16430 loss 0.7376375621708007 train RMSE 0.337246254930299 Validation RMSE 16430 : 0.35416809832453244 max of weights 1.9449068980235238
Iteration 16440 loss 0.7628487860623886 train RMSE 0.3488448939889641 Validation RMSE 16440 : 0.3554464588117843 max of weights 1.9454632280059199
Iteration 16450 loss 0.747596228963248 train RMSE 0.34182895701161975 Validation RMSE 16450 : 0.35455272366766283 max of weights 1.9473915051298818
Iteration 16460 loss 0.7549138420977008 train RMSE 0.3451982060370248 Validation RMSE 16460 : 0.35305185490200536 max of weights 1.9513172426876337
Iteration 16470 loss 0.7687451577870426 train RMSE 0.3515622442443546 Validation RMSE 16470 : 0.35659838179275394 max of weights 1.9604913993728221
Iteration 16480 loss 0.7802012035316466 train RMSE 0.35682939266785824 Validation RMSE 16480 : 0.3567025750393234 max of weights 1.9673938511663367
Iteration 16490 loss 0.7923449539943535 train RMSE 0.36242489165710656 Validation RMSE 16490 : 0.3559050018879097 max of weights 1.9654799801038316
Iteration 16500 loss 0.8058237208315484 train RMSE 0.3686276274908659 Validation RMSE 16500 : 0.3568994902884697 max of weights 1.973791376206137
Iteration 16510 loss 0.7900365202096109 train RMSE 0.3613585090099609 Validation RMSE 16510 : 0.35447082977633604 max of weights 1.9839208783912035
Iteration 16520 loss 0.7784636262605836 train RMSE 0.35603323914839097 Validation RMSE 16520 : 0.3538981115603424 max of weights 1.9908591692383548
Iteration 16530 loss 0.7850414367825874 train RMSE 0.3590651614062504 Validation RMSE 16530 : 0.35485130485724453 max of weights 2.0033452833764485
Iteration 16540 loss 0.8270572958633313 train RMSE 0.3783987205028529 Validation RMSE 16540 : 0.36862522592678415 max of weights 2.0048082162816874
Iteration 16550 loss 0.7958652309641777 train RMSE 0.36404759402558395 Validation RMSE 16550 : 0.3563074313684284 max of weights 2.007598532307186
Iteration 16560 loss 0.7809954483201338 train RMSE 0.35719747723708406 Validation RMSE 16560 : 0.35845872955380215 max of weights 2.0076384119497526
Iteration 16570 loss 0.7780350649403627 train RMSE 0.3558348315093147 Validation RMSE 16570 : 0.3550149262755026 max of weights 2.01686531781073
Iteration 16580 loss 0.7962491943025285 train RMSE 0.36421890016181657 Validation RMSE 16580 : 0.3560995720835772 max of weights 2.024921994859762
Iteration 16590 loss 0.789298024324268 train RMSE 0.3610138993230211 Validation RMSE 16590 : 0.3556660115347683 max of weights 2.026682796861458
Iteration 16600 loss 0.7797359630773016 train RMSE 0.3566092775597037 Validation RMSE 16600 : 0.3535487739697119 max of weights 2.025320011992913
Iteration 16610 loss 0.8113116428543334 train RMSE 0.37113075866203704 Validation RMSE 16610 : 0.3577851106085556 max of weights 2.022394535372439
Iteration 16620 loss 0.8113818625408131 train RMSE 0.3711536605000567 Validation RMSE 16620 : 0.3658840762534873 max of weights 2.024038388983468
Iteration 16630 loss 0.7675834522233032 train RMSE 0.35099904871618437 Validation RMSE 16630 : 0.3559384913850238 max of weights 2.028084432716187
Iteration 16640 loss 0.7780419778809846 train RMSE 0.35581935710906015 Validation RMSE 16640 : 0.3540270849962861 max of weights 2.0388829273439417
Iteration 16650 loss 0.7675160948056601 train RMSE 0.35098034544727624 Validation RMSE 16650 : 0.3552973633531357 max of weights 2.0453960607031068
Iteration 16660 loss 0.7448047865998935 train RMSE 0.34052779970458696 Validation RMSE 16660 : 0.3508926470999646 max of weights 2.049308262343301
Iteration 16670 loss 0.7441529664919131 train RMSE 0.34022222192836205 Validation RMSE 16670 : 0.35101546413914747 max of weights 2.0510045958945664
Iteration 16680 loss 0.7554303402557719 train RMSE 0.3454185825706297 Validation RMSE 16680 : 0.35036562744799665 max of weights 2.054846754195876
Iteration 16690 loss 0.7442693206432529 train RMSE 0.3402814024208822 Validation RMSE 16690 : 0.35175243661925204 max of weights 2.0523604642066804
Iteration 16700 loss 0.7525741010848589 train RMSE 0.3441001405349078 Validation RMSE 16700 : 0.3505648073951003 max of weights 2.0478542848862133
Iteration 16710 loss 0.7692732977653355 train RMSE 0.3517813856856252 Validation RMSE 16710 : 0.3528495682617218 max of weights 2.046723972765434
Iteration 16720 loss 0.7587877563808033 train RMSE 0.3469592767243901 Validation RMSE 16720 : 0.353024324511909 max of weights 2.0463773400317677
Iteration 16730 loss 0.7450882229490713 train RMSE 0.3406508286430434 Validation RMSE 16730 : 0.3511984421058368 max of weights 2.043656542908914
Iteration 16740 loss 0.7699797271278519 train RMSE 0.35209983974791764 Validation RMSE 16740 : 0.35604978913962515 max of weights 2.0437097237718667
Iteration 16750 loss 0.7745539720756024 train RMSE 0.35420920135039585 Validation RMSE 16750 : 0.3534220904338002 max of weights 2.044966688321744
Iteration 16760 loss 0.7413642671904869 train RMSE 0.33893267641065006 Validation RMSE 16760 : 0.350266034800417 max of weights 2.0402795254625308
Iteration 16770 loss 0.7519892314793875 train RMSE 0.3438223566985303 Validation RMSE 16770 : 0.3507608438201224 max of weights 2.039527866005901
Iteration 16780 loss 0.7504450899212153 train RMSE 0.34311065399899926 Validation RMSE 16780 : 0.3523309661730012 max of weights 2.0366842400283867
Iteration 16790 loss 0.7448497494137573 train RMSE 0.3405343543294039 Validation RMSE 16790 : 0.3519665612636718 max of weights 2.0369338308906997
Iteration 16800 loss 0.7589083174570646 train RMSE 0.3469979031971096 Validation RMSE 16800 : 0.3523562807986286 max of weights 2.041040573373623
Iteration 16810 loss 0.7348769855328554 train RMSE 0.33593676810915896 Validation RMSE 16810 : 0.3478944759238323 max of weights 2.0378366908454453
Iteration 16820 loss 0.741855973147618 train RMSE 0.33913870672271196 Validation RMSE 16820 : 0.3600963682452192 max of weights 2.030477321007946
Iteration 16830 loss 0.7590844651713476 train RMSE 0.3470592147327328 Validation RMSE 16830 : 0.35102958002177304 max of weights 2.0265933979861783
Iteration 16840 loss 0.7874522544710487 train RMSE 0.360108801622736 Validation RMSE 16840 : 0.35607214722343095 max of weights 2.0254562689141737
Iteration 16850 loss 0.7778495274085069 train RMSE 0.3556987522802014 Validation RMSE 16850 : 0.3509451989810169 max of weights 2.0290001473257946
Iteration 16860 loss 0.7542739138599509 train RMSE 0.3448560026231162 Validation RMSE 16860 : 0.35028821237982166 max of weights 2.0322087322667435
Iteration 16870 loss 0.7662308023071888 train RMSE 0.3503594183912653 Validation RMSE 16870 : 0.3549685504218007 max of weights 2.0385384185063233
Iteration 16880 loss 0.7537057652253216 train RMSE 0.34459009261521945 Validation RMSE 16880 : 0.3532647518110713 max of weights 2.0401067815039453
Iteration 16890 loss 0.7420400178434997 train RMSE 0.3392229055952897 Validation RMSE 16890 : 0.3521572041936498 max of weights 2.0389957554796925
Iteration 16900 loss 0.752373910715626 train RMSE 0.34398279822291356 Validation RMSE 16900 : 0.3526908952527361 max of weights 2.0391405531037754
Iteration 16910 loss 0.7614226702929799 train RMSE 0.34814734359322397 Validation RMSE 16910 : 0.35261591484266275 max of weights 2.0353352073375715
Iteration 16920 loss 0.78711921976202 train RMSE 0.359971810644089 Validation RMSE 16920 : 0.3579147942820481 max of weights 2.0336517496870714
Iteration 16930 loss 0.7659567708507514 train RMSE 0.3502332842953418 Validation RMSE 16930 : 0.3505723565573379 max of weights 2.035390042206016
Iteration 16940 loss 0.7789254600091164 train RMSE 0.3562036142643431 Validation RMSE 16940 : 0.3521989701911127 max of weights 2.034880381312492
Iteration 16950 loss 0.7657027201342327 train RMSE 0.3501171287594196 Validation RMSE 16950 : 0.3530985197580915 max of weights 2.0331025014375417
Iteration 16960 loss 0.7389489648910648 train RMSE 0.33780470467912227 Validation RMSE 16960 : 0.35335020312884763 max of weights 2.0308948993687648
Iteration 16970 loss 0.7562778728747965 train RMSE 0.345781383782157 Validation RMSE 16970 : 0.35274674924330945 max of weights 2.0325208438041003
Iteration 16980 loss 0.7410698350689284 train RMSE 0.33878809177119434 Validation RMSE 16980 : 0.35840989151695174 max of weights 2.0329982696391857
Iteration 16990 loss 0.7637308480288614 train RMSE 0.3492234943328604 Validation RMSE 16990 : 0.3615603951824505 max of weights 2.0328905453380295
Iteration 17000 loss 0.7292218390641276 train RMSE 0.3333417942644752 Validation RMSE 17000 : 0.3586862944525389 max of weights 2.0313516861844434
Iteration 17010 loss 0.7422642838660024 train RMSE 0.33934284376304524 Validation RMSE 17010 : 0.3552265333175005 max of weights 2.0347976731038515
Iteration 17020 loss 0.7628758064983318 train RMSE 0.3488213008941523 Validation RMSE 17020 : 0.3528784766774249 max of weights 2.0362949508869344
Iteration 17030 loss 0.7901705273402769 train RMSE 0.3613818798444519 Validation RMSE 17030 : 0.35440023212899585 max of weights 2.0388804052394436
Iteration 17040 loss 0.7832555321522807 train RMSE 0.35819579498069615 Validation RMSE 17040 : 0.35123673309424785 max of weights 2.039803667609318
Iteration 17050 loss 0.7788397727667886 train RMSE 0.3561516345313285 Validation RMSE 17050 : 0.35722618884868323 max of weights 2.035125110365083
Iteration 17060 loss 0.7858548252684294 train RMSE 0.35938456302521016 Validation RMSE 17060 : 0.3559808798744687 max of weights 2.036757103660855
Iteration 17070 loss 0.7636663266888305 train RMSE 0.34917581725709446 Validation RMSE 17070 : 0.3510668972964954 max of weights 2.041137465807987
Iteration 17080 loss 0.7576231284616224 train RMSE 0.3463957881224889 Validation RMSE 17080 : 0.34867807679865576 max of weights 2.0437984717735738
Iteration 17090 loss 0.758707534759389 train RMSE 0.346890210623401 Validation RMSE 17090 : 0.3511349059652653 max of weights 2.045370748398405
Iteration 17100 loss 0.7443291102637768 train RMSE 0.3402707603185743 Validation RMSE 17100 : 0.3487192638777749 max of weights 2.0428591395956834
Iteration 17110 loss 0.7652643612979804 train RMSE 0.3499076453005461 Validation RMSE 17110 : 0.3582687035050997 max of weights 2.043171590303839
Iteration 17120 loss 0.75570697903792 train RMSE 0.3455135326703254 Validation RMSE 17120 : 0.35240711431262184 max of weights 2.050022115198506
Iteration 17130 loss 0.7672671681195223 train RMSE 0.350834082821128 Validation RMSE 17130 : 0.3527243368916388 max of weights 2.0544477989995045
Iteration 17140 loss 0.7536043000232892 train RMSE 0.34454771619614766 Validation RMSE 17140 : 0.3516189532793391 max of weights 2.067936578775429
Iteration 17150 loss 0.7288266247351481 train RMSE 0.33314177370947295 Validation RMSE 17150 : 0.35135247581223433 max of weights 2.0702977819335615
Iteration 17160 loss 0.7348633802400297 train RMSE 0.33591644843568846 Validation RMSE 17160 : 0.35237188715453105 max of weights 2.075353686819168
Iteration 17170 loss 0.7358955533638485 train RMSE 0.33638884756307175 Validation RMSE 17170 : 0.3533840657560874 max of weights 2.0791752933401586
Iteration 17180 loss 0.7340029041705552 train RMSE 0.3355165733122092 Validation RMSE 17180 : 0.35384797687103947 max of weights 2.0760941661668313
Iteration 17190 loss 0.7396226191855558 train RMSE 0.3381010632767435 Validation RMSE 17190 : 0.3547528917494994 max of weights 2.070724776308525
Iteration 17200 loss 0.7237685042149252 train RMSE 0.3308010965189419 Validation RMSE 17200 : 0.35529208729445205 max of weights 2.0688789081680223
Iteration 17210 loss 0.7352258848201756 train RMSE 0.3360704550735941 Validation RMSE 17210 : 0.3547463143153895 max of weights 2.069178338906008
Iteration 17220 loss 0.7743129580112386 train RMSE 0.354058845234834 Validation RMSE 17220 : 0.35406363565342713 max of weights 2.073273684865471
Iteration 17230 loss 0.7832361653803824 train RMSE 0.3581661547872916 Validation RMSE 17230 : 0.3558849309065993 max of weights 2.0773115433451372
Iteration 17240 loss 0.7683375915639016 train RMSE 0.3513147033995868 Validation RMSE 17240 : 0.3534667756326684 max of weights 2.0742148147342903
Iteration 17250 loss 0.7470610080706649 train RMSE 0.34152367408697687 Validation RMSE 17250 : 0.3551161540733191 max of weights 2.07160998866001
Iteration 17260 loss 0.7574931209868274 train RMSE 0.3463276971443776 Validation RMSE 17260 : 0.35150084172735585 max of weights 2.0718708945455107
Iteration 17270 loss 0.766793873238827 train RMSE 0.35061066678285246 Validation RMSE 17270 : 0.3535766926696277 max of weights 2.0739188014291496
Iteration 17280 loss 0.7469317417035011 train RMSE 0.34146201687768774 Validation RMSE 17280 : 0.3544593342528113 max of weights 2.068780872408305
Iteration 17290 loss 0.7531319177167318 train RMSE 0.3443115784581418 Validation RMSE 17290 : 0.35280616413765825 max of weights 2.062898739223019
Iteration 17300 loss 0.7770843204511974 train RMSE 0.3553354366537931 Validation RMSE 17300 : 0.3538841751619717 max of weights 2.06011687719343
Iteration 17310 loss 0.7658457960971602 train RMSE 0.3501623060477975 Validation RMSE 17310 : 0.3531235668410087 max of weights 2.057805368630399
Iteration 17320 loss 0.7607205010911452 train RMSE 0.3477952568104908 Validation RMSE 17320 : 0.35535984483242583 max of weights 2.0579676870632033
Iteration 17330 loss 0.7503999471426966 train RMSE 0.3430465661162101 Validation RMSE 17330 : 0.35356120909973804 max of weights 2.0594490703339656
Iteration 17340 loss 0.7414683009216029 train RMSE 0.3389389574534266 Validation RMSE 17340 : 0.3533460677120486 max of weights 2.0594952723666635
Iteration 17350 loss 0.7252359569117656 train RMSE 0.3314785470141427 Validation RMSE 17350 : 0.3524821067806084 max of weights 2.0588810079798314
Iteration 17360 loss 0.727078722206144 train RMSE 0.3323287376580244 Validation RMSE 17360 : 0.35207726540316564 max of weights 2.0525105465374005
Iteration 17370 loss 0.7308477931980063 train RMSE 0.33405815791896515 Validation RMSE 17370 : 0.35349389951843496 max of weights 2.051186467950794
Iteration 17380 loss 0.7215769898178371 train RMSE 0.32980021614194205 Validation RMSE 17380 : 0.3525895111525604 max of weights 2.0519616917602677
Iteration 17390 loss 0.7345144764925382 train RMSE 0.33575793455395625 Validation RMSE 17390 : 0.3515774629962875 max of weights 2.0526633429679735
Iteration 17400 loss 0.756334589120843 train RMSE 0.3457928348289955 Validation RMSE 17400 : 0.3553249863094512 max of weights 2.0509518342042514
Iteration 17410 loss 0.7661706880731098 train RMSE 0.35032176794341724 Validation RMSE 17410 : 0.35407548024774455 max of weights 2.0615458978920556
Iteration 17420 loss 0.776793530803335 train RMSE 0.3552118435520661 Validation RMSE 17420 : 0.3550500054178408 max of weights 2.064358848346961
Iteration 17430 loss 0.7751343467264616 train RMSE 0.3544454468656834 Validation RMSE 17430 : 0.35588454576699796 max of weights 2.071229414411114
Iteration 17440 loss 0.7811004047599586 train RMSE 0.35719282375219935 Validation RMSE 17440 : 0.35935359114270005 max of weights 2.0755543430213503
Iteration 17450 loss 0.7505381488389776 train RMSE 0.34313360275872506 Validation RMSE 17450 : 0.35651019399454575 max of weights 2.0785707309343873
Iteration 17460 loss 0.727317659422604 train RMSE 0.3324465467322341 Validation RMSE 17460 : 0.3557793535447397 max of weights 2.0772923731370803
Iteration 17470 loss 0.7298681360156719 train RMSE 0.33361395177572356 Validation RMSE 17470 : 0.3564503733794007 max of weights 2.0648390942742054
Iteration 17480 loss 0.7558991712663271 train RMSE 0.34558502012931763 Validation RMSE 17480 : 0.3573978200348326 max of weights 2.061380227736712
Iteration 17490 loss 0.7692449065955296 train RMSE 0.3517235851027407 Validation RMSE 17490 : 0.35705917178721 max of weights 2.066465099728103
Iteration 17500 loss 0.7622709131029234 train RMSE 0.348512035111711 Validation RMSE 17500 : 0.35519894247783246 max of weights 2.079765378099958
Iteration 17510 loss 0.7527725019626725 train RMSE 0.34414331659028524 Validation RMSE 17510 : 0.3540065825410362 max of weights 2.0873290709219483
Iteration 17520 loss 0.7357598149243247 train RMSE 0.33631730153421635 Validation RMSE 17520 : 0.3541980266527276 max of weights 2.088390721479575
Iteration 17530 loss 0.7308755323022372 train RMSE 0.3340651489672486 Validation RMSE 17530 : 0.35358903298784305 max of weights 2.084619128124389
Iteration 17540 loss 0.738036606127981 train RMSE 0.3373645723864965 Validation RMSE 17540 : 0.3557487627801074 max of weights 2.086891398336876
Iteration 17550 loss 0.7394740417085053 train RMSE 0.3380364167954548 Validation RMSE 17550 : 0.3524791729566681 max of weights 2.0848432016997114
Iteration 17560 loss 0.7585176926367272 train RMSE 0.3468053317078724 Validation RMSE 17560 : 0.35650583469235314 max of weights 2.0860857626034783
Iteration 17570 loss 0.763504746971886 train RMSE 0.3490999765801156 Validation RMSE 17570 : 0.35485058302645134 max of weights 2.0894821882519534
Iteration 17580 loss 0.7460884566295057 train RMSE 0.34107789129567695 Validation RMSE 17580 : 0.3543084180251834 max of weights 2.089120858083395
Iteration 17590 loss 0.7480347926942956 train RMSE 0.34196576691997327 Validation RMSE 17590 : 0.3553134812820973 max of weights 2.0947294295050165
Iteration 17600 loss 0.7682689140626962 train RMSE 0.3512768146788793 Validation RMSE 17600 : 0.3543033039454186 max of weights 2.0945493407677356
Iteration 17610 loss 0.7752213529013644 train RMSE 0.35447237838631435 Validation RMSE 17610 : 0.3579139705222959 max of weights 2.09640394825056
Iteration 17620 loss 0.7732186617052045 train RMSE 0.35354761129542783 Validation RMSE 17620 : 0.35468962005216215 max of weights 2.094493441423626
Iteration 17630 loss 0.7726490593697001 train RMSE 0.35327873880108146 Validation RMSE 17630 : 0.3553386553264617 max of weights 2.0915797943957433
Iteration 17640 loss 0.778702448450795 train RMSE 0.35606067323612683 Validation RMSE 17640 : 0.35425298175885445 max of weights 2.085715876440004
Iteration 17650 loss 0.7622722454844081 train RMSE 0.3485003355210205 Validation RMSE 17650 : 0.3569231428288515 max of weights 2.0889448814098115
Iteration 17660 loss 0.7400335364757074 train RMSE 0.3382621129054028 Validation RMSE 17660 : 0.35543992239741945 max of weights 2.0866325185544814
Iteration 17670 loss 0.734643797248053 train RMSE 0.3357747109473087 Validation RMSE 17670 : 0.35632779291728667 max of weights 2.082960565412782
Iteration 17680 loss 0.7381518181016213 train RMSE 0.33739070496065615 Validation RMSE 17680 : 0.3525846322380488 max of weights 2.0827003298613995
Iteration 17690 loss 0.7486155507057044 train RMSE 0.3422002213233581 Validation RMSE 17690 : 0.35189856577468226 max of weights 2.0744657366448775
Iteration 17700 loss 0.7678389931814766 train RMSE 0.35103855732348593 Validation RMSE 17700 : 0.35302313126100093 max of weights 2.0768850451786234
Iteration 17710 loss 0.7821772170973411 train RMSE 0.357626383208717 Validation RMSE 17710 : 0.35511585387434036 max of weights 2.086241471162316
Iteration 17720 loss 0.7844220327104374 train RMSE 0.3586592456449656 Validation RMSE 17720 : 0.3569508972344391 max of weights 2.0928849472447393
Iteration 17730 loss 0.7712184348737912 train RMSE 0.35258152059202985 Validation RMSE 17730 : 0.35628814243891793 max of weights 2.106072973806508
Iteration 17740 loss 0.7669179303482111 train RMSE 0.350604882852898 Validation RMSE 17740 : 0.3565160320483354 max of weights 2.1105857928961718
Iteration 17750 loss 0.7672026062411929 train RMSE 0.3507419588711999 Validation RMSE 17750 : 0.3565747936080142 max of weights 2.109496257312348
Iteration 17760 loss 0.7570673438062655 train RMSE 0.3460792784657416 Validation RMSE 17760 : 0.35593052434807515 max of weights 2.1055866657261593
Iteration 17770 loss 0.7362463846720827 train RMSE 0.33650230286203586 Validation RMSE 17770 : 0.3536783472128763 max of weights 2.108418250969256
Iteration 17780 loss 0.7060406541928447 train RMSE 0.3226021475013342 Validation RMSE 17780 : 0.35627177663705656 max of weights 2.1096991179205142
Iteration 17790 loss 0.7292189175945591 train RMSE 0.3332639902431455 Validation RMSE 17790 : 0.35813900667504606 max of weights 2.110172169278881
Iteration 17800 loss 0.7383472277525729 train RMSE 0.33746197048091275 Validation RMSE 17800 : 0.3587899647488413 max of weights 2.103888347043174
Iteration 17810 loss 0.723284580372834 train RMSE 0.33053389521563814 Validation RMSE 17810 : 0.3544034122342465 max of weights 2.1015807164942393
Iteration 17820 loss 0.7413775939219521 train RMSE 0.33885717285976036 Validation RMSE 17820 : 0.3562557261380294 max of weights 2.1000366636720815
Iteration 17830 loss 0.7340850123284811 train RMSE 0.33550270036488755 Validation RMSE 17830 : 0.3536629229591934 max of weights 2.0944118676653645
Iteration 17840 loss 0.7372816077109946 train RMSE 0.3369760143372734 Validation RMSE 17840 : 0.3552582548653814 max of weights 2.091384837183738
Iteration 17850 loss 0.7315179132023809 train RMSE 0.3343274328878599 Validation RMSE 17850 : 0.3540144112522005 max of weights 2.0825715538412095
Iteration 17860 loss 0.7283698721315426 train RMSE 0.33287315896798014 Validation RMSE 17860 : 0.3542379843947998 max of weights 2.0802720858127257
Iteration 17870 loss 0.719608491470998 train RMSE 0.32883355997868086 Validation RMSE 17870 : 0.35335260165169696 max of weights 2.0721271018269705
Iteration 17880 loss 0.7403872504137121 train RMSE 0.33838355327906305 Validation RMSE 17880 : 0.3534012194927048 max of weights 2.067025876947072
Iteration 17890 loss 0.74036507321062 train RMSE 0.3383742052663266 Validation RMSE 17890 : 0.3531478730487479 max of weights 2.0648069785920056
Iteration 17900 loss 0.7312659980408547 train RMSE 0.334189465902706 Validation RMSE 17900 : 0.35333060164777635 max of weights 2.0696801943291563
Iteration 17910 loss 0.7506144355205011 train RMSE 0.3430948605186724 Validation RMSE 17910 : 0.3524768380992505 max of weights 2.0800164549021627
Iteration 17920 loss 0.7574725544634284 train RMSE 0.34624483948879414 Validation RMSE 17920 : 0.355631371974753 max of weights 2.0911198737540126
Iteration 17930 loss 0.7701981582752621 train RMSE 0.3521016761574773 Validation RMSE 17930 : 0.3547802548618695 max of weights 2.0979033891294474
Iteration 17940 loss 0.7881888939815829 train RMSE 0.36038465334108394 Validation RMSE 17940 : 0.3548632219458687 max of weights 2.095458132425143
Iteration 17950 loss 0.8037348281278585 train RMSE 0.3675384250590972 Validation RMSE 17950 : 0.35627088612061203 max of weights 2.104476277575432
Iteration 17960 loss 0.7855335429027401 train RMSE 0.35915698432628135 Validation RMSE 17960 : 0.35493890962275443 max of weights 2.1091112565051664
Iteration 17970 loss 0.7707658146764732 train RMSE 0.3523660493378707 Validation RMSE 17970 : 0.351874895808023 max of weights 2.108420487805437
Iteration 17980 loss 0.7889435132615992 train RMSE 0.3607324569435526 Validation RMSE 17980 : 0.3561975437840152 max of weights 2.105928308378361
Iteration 17990 loss 0.8146378114072387 train RMSE 0.372556767405671 Validation RMSE 17990 : 0.3623862742928476 max of weights 2.1025570968207474
Iteration 18000 loss 0.7903804343670582 train RMSE 0.36139161355987476 Validation RMSE 18000 : 0.35361068132933043 max of weights 2.1034029983113354
Iteration 18010 loss 0.779425593594633 train RMSE 0.35634210255697885 Validation RMSE 18010 : 0.35648859854295095 max of weights 2.106814009696292
Iteration 18020 loss 0.7826310321272207 train RMSE 0.35781938421827153 Validation RMSE 18020 : 0.3537259526745297 max of weights 2.120501446922722
Iteration 18030 loss 0.7970971273924492 train RMSE 0.3644762746473678 Validation RMSE 18030 : 0.35625791517723265 max of weights 2.126391301214732
Iteration 18040 loss 0.7769572799756057 train RMSE 0.35520172279387074 Validation RMSE 18040 : 0.3540133498072403 max of weights 2.127753001452081
Iteration 18050 loss 0.7835408874872448 train RMSE 0.3582274937488697 Validation RMSE 18050 : 0.3530733714705879 max of weights 2.1264873705865104
Iteration 18060 loss 0.8190775700092676 train RMSE 0.37457220793075957 Validation RMSE 18060 : 0.36233051887883494 max of weights 2.1228187687833557
Iteration 18070 loss 0.7940391790877023 train RMSE 0.36304126907802337 Validation RMSE 18070 : 0.36589426915520334 max of weights 2.1233036947672166
Iteration 18080 loss 0.7649090654197226 train RMSE 0.3496399335172972 Validation RMSE 18080 : 0.3536879032506135 max of weights 2.132504459278451
Iteration 18090 loss 0.771932760152513 train RMSE 0.3528788270947261 Validation RMSE 18090 : 0.35454466693026065 max of weights 2.1396730678896767
Iteration 18100 loss 0.7519158622318993 train RMSE 0.3436706552350328 Validation RMSE 18100 : 0.35328590483281314 max of weights 2.143294184226469
Iteration 18110 loss 0.7298471837163827 train RMSE 0.3335131431912456 Validation RMSE 18110 : 0.3499757940442414 max of weights 2.1437756707363786
Iteration 18120 loss 0.7371129049780699 train RMSE 0.3368547131929293 Validation RMSE 18120 : 0.35063432674997036 max of weights 2.145557870841172
Iteration 18130 loss 0.7527125624078738 train RMSE 0.3440417128942102 Validation RMSE 18130 : 0.35208204042979674 max of weights 2.1490500925766916
Iteration 18140 loss 0.7375146883191336 train RMSE 0.3370481793495139 Validation RMSE 18140 : 0.35289958585214143 max of weights 2.1466559428261975
Iteration 18150 loss 0.7469731577934036 train RMSE 0.34139459188434357 Validation RMSE 18150 : 0.35121278318374916 max of weights 2.144142547554708
Iteration 18160 loss 0.7485970703900058 train RMSE 0.3421437221709101 Validation RMSE 18160 : 0.35226797816683764 max of weights 2.145605859264976
Iteration 18170 loss 0.7381083631095201 train RMSE 0.3373202681682339 Validation RMSE 18170 : 0.351377017162359 max of weights 2.1451782174887866
Iteration 18180 loss 0.731331330743682 train RMSE 0.3341962751057366 Validation RMSE 18180 : 0.35027974745213014 max of weights 2.141069530659269
Iteration 18190 loss 0.7605630725556755 train RMSE 0.34764822247769545 Validation RMSE 18190 : 0.35609148612607805 max of weights 2.1429407865758994
Iteration 18200 loss 0.7530380255243844 train RMSE 0.34418808655627225 Validation RMSE 18200 : 0.35125286954449253 max of weights 2.1419123612804474
Iteration 18210 loss 0.7328959099916494 train RMSE 0.334916354340992 Validation RMSE 18210 : 0.34807927001153127 max of weights 2.1385536970448356
Iteration 18220 loss 0.7473982362044352 train RMSE 0.34158942538050385 Validation RMSE 18220 : 0.35110906963929106 max of weights 2.138182446488626
Iteration 18230 loss 0.7461187378842707 train RMSE 0.3409983929626399 Validation RMSE 18230 : 0.35245897174649315 max of weights 2.1341139770629214
Iteration 18240 loss 0.7418564511384605 train RMSE 0.3390348389245964 Validation RMSE 18240 : 0.350385190724448 max of weights 2.135642847367268
Iteration 18250 loss 0.7457090907141061 train RMSE 0.340803146983664 Validation RMSE 18250 : 0.3494010410296152 max of weights 2.138872971325955
Iteration 18260 loss 0.7231158142586768 train RMSE 0.33040259542838474 Validation RMSE 18260 : 0.34783932224256037 max of weights 2.133076288188312
Iteration 18270 loss 0.7346204201702348 train RMSE 0.33568762504685834 Validation RMSE 18270 : 0.3537719598615809 max of weights 2.126110379742583
Iteration 18280 loss 0.7664592796758851 train RMSE 0.3503324926176625 Validation RMSE 18280 : 0.3509060866177888 max of weights 2.122209403068454
Iteration 18290 loss 0.7811101179419587 train RMSE 0.3570754924687402 Validation RMSE 18290 : 0.350817255536307 max of weights 2.1227957456496656
Iteration 18300 loss 0.7757944439150762 train RMSE 0.3546357404692133 Validation RMSE 18300 : 0.34904992179250566 max of weights 2.1258453170494795
Iteration 18310 loss 0.7557839588518391 train RMSE 0.34543087815583107 Validation RMSE 18310 : 0.35007984852947527 max of weights 2.132826961325996
Iteration 18320 loss 0.7626427170269875 train RMSE 0.34858579668596723 Validation RMSE 18320 : 0.3519181442083795 max of weights 2.1381567678840154
Iteration 18330 loss 0.7578381140695852 train RMSE 0.34636918142726353 Validation RMSE 18330 : 0.3517759445706126 max of weights 2.1384250670904414
Iteration 18340 loss 0.7462477838819018 train RMSE 0.34103824654523335 Validation RMSE 18340 : 0.35023306698501955 max of weights 2.1383774832561424
Iteration 18350 loss 0.7541253806763084 train RMSE 0.3446676736111228 Validation RMSE 18350 : 0.35111445181961864 max of weights 2.1359697836917277
Iteration 18360 loss 0.7716276911857259 train RMSE 0.35272044403978575 Validation RMSE 18360 : 0.3538009445974879 max of weights 2.128915718197603
Iteration 18370 loss 0.7789416719421994 train RMSE 0.35608547343487623 Validation RMSE 18370 : 0.3533961114945861 max of weights 2.1293977500640855
Iteration 18380 loss 0.7675724187595115 train RMSE 0.3508552685764475 Validation RMSE 18380 : 0.3495438203702073 max of weights 2.131474786530475
Iteration 18390 loss 0.7674954542442239 train RMSE 0.3508231565500428 Validation RMSE 18390 : 0.35068169998877724 max of weights 2.12934882711188
Iteration 18400 loss 0.755635276967627 train RMSE 0.3453607446527892 Validation RMSE 18400 : 0.35448185942479143 max of weights 2.127038804725087
Iteration 18410 loss 0.7474937371876251 train RMSE 0.3416146969157247 Validation RMSE 18410 : 0.35358195299996453 max of weights 2.1224166938158593
Iteration 18420 loss 0.7487398918798726 train RMSE 0.34219293565104136 Validation RMSE 18420 : 0.3515592031195664 max of weights 2.123245813549702
Iteration 18430 loss 0.7308208202273315 train RMSE 0.33395065831627463 Validation RMSE 18430 : 0.35659501318028347 max of weights 2.1234186131365993
Iteration 18440 loss 0.7455393823897862 train RMSE 0.3407292898102427 Validation RMSE 18440 : 0.357624266518254 max of weights 2.121553613469917
Iteration 18450 loss 0.7321774239367576 train RMSE 0.33457835803046093 Validation RMSE 18450 : 0.35950552123924695 max of weights 2.1203289801319487
Iteration 18460 loss 0.746550023359692 train RMSE 0.3411894744151581 Validation RMSE 18460 : 0.354199949150911 max of weights 2.121671622365018
Iteration 18470 loss 0.7714736796650454 train RMSE 0.35265530363830055 Validation RMSE 18470 : 0.35272923242014825 max of weights 2.121508496004656
Iteration 18480 loss 0.7872707389954644 train RMSE 0.3599256238670136 Validation RMSE 18480 : 0.352532911850112 max of weights 2.1242776166803092
Iteration 18490 loss 0.776777634357148 train RMSE 0.3550873387828729 Validation RMSE 18490 : 0.35398829692689754 max of weights 2.1235028038990222
Iteration 18500 loss 0.7770725385367855 train RMSE 0.35521804070285223 Validation RMSE 18500 : 0.35527101232049585 max of weights 2.1215768733507754
Iteration 18510 loss 0.7785385045090645 train RMSE 0.3558988582052734 Validation RMSE 18510 : 0.35465263864915925 max of weights 2.1246872220560777
Iteration 18520 loss 0.7672476073661926 train RMSE 0.3507039947887343 Validation RMSE 18520 : 0.351358840815053 max of weights 2.1284166327024043
Iteration 18530 loss 0.7652173310883948 train RMSE 0.3497697604872821 Validation RMSE 18530 : 0.35086652234632904 max of weights 2.126656054259523
Iteration 18540 loss 0.7543637411869029 train RMSE 0.3447718299674921 Validation RMSE 18540 : 0.3481701938931479 max of weights 2.1292979432497354
Iteration 18550 loss 0.7449689763036166 train RMSE 0.3404492284556687 Validation RMSE 18550 : 0.3487335443313804 max of weights 2.1279722440768687
Iteration 18560 loss 0.7667970274874291 train RMSE 0.3504966384838944 Validation RMSE 18560 : 0.35356691835527676 max of weights 2.1324773094286025
Iteration 18570 loss 0.7667390881146116 train RMSE 0.35046941225539224 Validation RMSE 18570 : 0.35276162911173015 max of weights 2.1400491449468677
Iteration 18580 loss 0.7524144976992919 train RMSE 0.34387799149815074 Validation RMSE 18580 : 0.34997854869345324 max of weights 2.146911609044777
Iteration 18590 loss 0.7554623276193643 train RMSE 0.3452775090961232 Validation RMSE 18590 : 0.3541215461281344 max of weights 2.1567066483438784
Iteration 18600 loss 0.72000713663751 train RMSE 0.32895802977923216 Validation RMSE 18600 : 0.35722577357371255 max of weights 2.1576623334009217
Iteration 18610 loss 0.735672294582392 train RMSE 0.3361663730214394 Validation RMSE 18610 : 0.35044984537314905 max of weights 2.1621637874632915
Iteration 18620 loss 0.7348731085982274 train RMSE 0.3357963594499039 Validation RMSE 18620 : 0.3517909482190854 max of weights 2.161917239796096
Iteration 18630 loss 0.7353902997628424 train RMSE 0.33603496921109494 Validation RMSE 18630 : 0.35342453430327564 max of weights 2.159354227175534
Iteration 18640 loss 0.7364944628148827 train RMSE 0.336538187818635 Validation RMSE 18640 : 0.3520119807894108 max of weights 2.1540058609874637
Iteration 18650 loss 0.7295587147771884 train RMSE 0.33333968191161145 Validation RMSE 18650 : 0.3586366989450124 max of weights 2.1552371989989
Iteration 18660 loss 0.7387477691525716 train RMSE 0.3375695573176914 Validation RMSE 18660 : 0.35054763591163807 max of weights 2.1576331115274994
Iteration 18670 loss 0.7800115917678236 train RMSE 0.3565596096027051 Validation RMSE 18670 : 0.35542757928256385 max of weights 2.1653054797517974
Iteration 18680 loss 0.7773042727308263 train RMSE 0.35531690890777773 Validation RMSE 18680 : 0.3548210599958548 max of weights 2.1675751882384744
Iteration 18690 loss 0.7562968905462414 train RMSE 0.3456516997070721 Validation RMSE 18690 : 0.3531290156353533 max of weights 2.1658337121197326
Iteration 18700 loss 0.7409890635658629 train RMSE 0.33860530974036085 Validation RMSE 18700 : 0.35496066921688374 max of weights 2.164975434771792
Iteration 18710 loss 0.758019240779479 train RMSE 0.3464496799611554 Validation RMSE 18710 : 0.3517206394597458 max of weights 2.1675700819598323
Iteration 18720 loss 0.7564913153396478 train RMSE 0.3457444011200588 Validation RMSE 18720 : 0.35252399326953343 max of weights 2.1680881127707123
Iteration 18730 loss 0.7376885338201363 train RMSE 0.33708487620995364 Validation RMSE 18730 : 0.35094785036728837 max of weights 2.1612609096426
Iteration 18740 loss 0.7535468989345081 train RMSE 0.34438011615591013 Validation RMSE 18740 : 0.351614823874614 max of weights 2.1560001491451763
Iteration 18750 loss 0.7764422558976686 train RMSE 0.35491934344838705 Validation RMSE 18750 : 0.35262996437930366 max of weights 2.154262556815391
Iteration 18760 loss 0.7551989226836731 train RMSE 0.3451409037812929 Validation RMSE 18760 : 0.35209822208182673 max of weights 2.1514313461391104
Iteration 18770 loss 0.7592282186946504 train RMSE 0.3469882859993827 Validation RMSE 18770 : 0.3545985274928695 max of weights 2.1562598440088445
Iteration 18780 loss 0.7347026499983453 train RMSE 0.33570501017022264 Validation RMSE 18780 : 0.3517309171810377 max of weights 2.1578032407563272
Iteration 18790 loss 0.7323194882134594 train RMSE 0.3346116625659093 Validation RMSE 18790 : 0.3521304854872269 max of weights 2.1568055531480543
Iteration 18800 loss 0.7169612629150285 train RMSE 0.3275541087373088 Validation RMSE 18800 : 0.3512926875300808 max of weights 2.1538854858402097
Iteration 18810 loss 0.7303897723658446 train RMSE 0.3337330984674128 Validation RMSE 18810 : 0.3505865093747793 max of weights 2.146498952271261
Iteration 18820 loss 0.7147869663268428 train RMSE 0.326554978340262 Validation RMSE 18820 : 0.35145987555340086 max of weights 2.1423340959939856
Iteration 18830 loss 0.7272318258094504 train RMSE 0.33228926520950963 Validation RMSE 18830 : 0.35241496355238505 max of weights 2.140376919624454
Iteration 18840 loss 0.7398768223335901 train RMSE 0.33811054199873797 Validation RMSE 18840 : 0.35008277442559393 max of weights 2.1387672555366444
Iteration 18850 loss 0.7505948008196738 train RMSE 0.3430379238621966 Validation RMSE 18850 : 0.35420495894534143 max of weights 2.152491846948873
Iteration 18860 loss 0.7551370824602354 train RMSE 0.34513407002363655 Validation RMSE 18860 : 0.3519416626984408 max of weights 2.1665199220644227
Iteration 18870 loss 0.7652494715724363 train RMSE 0.3497863747657693 Validation RMSE 18870 : 0.3542221105767706 max of weights 2.1795937102911624
Iteration 18880 loss 0.76506473305624 train RMSE 0.349697027057996 Validation RMSE 18880 : 0.35444365692149293 max of weights 2.181394016235879
Iteration 18890 loss 0.7649456484608352 train RMSE 0.3496446597381364 Validation RMSE 18890 : 0.35609254104294397 max of weights 2.1867501346875886
Iteration 18900 loss 0.7401238457733953 train RMSE 0.33822270672154536 Validation RMSE 18900 : 0.35565723181760855 max of weights 2.1917833157684523
Iteration 18910 loss 0.7240100053669335 train RMSE 0.33080392712078566 Validation RMSE 18910 : 0.35381662209629244 max of weights 2.1904955566454647
Iteration 18920 loss 0.7356733469875294 train RMSE 0.3361625209340616 Validation RMSE 18920 : 0.35654289776968723 max of weights 2.179936642156847
Iteration 18930 loss 0.7660988724790513 train RMSE 0.35016056870678447 Validation RMSE 18930 : 0.3566635207112729 max of weights 2.1739324481435642
Iteration 18940 loss 0.7678661362714176 train RMSE 0.35097075823077195 Validation RMSE 18940 : 0.3573116367888752 max of weights 2.1756725102223102
Iteration 18950 loss 0.7593936138700583 train RMSE 0.34707160208612386 Validation RMSE 18950 : 0.35430851290805326 max of weights 2.1862630650408827
Iteration 18960 loss 0.7530144976033798 train RMSE 0.34414187954709063 Validation RMSE 18960 : 0.35428050583242365 max of weights 2.1894729186190363
Iteration 18970 loss 0.7382520135126722 train RMSE 0.33734647499974796 Validation RMSE 18970 : 0.35483698285871734 max of weights 2.186825149131297
Iteration 18980 loss 0.7366638949554368 train RMSE 0.3366125329306855 Validation RMSE 18980 : 0.3558436489825475 max of weights 2.1840409405606067
Iteration 18990 loss 0.7395428782784077 train RMSE 0.33794318639772913 Validation RMSE 18990 : 0.35401864704484054 max of weights 2.1843664052293406
Iteration 19000 loss 0.7474052081619313 train RMSE 0.3415734695932195 Validation RMSE 19000 : 0.352448506545399 max of weights 2.180037160043945
Iteration 19010 loss 0.7623389487119437 train RMSE 0.3484517854618524 Validation RMSE 19010 : 0.3559887988800971 max of weights 2.186736876241927
Iteration 19020 loss 0.7652256936332579 train RMSE 0.3497776519054198 Validation RMSE 19020 : 0.3548615369490011 max of weights 2.1889401253524694
Iteration 19030 loss 0.7406208965704866 train RMSE 0.3384482548639491 Validation RMSE 19030 : 0.35323506972066854 max of weights 2.190159623973563
Iteration 19040 loss 0.7528577207247 train RMSE 0.344074848936648 Validation RMSE 19040 : 0.3527915793226164 max of weights 2.1940602623533625
Iteration 19050 loss 0.7675310768408735 train RMSE 0.3508247388231158 Validation RMSE 19050 : 0.35331770455691963 max of weights 2.192131172136955
Iteration 19060 loss 0.7690295921209279 train RMSE 0.35150924232347236 Validation RMSE 19060 : 0.35555468488416775 max of weights 2.195189355729446
Iteration 19070 loss 0.7756141801067968 train RMSE 0.35453546338963815 Validation RMSE 19070 : 0.3552649471695894 max of weights 2.189874586748459
Iteration 19080 loss 0.782359506962532 train RMSE 0.3576312617964915 Validation RMSE 19080 : 0.3536386976530937 max of weights 2.1869195775291344
Iteration 19090 loss 0.7820725727132943 train RMSE 0.35749642768766265 Validation RMSE 19090 : 0.3560852161083416 max of weights 2.1874808935547034
Iteration 19100 loss 0.757776312400037 train RMSE 0.346316663931613 Validation RMSE 19100 : 0.3550843542689226 max of weights 2.186733067668293
Iteration 19110 loss 0.7453592224845091 train RMSE 0.3405950587278071 Validation RMSE 19110 : 0.3544720179174674 max of weights 2.1824759855597646
Iteration 19120 loss 0.7402390818857107 train RMSE 0.3382324404618438 Validation RMSE 19120 : 0.35332858088946884 max of weights 2.180406026480182
Iteration 19130 loss 0.7483686991166042 train RMSE 0.3419732681625035 Validation RMSE 19130 : 0.3520180520394328 max of weights 2.1796187624456778
Iteration 19140 loss 0.758000170097277 train RMSE 0.3463996886210756 Validation RMSE 19140 : 0.3506026225919256 max of weights 2.1739998254335946
Iteration 19150 loss 0.7695639671282427 train RMSE 0.3517117307623364 Validation RMSE 19150 : 0.3514702597652945 max of weights 2.1809036275991995
Iteration 19160 loss 0.7808398933324492 train RMSE 0.35689093915115544 Validation RMSE 19160 : 0.3543047975710981 max of weights 2.188050514790683
Iteration 19170 loss 0.7889585635206832 train RMSE 0.36062493298032144 Validation RMSE 19170 : 0.3580820580278256 max of weights 2.1906036256642785
Iteration 19180 loss 0.771159773093384 train RMSE 0.35243565971017654 Validation RMSE 19180 : 0.35462375551818365 max of weights 2.1942509437670217
Iteration 19190 loss 0.7700866528523914 train RMSE 0.3519482792898524 Validation RMSE 19190 : 0.35652023623949947 max of weights 2.1930096850534992
Iteration 19200 loss 0.7624476197871298 train RMSE 0.3484372328748542 Validation RMSE 19200 : 0.355412200820366 max of weights 2.186439372384508
Iteration 19210 loss 0.7499037203315396 train RMSE 0.34266917490710014 Validation RMSE 19210 : 0.35390272133260836 max of weights 2.1816360091333977
Iteration 19220 loss 0.7190377817865172 train RMSE 0.3284691780283143 Validation RMSE 19220 : 0.35208109443788915 max of weights 2.182697521339023
Iteration 19230 loss 0.709107834925351 train RMSE 0.32389662441156447 Validation RMSE 19230 : 0.3558935713533478 max of weights 2.181781505570684
Iteration 19240 loss 0.7358578318261471 train RMSE 0.3362015744657974 Validation RMSE 19240 : 0.36056357793970395 max of weights 2.1787316245421433
Iteration 19250 loss 0.7317904062992348 train RMSE 0.3343296729167885 Validation RMSE 19250 : 0.3559786752957161 max of weights 2.167044164884405
Iteration 19260 loss 0.7177110466090477 train RMSE 0.32785192296279153 Validation RMSE 19260 : 0.3542902390428337 max of weights 2.165714678933521
Iteration 19270 loss 0.7269609678622626 train RMSE 0.3321073710203429 Validation RMSE 19270 : 0.35489503863488253 max of weights 2.162062549242718
Iteration 19280 loss 0.7224776853725209 train RMSE 0.33004586568782507 Validation RMSE 19280 : 0.3529024931238084 max of weights 2.1589622193960007
Iteration 19290 loss 0.7261558406890238 train RMSE 0.3317404313590775 Validation RMSE 19290 : 0.3528106854511342 max of weights 2.1515027307795624
Iteration 19300 loss 0.7276508855090696 train RMSE 0.33242889173531637 Validation RMSE 19300 : 0.3529697164614739 max of weights 2.1451340550909768
Iteration 19310 loss 0.7250087224976837 train RMSE 0.331207627103109 Validation RMSE 19310 : 0.3533155682721997 max of weights 2.1420694474130504
Iteration 19320 loss 0.719910578560856 train RMSE 0.32885327349458987 Validation RMSE 19320 : 0.3525985815062908 max of weights 2.137820645941647
Iteration 19330 loss 0.7413403100182122 train RMSE 0.3387063042766501 Validation RMSE 19330 : 0.35312176391476596 max of weights 2.142940046591526
Iteration 19340 loss 0.7294267706672737 train RMSE 0.3332279796100489 Validation RMSE 19340 : 0.3526984962369266 max of weights 2.1504492743915167
Iteration 19350 loss 0.7287969907250602 train RMSE 0.33294180418509495 Validation RMSE 19350 : 0.35221084230447636 max of weights 2.158805603958806
Iteration 19360 loss 0.7481000402469046 train RMSE 0.34182637491915985 Validation RMSE 19360 : 0.35321758963713745 max of weights 2.1655861143054405
Iteration 19370 loss 0.7583827023508622 train RMSE 0.3465503288754468 Validation RMSE 19370 : 0.3554552442816226 max of weights 2.1698143548973405
Iteration 19380 loss 0.7736379843993088 train RMSE 0.35357433541441485 Validation RMSE 19380 : 0.35446883551791675 max of weights 2.168521880663117
Iteration 19390 loss 0.7935116809062469 train RMSE 0.362721046684077 Validation RMSE 19390 : 0.35401521572722844 max of weights 2.1590716967521115
Iteration 19400 loss 0.7917076613124173 train RMSE 0.36189023535399434 Validation RMSE 19400 : 0.3534291195387086 max of weights 2.1581848847749465
Iteration 19410 loss 0.7749142749211206 train RMSE 0.3541569761138865 Validation RMSE 19410 : 0.35305965061890826 max of weights 2.161016151282676
Iteration 19420 loss 0.7726095067197817 train RMSE 0.35310169459357915 Validation RMSE 19420 : 0.3516482411382644 max of weights 2.160466100182831
Iteration 19430 loss 0.8061031323013693 train RMSE 0.36851482286589704 Validation RMSE 19430 : 0.36246461329733726 max of weights 2.1597191569911915
Iteration 19440 loss 0.8005191549718415 train RMSE 0.3659468652432048 Validation RMSE 19440 : 0.356317144400071 max of weights 2.1609498507875657
Iteration 19450 loss 0.7863586491311344 train RMSE 0.35942523378082514 Validation RMSE 19450 : 0.3541008978537243 max of weights 2.1618045387315834
Iteration 19460 loss 0.7790422739663324 train RMSE 0.3560547475209736 Validation RMSE 19460 : 0.35522572077098274 max of weights 2.1693895613092207
Iteration 19470 loss 0.7936478461669862 train RMSE 0.36277817743524093 Validation RMSE 19470 : 0.3537113891998393 max of weights 2.1811997486077392
Iteration 19480 loss 0.797169956865813 train RMSE 0.36439693360318526 Validation RMSE 19480 : 0.3550350362381159 max of weights 2.1813287596904853
Iteration 19490 loss 0.7685702945306858 train RMSE 0.3512309116538678 Validation RMSE 19490 : 0.35265484319060625 max of weights 2.178846908085114
Iteration 19500 loss 0.7828765933691267 train RMSE 0.3578082030544849 Validation RMSE 19500 : 0.3526676971852642 max of weights 2.1783663802635855
Iteration 19510 loss 0.8070641008120993 train RMSE 0.36892945457813525 Validation RMSE 19510 : 0.36164207311019714 max of weights 2.1784453159334207
Iteration 19520 loss 0.7794287962664143 train RMSE 0.35620611276151737 Validation RMSE 19520 : 0.3622790740991522 max of weights 2.181162541058943
Iteration 19530 loss 0.772305131799147 train RMSE 0.3529362976609107 Validation RMSE 19530 : 0.35156949749631305 max of weights 2.1939972233683367
Iteration 19540 loss 0.7773971685136721 train RMSE 0.35528634517468083 Validation RMSE 19540 : 0.3563504355012065 max of weights 2.2011771294280003
Iteration 19550 loss 0.7518934780218579 train RMSE 0.34355208573289364 Validation RMSE 19550 : 0.35081538625159564 max of weights 2.2054320734000172
Iteration 19560 loss 0.7427653233101184 train RMSE 0.33934666840675687 Validation RMSE 19560 : 0.3501285285615328 max of weights 2.202338258072941
Iteration 19570 loss 0.74586438899224 train RMSE 0.340774886514135 Validation RMSE 19570 : 0.34898985030123025 max of weights 2.203565080704926
Iteration 19580 loss 0.7525136824215133 train RMSE 0.3438382475355091 Validation RMSE 19580 : 0.3511418957366746 max of weights 2.2028843217292837
Iteration 19590 loss 0.7370440404228872 train RMSE 0.33671886293029624 Validation RMSE 19590 : 0.34914690476274063 max of weights 2.198507303546601
Iteration 19600 loss 0.758195951376654 train RMSE 0.34644431210657023 Validation RMSE 19600 : 0.35168135681205315 max of weights 2.197428039185764
Iteration 19610 loss 0.7560164099767315 train RMSE 0.3454453757707467 Validation RMSE 19610 : 0.35255413443728517 max of weights 2.1954013530698013
Iteration 19620 loss 0.7420378455043203 train RMSE 0.33901426556188025 Validation RMSE 19620 : 0.3500324234337036 max of weights 2.194507994768758
Iteration 19630 loss 0.7425245000783935 train RMSE 0.3392341528665684 Validation RMSE 19630 : 0.34963817679977816 max of weights 2.190560154413043
Iteration 19640 loss 0.7654115006024312 train RMSE 0.349769466635684 Validation RMSE 19640 : 0.35456986993549744 max of weights 2.1943829628274663
Iteration 19650 loss 0.7447982538538405 train RMSE 0.3402828959909154 Validation RMSE 19650 : 0.349714576619577 max of weights 2.1899251030680698
Iteration 19660 loss 0.7433195883938276 train RMSE 0.33960266013932644 Validation RMSE 19660 : 0.34821265822281156 max of weights 2.1865162420190165
Iteration 19670 loss 0.7541045958257462 train RMSE 0.34456451362938956 Validation RMSE 19670 : 0.35074481975389854 max of weights 2.1840305122808323
Iteration 19680 loss 0.751775651848858 train RMSE 0.34348840484190846 Validation RMSE 19680 : 0.35206737881570493 max of weights 2.182204606784885
Iteration 19690 loss 0.7514587939260244 train RMSE 0.3433392432830383 Validation RMSE 19690 : 0.3497809691347665 max of weights 2.1866186337783966
Iteration 19700 loss 0.7447488825089126 train RMSE 0.3402496413653659 Validation RMSE 19700 : 0.3481479524691447 max of weights 2.1864423872602603
Iteration 19710 loss 0.725732134971761 train RMSE 0.3314932800809131 Validation RMSE 19710 : 0.34968559263634874 max of weights 2.1774851850797066
Iteration 19720 loss 0.7369037083551114 train RMSE 0.33662480437988507 Validation RMSE 19720 : 0.35052887698548774 max of weights 2.1698761192042597
Iteration 19730 loss 0.7643117934353095 train RMSE 0.3492312693761459 Validation RMSE 19730 : 0.34955651645709557 max of weights 2.1657815066737562
Iteration 19740 loss 0.769349632165162 train RMSE 0.35155516731781916 Validation RMSE 19740 : 0.34849660694335627 max of weights 2.1672360557746617
Iteration 19750 loss 0.7629709174785458 train RMSE 0.34862651880427786 Validation RMSE 19750 : 0.3470896803335844 max of weights 2.1694458156117324
Iteration 19760 loss 0.7644678594121557 train RMSE 0.3493183950824831 Validation RMSE 19760 : 0.3520696355264037 max of weights 2.1755565523102915
Iteration 19770 loss 0.7557020292843746 train RMSE 0.34528105149803245 Validation RMSE 19770 : 0.34993090729258225 max of weights 2.1795598540992853
Iteration 19780 loss 0.7519338096817069 train RMSE 0.34354179281188174 Validation RMSE 19780 : 0.35041777130810187 max of weights 2.178105461039578
Iteration 19790 loss 0.7485870884040046 train RMSE 0.34200533129320504 Validation RMSE 19790 : 0.3490348837205047 max of weights 2.1799087461014897
Iteration 19800 loss 0.7530256451803047 train RMSE 0.3440506181035489 Validation RMSE 19800 : 0.3489599623933908 max of weights 2.175927905759142
Iteration 19810 loss 0.7792442264064887 train RMSE 0.35611444592867164 Validation RMSE 19810 : 0.35404429916673447 max of weights 2.170134244763071
Iteration 19820 loss 0.7730864676685113 train RMSE 0.35328141298053267 Validation RMSE 19820 : 0.3501667043070738 max of weights 2.171440398179272
Iteration 19830 loss 0.7763026786764523 train RMSE 0.3547633590926233 Validation RMSE 19830 : 0.3496615834219337 max of weights 2.1738221382457747
Iteration 19840 loss 0.7711980961732607 train RMSE 0.3524157586864585 Validation RMSE 19840 : 0.3510275104819456 max of weights 2.1701813937805206
Iteration 19850 loss 0.7531117744598117 train RMSE 0.3440863398990634 Validation RMSE 19850 : 0.35625330873442773 max of weights 2.1661192167933963
Iteration 19860 loss 0.7570502033241504 train RMSE 0.3458992377595568 Validation RMSE 19860 : 0.3533796845539822 max of weights 2.1623400272445688
Iteration 19870 loss 0.7428005937644949 train RMSE 0.3393487835415104 Validation RMSE 19870 : 0.35072855486341314 max of weights 2.162622912674972
Iteration 19880 loss 0.7289279694970644 train RMSE 0.332969215882511 Validation RMSE 19880 : 0.35166796009812107 max of weights 2.16288191761769
Iteration 19890 loss 0.7328045470930011 train RMSE 0.33475404337263526 Validation RMSE 19890 : 0.35419911849204516 max of weights 2.1601149392366787
Iteration 19900 loss 0.7337388434391731 train RMSE 0.3351831039100926 Validation RMSE 19900 : 0.35546722922422114 max of weights 2.160406647566982
Iteration 19910 loss 0.7508577725828858 train RMSE 0.3430545084517248 Validation RMSE 19910 : 0.3523361630247495 max of weights 2.160450697567861
Iteration 19920 loss 0.7852365599585717 train RMSE 0.35887165291307593 Validation RMSE 19920 : 0.35369190419798774 max of weights 2.160620082000748
Iteration 19930 loss 0.7838309109846345 train RMSE 0.3582260235875102 Validation RMSE 19930 : 0.3501923995582471 max of weights 2.162025550560986
Iteration 19940 loss 0.777609421838187 train RMSE 0.3553518037328078 Validation RMSE 19940 : 0.3544064584655472 max of weights 2.159569710114055
Iteration 19950 loss 0.7817818024334803 train RMSE 0.357270231710009 Validation RMSE 19950 : 0.3555028172509102 max of weights 2.15790848151503
Iteration 19960 loss 0.771640981109328 train RMSE 0.35260837866189165 Validation RMSE 19960 : 0.3510927288101716 max of weights 2.161852602702857
Iteration 19970 loss 0.7672274263774089 train RMSE 0.350577580632501 Validation RMSE 19970 : 0.3496739348948282 max of weights 2.165639542450652
Iteration 19980 loss 0.776213028854876 train RMSE 0.35471000796677143 Validation RMSE 19980 : 0.35371936820303246 max of weights 2.1675082657910787
Iteration 19990 loss 0.7584909672600963 train RMSE 0.346552764492335 Validation RMSE 19990 : 0.3474761668005915 max of weights 2.1696407319609183
Iteration 20000 loss 0.7516663480836823 train RMSE 0.34341508614135585 Validation RMSE 20000 : 0.3504310906372424 max of weights 2.173735777754455
Iteration 20010 loss 0.7671080751610241 train RMSE 0.35052476266697735 Validation RMSE 20010 : 0.3513903112065689 max of weights 2.183571144814416
Iteration 20020 loss 0.7683778173296898 train RMSE 0.3511085953909225 Validation RMSE 20020 : 0.34954887300533516 max of weights 2.191414705334146
Iteration 20030 loss 0.7516257725726067 train RMSE 0.34339918202199693 Validation RMSE 20030 : 0.3490156718645767 max of weights 2.203178535180036
Iteration 20040 loss 0.7377890300155528 train RMSE 0.33702983654143054 Validation RMSE 20040 : 0.34785807724105294 max of weights 2.2112162777990862
Iteration 20050 loss 0.721954935049215 train RMSE 0.3297398686315756 Validation RMSE 20050 : 0.35336673669881213 max of weights 2.2141231821651894
Iteration 20060 loss 0.7308917850394431 train RMSE 0.3338498971701388 Validation RMSE 20060 : 0.35061408119749427 max of weights 2.2208697830011404
Iteration 20070 loss 0.7371939368314668 train RMSE 0.3367487532741209 Validation RMSE 20070 : 0.35152603631591695 max of weights 2.2190115020185317
Iteration 20080 loss 0.7384697710553858 train RMSE 0.33733749696030396 Validation RMSE 20080 : 0.353846216193798 max of weights 2.2160651160194855
Iteration 20090 loss 0.728292863137586 train RMSE 0.33265009096350673 Validation RMSE 20090 : 0.35037821311519196 max of weights 2.2102673678060523
Iteration 20100 loss 0.7326763639708834 train RMSE 0.3346620753453299 Validation RMSE 20100 : 0.3574150392705712 max of weights 2.2111352316670727
Iteration 20110 loss 0.7539302730365067 train RMSE 0.3444451926435584 Validation RMSE 20110 : 0.3504052554501916 max of weights 2.214889812568911
Iteration 20120 loss 0.7785968850667879 train RMSE 0.3557973291923744 Validation RMSE 20120 : 0.3552371177633725 max of weights 2.2219441143043506
Iteration 20130 loss 0.7747797674786001 train RMSE 0.35404338155611786 Validation RMSE 20130 : 0.3540939625177239 max of weights 2.2228705947637803
Iteration 20140 loss 0.747624445635278 train RMSE 0.34154848124236425 Validation RMSE 20140 : 0.352623516223503 max of weights 2.2248290168772447
Iteration 20150 loss 0.7431686256495331 train RMSE 0.33949789590620966 Validation RMSE 20150 : 0.3521573671260867 max of weights 2.225640192877324
Iteration 20160 loss 0.7628938564253054 train RMSE 0.34857868449753354 Validation RMSE 20160 : 0.3511911688025666 max of weights 2.227642802327696
Iteration 20170 loss 0.7558783284488941 train RMSE 0.34534300279528696 Validation RMSE 20170 : 0.3579459142319319 max of weights 2.2254812951188083
Iteration 20180 loss 0.7422892863962932 train RMSE 0.33908743746783593 Validation RMSE 20180 : 0.3504974171590542 max of weights 2.216285285417957
Iteration 20190 loss 0.7618653771845776 train RMSE 0.34809260941320946 Validation RMSE 20190 : 0.3515460939217122 max of weights 2.211205863661544
Iteration 20200 loss 0.7691176953330287 train RMSE 0.3514316879662499 Validation RMSE 20200 : 0.35199435422886877 max of weights 2.2080297803725037
Iteration 20210 loss 0.75613300945875 train RMSE 0.3454486680428736 Validation RMSE 20210 : 0.35315627509331515 max of weights 2.206069935987207
Iteration 20220 loss 0.7589547403680539 train RMSE 0.34674242538529704 Validation RMSE 20220 : 0.35340662401477313 max of weights 2.209632240952665
Iteration 20230 loss 0.7465043698401385 train RMSE 0.34101549448211355 Validation RMSE 20230 : 0.35210066637179455 max of weights 2.2125274476661683
Iteration 20240 loss 0.7339677566816052 train RMSE 0.33525211141251793 Validation RMSE 20240 : 0.35138355650234687 max of weights 2.2105250722296748
Iteration 20250 loss 0.7238438605344842 train RMSE 0.3306010654883179 Validation RMSE 20250 : 0.3515613423943858 max of weights 2.204473463056245
Iteration 20260 loss 0.7343315773129996 train RMSE 0.33542293514741894 Validation RMSE 20260 : 0.3513663947008283 max of weights 2.1989651017196015
Iteration 20270 loss 0.7153090711355233 train RMSE 0.32667772730724914 Validation RMSE 20270 : 0.3497399099052596 max of weights 2.1958283535687055
Iteration 20280 loss 0.7310920218275905 train RMSE 0.3339446860489634 Validation RMSE 20280 : 0.3519025974313106 max of weights 2.1937224452035644
Iteration 20290 loss 0.7396355485797776 train RMSE 0.3378736154790495 Validation RMSE 20290 : 0.3507527939610186 max of weights 2.1928027173860642
Iteration 20300 loss 0.7537225048741913 train RMSE 0.34435315149293866 Validation RMSE 20300 : 0.3525239987401198 max of weights 2.213132079744599
Iteration 20310 loss 0.76238991327833 train RMSE 0.348348556059648 Validation RMSE 20310 : 0.35187215043495523 max of weights 2.2276160940391616
Iteration 20320 loss 0.7674915822828362 train RMSE 0.35069357394653344 Validation RMSE 20320 : 0.3535799028932619 max of weights 2.238301250047279
Iteration 20330 loss 0.7731311615340819 train RMSE 0.3532844927285656 Validation RMSE 20330 : 0.3560516718472987 max of weights 2.240228460461245
Iteration 20340 loss 0.7573235139669375 train RMSE 0.346014725771691 Validation RMSE 20340 : 0.35468523109532385 max of weights 2.2443982397123783
Iteration 20350 loss 0.73317113768362 train RMSE 0.33489913261708043 Validation RMSE 20350 : 0.3555311459492763 max of weights 2.246615226537902
Iteration 20360 loss 0.7246233070108775 train RMSE 0.3309602632827291 Validation RMSE 20360 : 0.35340895195324784 max of weights 2.240870105572037
Iteration 20370 loss 0.7438176226299302 train RMSE 0.33978455578191613 Validation RMSE 20370 : 0.35796289958621635 max of weights 2.2318444121952545
Iteration 20380 loss 0.7683408667343332 train RMSE 0.35107142890420856 Validation RMSE 20380 : 0.35540947330713013 max of weights 2.2295395708165806
Iteration 20390 loss 0.7692264145325107 train RMSE 0.3514767785906995 Validation RMSE 20390 : 0.35697077299868385 max of weights 2.233509046488476
Iteration 20400 loss 0.7591592414139544 train RMSE 0.34684324714786235 Validation RMSE 20400 : 0.3537184436641475 max of weights 2.2420502763645613
Iteration 20410 loss 0.7519850215709507 train RMSE 0.34354745818974025 Validation RMSE 20410 : 0.3552004519622775 max of weights 2.2442012441249077
Iteration 20420 loss 0.7326431543429714 train RMSE 0.3346410949530385 Validation RMSE 20420 : 0.35323623839012785 max of weights 2.2387742900929837
Iteration 20430 loss 0.7363771155598401 train RMSE 0.3363598257538732 Validation RMSE 20430 : 0.3573714271242602 max of weights 2.2375900180406125
Iteration 20440 loss 0.7344804855164725 train RMSE 0.3354960175452894 Validation RMSE 20440 : 0.35143636323111266 max of weights 2.2369729952540203
Iteration 20450 loss 0.7514246490319175 train RMSE 0.3433048875350417 Validation RMSE 20450 : 0.3531505680781109 max of weights 2.2324509152863583
Iteration 20460 loss 0.7636389237948372 train RMSE 0.34893008895418104 Validation RMSE 20460 : 0.35537493317862157 max of weights 2.2374990766472025
Iteration 20470 loss 0.7558804906087794 train RMSE 0.34535525737521566 Validation RMSE 20470 : 0.35418451737338125 max of weights 2.235059819570399
Iteration 20480 loss 0.7405371621198874 train RMSE 0.33828637630568714 Validation RMSE 20480 : 0.35307285786928183 max of weights 2.2379182834918026
Iteration 20490 loss 0.7609035688449881 train RMSE 0.347656257927642 Validation RMSE 20490 : 0.35261494071107224 max of weights 2.239945419317873
Iteration 20500 loss 0.7740208454394983 train RMSE 0.35368760723733667 Validation RMSE 20500 : 0.35547452307666405 max of weights 2.2414132080806026
Iteration 20510 loss 0.7660262150617829 train RMSE 0.3500060266673967 Validation RMSE 20510 : 0.352277995260358 max of weights 2.2420727135089327
Iteration 20520 loss 0.7732756456272796 train RMSE 0.3533372039677484 Validation RMSE 20520 : 0.3555025653453096 max of weights 2.236966723972636
Iteration 20530 loss 0.7807284541741676 train RMSE 0.35675988987891877 Validation RMSE 20530 : 0.3521515447944767 max of weights 2.23464765885588
Iteration 20540 loss 0.7741370149631398 train RMSE 0.35372427530565004 Validation RMSE 20540 : 0.35548473516353185 max of weights 2.2379965148901815
Iteration 20550 loss 0.7490003407624579 train RMSE 0.3421564194880094 Validation RMSE 20550 : 0.3520083526387881 max of weights 2.2397172451884924
Iteration 20560 loss 0.7438166471259235 train RMSE 0.33976198076836706 Validation RMSE 20560 : 0.35293192813650526 max of weights 2.2363161301766374
Iteration 20570 loss 0.7385220945208983 train RMSE 0.3373230415835249 Validation RMSE 20570 : 0.3507393659100194 max of weights 2.234784392955386
Iteration 20580 loss 0.7441034587934321 train RMSE 0.3398897401773315 Validation RMSE 20580 : 0.3505892404892268 max of weights 2.2304437083036923
Iteration 20590 loss 0.7582025654714489 train RMSE 0.34637301897535316 Validation RMSE 20590 : 0.3505422197745435 max of weights 2.2256373187619687
Iteration 20600 loss 0.7695141907851073 train RMSE 0.35156782647057194 Validation RMSE 20600 : 0.35144942186922434 max of weights 2.234859799369507
Iteration 20610 loss 0.7748844274174189 train RMSE 0.35403459092055406 Validation RMSE 20610 : 0.3537279548115605 max of weights 2.23980678551215
Iteration 20620 loss 0.7832365449328575 train RMSE 0.3578754197701153 Validation RMSE 20620 : 0.35787929324639595 max of weights 2.2452165121031995
Iteration 20630 loss 0.7748153866272836 train RMSE 0.354001063970952 Validation RMSE 20630 : 0.3561100067146405 max of weights 2.2478494452558997
Iteration 20640 loss 0.7694399420429519 train RMSE 0.35153419542440084 Validation RMSE 20640 : 0.35548229517727425 max of weights 2.2461550709759894
Iteration 20650 loss 0.7554943697004651 train RMSE 0.3451175589653569 Validation RMSE 20650 : 0.35458312766796757 max of weights 2.2393831093240255
Iteration 20660 loss 0.733889809983467 train RMSE 0.3351812088034907 Validation RMSE 20660 : 0.3523700682997584 max of weights 2.2391793671894646
Iteration 20670 loss 0.7007557370130792 train RMSE 0.3199356269656599 Validation RMSE 20670 : 0.35250432166242546 max of weights 2.241150109554009
Iteration 20680 loss 0.7136066871066601 train RMSE 0.3258462280829718 Validation RMSE 20680 : 0.35566592129856905 max of weights 2.243353862350303
Iteration 20690 loss 0.7358974417944939 train RMSE 0.3360997919836266 Validation RMSE 20690 : 0.3613047475768537 max of weights 2.241612112846291
Iteration 20700 loss 0.7279784969132332 train RMSE 0.33245692630496093 Validation RMSE 20700 : 0.3547170931744261 max of weights 2.2328573039087187
Iteration 20710 loss 0.7233373454129123 train RMSE 0.33032106130929584 Validation RMSE 20710 : 0.35528720472058245 max of weights 2.2338048805985715
Iteration 20720 loss 0.7199485401626736 train RMSE 0.3287633919473975 Validation RMSE 20720 : 0.3534110159515211 max of weights 2.226542865499981
Iteration 20730 loss 0.7240316629395155 train RMSE 0.33064448973034105 Validation RMSE 20730 : 0.3526830833359301 max of weights 2.220931458630893
Iteration 20740 loss 0.7262403713402994 train RMSE 0.3316634816265725 Validation RMSE 20740 : 0.35281420613064407 max of weights 2.212493480143357
Iteration 20750 loss 0.7251215546518686 train RMSE 0.33114704625766195 Validation RMSE 20750 : 0.35371654015704074 max of weights 2.206507751635308
Iteration 20760 loss 0.7186571932561633 train RMSE 0.32816747060431245 Validation RMSE 20760 : 0.3529129498331825 max of weights 2.202362396699642
Iteration 20770 loss 0.7219799350432479 train RMSE 0.32968594990037386 Validation RMSE 20770 : 0.3522833733455477 max of weights 2.201413221843471
Iteration 20780 loss 0.7385687500027323 train RMSE 0.3373154130749035 Validation RMSE 20780 : 0.35319784490413897 max of weights 2.205828598135183
Iteration 20790 loss 0.722625437355216 train RMSE 0.3299808682381381 Validation RMSE 20790 : 0.3529896657875648 max of weights 2.212371532858169
Iteration 20800 loss 0.7278026520145371 train RMSE 0.33236536923459886 Validation RMSE 20800 : 0.35124465932994037 max of weights 2.2230119795613565
Iteration 20810 loss 0.7475513874355969 train RMSE 0.3414513381691999 Validation RMSE 20810 : 0.3538447519768973 max of weights 2.2292049980469453
Iteration 20820 loss 0.7647290887361979 train RMSE 0.3493474665060356 Validation RMSE 20820 : 0.35539162377086353 max of weights 2.235162584204526
Iteration 20830 loss 0.7821852119594258 train RMSE 0.3573865625500191 Validation RMSE 20830 : 0.3543781683181701 max of weights 2.2300694791325104
Iteration 20840 loss 0.7997422212058862 train RMSE 0.3654656826753272 Validation RMSE 20840 : 0.3550045423442583 max of weights 2.2199096817246837
Iteration 20850 loss 0.7858424226495455 train RMSE 0.3590670879148393 Validation RMSE 20850 : 0.35233013988717343 max of weights 2.2234063826340944
Iteration 20860 loss 0.7688828419364983 train RMSE 0.35126371317480276 Validation RMSE 20860 : 0.35117275527701336 max of weights 2.2259795590860953
Iteration 20870 loss 0.779288375805645 train RMSE 0.35605712527971495 Validation RMSE 20870 : 0.35213308559738415 max of weights 2.2255569962342148
Iteration 20880 loss 0.8224413290551797 train RMSE 0.37591274964318966 Validation RMSE 20880 : 0.3659735527985999 max of weights 2.2227157718643973
Iteration 20890 loss 0.8018123213816005 train RMSE 0.3664209835925913 Validation RMSE 20890 : 0.355095124632861 max of weights 2.225716447986168
Iteration 20900 loss 0.7871962650086568 train RMSE 0.35968822217967866 Validation RMSE 20900 : 0.3560346106649378 max of weights 2.2253818370609895
Iteration 20910 loss 0.7841096103698758 train RMSE 0.35826571762557213 Validation RMSE 20910 : 0.35378913592113376 max of weights 2.2371291700384397
Iteration 20920 loss 0.8016207996218526 train RMSE 0.36632551969759863 Validation RMSE 20920 : 0.3540127150146148 max of weights 2.244781650312248
Iteration 20930 loss 0.7909735989694595 train RMSE 0.3614199243538139 Validation RMSE 20930 : 0.3537253861036626 max of weights 2.2431888836528144
Iteration 20940 loss 0.768905485882809 train RMSE 0.35126028824811883 Validation RMSE 20940 : 0.35140832341015893 max of weights 2.239588408607722
Iteration 20950 loss 0.7948127079110389 train RMSE 0.3631744867113664 Validation RMSE 20950 : 0.35387117495062326 max of weights 2.235067729328238
Iteration 20960 loss 0.8041992094170319 train RMSE 0.36748452885691 Validation RMSE 20960 : 0.3628024474430919 max of weights 2.2353948141198297
Iteration 20970 loss 0.7702054880373085 train RMSE 0.35184180538689364 Validation RMSE 20970 : 0.35556486771616924 max of weights 2.2393681867057493
Iteration 20980 loss 0.7757070277098135 train RMSE 0.35438455429156496 Validation RMSE 20980 : 0.35106420341642025 max of weights 2.2432706693764803
Iteration 20990 loss 0.7704186282755544 train RMSE 0.3519579919541406 Validation RMSE 20990 : 0.35412611188579035 max of weights 2.2450653641878886
Iteration 21000 loss 0.7477644596073468 train RMSE 0.3415320454110978 Validation RMSE 21000 : 0.3490585954065408 max of weights 2.246136890812008
Iteration 21010 loss 0.7405906969633016 train RMSE 0.3382244507015776 Validation RMSE 21010 : 0.34961544785129484 max of weights 2.243612258631541
Iteration 21020 loss 0.749703954419977 train RMSE 0.3424267747842071 Validation RMSE 21020 : 0.3483337436219133 max of weights 2.2463412314210998
Iteration 21030 loss 0.7458880567425532 train RMSE 0.3406713214425454 Validation RMSE 21030 : 0.34978378249798864 max of weights 2.2452670205589764
Iteration 21040 loss 0.74706714042562 train RMSE 0.34121265244724613 Validation RMSE 21040 : 0.348453344931664 max of weights 2.2413486058257273
Iteration 21050 loss 0.7592210185230657 train RMSE 0.34679979954271306 Validation RMSE 21050 : 0.35067196324622074 max of weights 2.2414616196556496
Iteration 21060 loss 0.7469517960766202 train RMSE 0.34115810063682755 Validation RMSE 21060 : 0.3505272590865354 max of weights 2.2400926298093933
Iteration 21070 loss 0.7341989198694626 train RMSE 0.3352882705003893 Validation RMSE 21070 : 0.34880483235172083 max of weights 2.2387520886689227
Iteration 21080 loss 0.751666023730009 train RMSE 0.3433234627964795 Validation RMSE 21080 : 0.35045881465969114 max of weights 2.2386111472194323
Iteration 21090 loss 0.7631134723091364 train RMSE 0.3485940798275271 Validation RMSE 21090 : 0.35183377581299874 max of weights 2.2392060312485205
Iteration 21100 loss 0.7408427229222802 train RMSE 0.33834104375570245 Validation RMSE 21100 : 0.3497396883653589 max of weights 2.231202200049927
Iteration 21110 loss 0.7566951514071536 train RMSE 0.3456371395660933 Validation RMSE 21110 : 0.3508095862621454 max of weights 2.230206170447226
Iteration 21120 loss 0.7581645342486454 train RMSE 0.3463128444531552 Validation RMSE 21120 : 0.3511850369349538 max of weights 2.2270651562227473
Iteration 21130 loss 0.7463395649690406 train RMSE 0.3408706690384772 Validation RMSE 21130 : 0.35058450126809093 max of weights 2.2267065977548834
Iteration 21140 loss 0.7547781792632611 train RMSE 0.3447512538836139 Validation RMSE 21140 : 0.34918474616249595 max of weights 2.2333341608540054
Iteration 21150 loss 0.7452218724753433 train RMSE 0.34035255606833353 Validation RMSE 21150 : 0.34678876498613015 max of weights 2.230277021150184
Iteration 21160 loss 0.7326428792330835 train RMSE 0.33455497833901077 Validation RMSE 21160 : 0.35047306509355236 max of weights 2.221230102332971
Iteration 21170 loss 0.7468877491555482 train RMSE 0.34110201252299993 Validation RMSE 21170 : 0.3493526807923065 max of weights 2.216193798855181
Iteration 21180 loss 0.7692931026721145 train RMSE 0.3514079475099382 Validation RMSE 21180 : 0.34944661917753206 max of weights 2.212390660729343
Iteration 21190 loss 0.7703238423991967 train RMSE 0.35189109730066886 Validation RMSE 21190 : 0.34777268927039257 max of weights 2.2138778138732356
Iteration 21200 loss 0.7586591546597824 train RMSE 0.34652880265576297 Validation RMSE 21200 : 0.34668679247606615 max of weights 2.216568777286995
Iteration 21210 loss 0.7659233859203196 train RMSE 0.3498708765311801 Validation RMSE 21210 : 0.35091230918462213 max of weights 2.224323977512963
Iteration 21220 loss 0.7594964838599032 train RMSE 0.34690720952169163 Validation RMSE 21220 : 0.3497509972802173 max of weights 2.2264342974126894
Iteration 21230 loss 0.7514845585984701 train RMSE 0.34321822810541197 Validation RMSE 21230 : 0.34931567369389016 max of weights 2.2243008612685067
Iteration 21240 loss 0.7560726183491808 train RMSE 0.34533408284599654 Validation RMSE 21240 : 0.34932072140150316 max of weights 2.2238561403936745
Iteration 21250 loss 0.7617205457486734 train RMSE 0.34793474760852067 Validation RMSE 21250 : 0.348967752133924 max of weights 2.217888516905288
Iteration 21260 loss 0.7877108169850828 train RMSE 0.3598943008945876 Validation RMSE 21260 : 0.35512332547230113 max of weights 2.2135684651599257
Iteration 21270 loss 0.7700190818571222 train RMSE 0.35175282480294673 Validation RMSE 21270 : 0.3489372462600727 max of weights 2.2154836093774852
Iteration 21280 loss 0.7695978777756731 train RMSE 0.3515604115026423 Validation RMSE 21280 : 0.34885360226015477 max of weights 2.215959578795968
Iteration 21290 loss 0.762579765024486 train RMSE 0.34832793164670817 Validation RMSE 21290 : 0.35032420239253326 max of weights 2.216144092513803
Iteration 21300 loss 0.7421698130295696 train RMSE 0.3389318973816737 Validation RMSE 21300 : 0.35201826735512926 max of weights 2.2230938454806535
Iteration 21310 loss 0.7536502309950723 train RMSE 0.3442145083568174 Validation RMSE 21310 : 0.3500346519265519 max of weights 2.2220603237967076
Iteration 21320 loss 0.7424834361205116 train RMSE 0.3390807428620799 Validation RMSE 21320 : 0.35271244980514754 max of weights 2.2241613723670786
Iteration 21330 loss 0.743728832991793 train RMSE 0.3396590502035839 Validation RMSE 21330 : 0.3526747799108626 max of weights 2.226989245272332
Iteration 21340 loss 0.7341695874087156 train RMSE 0.33525736707520554 Validation RMSE 21340 : 0.3550258457753972 max of weights 2.2317022140307596
Iteration 21350 loss 0.7444209043912292 train RMSE 0.33997441156009806 Validation RMSE 21350 : 0.353660518398875 max of weights 2.2368929200998333
Iteration 21360 loss 0.7633836647336213 train RMSE 0.3486939091888587 Validation RMSE 21360 : 0.35069348203071604 max of weights 2.238122763498092
Iteration 21370 loss 0.7876157007261582 train RMSE 0.3598441667533708 Validation RMSE 21370 : 0.3524502509927031 max of weights 2.234591640001404
Iteration 21380 loss 0.7802991067809799 train RMSE 0.3564746648084799 Validation RMSE 21380 : 0.34884341341526964 max of weights 2.229241736427566
Iteration 21390 loss 0.7885915395258826 train RMSE 0.3602771851578639 Validation RMSE 21390 : 0.35490985798035635 max of weights 2.216992119678984
Iteration 21400 loss 0.7950446670861292 train RMSE 0.36324890196292997 Validation RMSE 21400 : 0.354625050490367 max of weights 2.207203273755102
Iteration 21410 loss 0.7731420916340968 train RMSE 0.3531725374290928 Validation RMSE 21410 : 0.3497195293589344 max of weights 2.210819600016432
Iteration 21420 loss 0.7671840020829888 train RMSE 0.35043258054688814 Validation RMSE 21420 : 0.3479944250315433 max of weights 2.2131146425529176
Iteration 21430 loss 0.7720402077597541 train RMSE 0.35266334025287693 Validation RMSE 21430 : 0.3503575542646869 max of weights 2.2169656799013486
Iteration 21440 loss 0.7605836874980731 train RMSE 0.34739058977799603 Validation RMSE 21440 : 0.3469854963815314 max of weights 2.21663721586827
Iteration 21450 loss 0.7702806942464415 train RMSE 0.3518575694322633 Validation RMSE 21450 : 0.3535742214680507 max of weights 2.2229604454905396
Iteration 21460 loss 0.7694874942595321 train RMSE 0.3514954366327191 Validation RMSE 21460 : 0.34980708736089144 max of weights 2.2336859324706775
Iteration 21470 loss 0.7676704483450656 train RMSE 0.35065935925809144 Validation RMSE 21470 : 0.34959082661057744 max of weights 2.240629271032416
Iteration 21480 loss 0.7524122209156098 train RMSE 0.3436387400974103 Validation RMSE 21480 : 0.34798713796439285 max of weights 2.2568366128885806
Iteration 21490 loss 0.7269993230782359 train RMSE 0.3319425075368145 Validation RMSE 21490 : 0.34797314877128166 max of weights 2.2608535879742333
Iteration 21500 loss 0.7257612612682394 train RMSE 0.33137062225876157 Validation RMSE 21500 : 0.3500996536337951 max of weights 2.262139972115906
Iteration 21510 loss 0.7335232284946752 train RMSE 0.3349411123125011 Validation RMSE 21510 : 0.3497967787552678 max of weights 2.264966899004249
Iteration 21520 loss 0.7383069815818039 train RMSE 0.33714219547850754 Validation RMSE 21520 : 0.35014066118893084 max of weights 2.2610745782412702
Iteration 21530 loss 0.7453143272677422 train RMSE 0.3403652661206536 Validation RMSE 21530 : 0.3515422774188393 max of weights 2.2542746385812387
Iteration 21540 loss 0.7318114027545939 train RMSE 0.33414691595756163 Validation RMSE 21540 : 0.3516294074937401 max of weights 2.252617303385112
Iteration 21550 loss 0.7394734183421382 train RMSE 0.3376678231693351 Validation RMSE 21550 : 0.3561013016958334 max of weights 2.2560721260204892
Iteration 21560 loss 0.7668842312255142 train RMSE 0.35028497027512934 Validation RMSE 21560 : 0.3513472326827919 max of weights 2.2619998570485165
Iteration 21570 loss 0.7817205923366601 train RMSE 0.3571144362397715 Validation RMSE 21570 : 0.3545681310948706 max of weights 2.268853743351647
Iteration 21580 loss 0.7719428295267429 train RMSE 0.3526173170164963 Validation RMSE 21580 : 0.3532939066584179 max of weights 2.2699394361986043
Iteration 21590 loss 0.753965850840249 train RMSE 0.34434364021798314 Validation RMSE 21590 : 0.35356439242866267 max of weights 2.272814263856999
Iteration 21600 loss 0.756057760082029 train RMSE 0.34530839754114273 Validation RMSE 21600 : 0.3499581891642572 max of weights 2.2759514349912995
Iteration 21610 loss 0.7698032199946083 train RMSE 0.35163539288408896 Validation RMSE 21610 : 0.351304665580096 max of weights 2.281291913958756
Iteration 21620 loss 0.7532543326671401 train RMSE 0.3440096856257496 Validation RMSE 21620 : 0.3558995124284884 max of weights 2.2800512395214896
Iteration 21630 loss 0.7506919892897683 train RMSE 0.3428291481838541 Validation RMSE 21630 : 0.3501807857236954 max of weights 2.2744787486728204
Iteration 21640 loss 0.7821381483687311 train RMSE 0.35730194044447144 Validation RMSE 21640 : 0.3527381458852092 max of weights 2.272739439836248
Iteration 21650 loss 0.7637088501459669 train RMSE 0.34882234329615147 Validation RMSE 21650 : 0.349589656608181 max of weights 2.2712210444329135
Iteration 21660 loss 0.7568242534802958 train RMSE 0.34564715746560626 Validation RMSE 21660 : 0.3514467281292287 max of weights 2.2724950215804722
Iteration 21670 loss 0.7541849770029982 train RMSE 0.3444299514677097 Validation RMSE 21670 : 0.3507741436833328 max of weights 2.27608826580635
Iteration 21680 loss 0.7456758053231815 train RMSE 0.3405148609656974 Validation RMSE 21680 : 0.35096253453349247 max of weights 2.274429481643588
Iteration 21690 loss 0.7305769241816036 train RMSE 0.33357319129985546 Validation RMSE 21690 : 0.3496613006334015 max of weights 2.2697636089813535
Iteration 21700 loss 0.7305901566744553 train RMSE 0.333583908358161 Validation RMSE 21700 : 0.3499291753294848 max of weights 2.259420141096634
Iteration 21710 loss 0.7257129581075763 train RMSE 0.3313354991085833 Validation RMSE 21710 : 0.3507237149300545 max of weights 2.2537147973551686
Iteration 21720 loss 0.7135217963217063 train RMSE 0.32573387757190714 Validation RMSE 21720 : 0.3497184385009647 max of weights 2.250647941687249
Iteration 21730 loss 0.7256085402394788 train RMSE 0.33130201585981955 Validation RMSE 21730 : 0.34858904021843523 max of weights 2.2499941618756787
Iteration 21740 loss 0.7488363183260894 train RMSE 0.3419841348825476 Validation RMSE 21740 : 0.3518334060137782 max of weights 2.253088442910042
Iteration 21750 loss 0.7589613279608394 train RMSE 0.34664551035021285 Validation RMSE 21750 : 0.3513809475449114 max of weights 2.263040189059247
Iteration 21760 loss 0.7673687106090502 train RMSE 0.35051846369364476 Validation RMSE 21760 : 0.3520059533723385 max of weights 2.271598308698075
Iteration 21770 loss 0.7689907926681672 train RMSE 0.35126121935499727 Validation RMSE 21770 : 0.35264498516169884 max of weights 2.27758849017061
Iteration 21780 loss 0.7786383306858291 train RMSE 0.3557006093982109 Validation RMSE 21780 : 0.356155642670403 max of weights 2.284224752164496
Iteration 21790 loss 0.752050748998949 train RMSE 0.3434684026299251 Validation RMSE 21790 : 0.3535974511742441 max of weights 2.287439661651536
Iteration 21800 loss 0.7276699161112931 train RMSE 0.3322465921655222 Validation RMSE 21800 : 0.3536374060173196 max of weights 2.284641019070208
Iteration 21810 loss 0.7286989611492745 train RMSE 0.3327151293961244 Validation RMSE 21810 : 0.3533625621101667 max of weights 2.271886740634101
Iteration 21820 loss 0.7521261675527995 train RMSE 0.34348968914008 Validation RMSE 21820 : 0.35593138919603556 max of weights 2.2645601593141507
Iteration 21830 loss 0.7695199971781289 train RMSE 0.35149501999221217 Validation RMSE 21830 : 0.35480832844214616 max of weights 2.2635023813854733
Iteration 21840 loss 0.7671521064743388 train RMSE 0.35040298356913846 Validation RMSE 21840 : 0.3542495458649683 max of weights 2.272278671622945
Iteration 21850 loss 0.761355487942937 train RMSE 0.3477356709409109 Validation RMSE 21850 : 0.35313847252561886 max of weights 2.2792729517104378
Iteration 21860 loss 0.7430160676364853 train RMSE 0.3392991929422931 Validation RMSE 21860 : 0.35236693909568034 max of weights 2.28032455972296
Iteration 21870 loss 0.7308020208083543 train RMSE 0.33367222001497354 Validation RMSE 21870 : 0.3513677394868548 max of weights 2.2755564447558236
Iteration 21880 loss 0.7364670621831914 train RMSE 0.33628045057488676 Validation RMSE 21880 : 0.354576328366777 max of weights 2.2766653086601147
Iteration 21890 loss 0.7377936398315077 train RMSE 0.3369013016473218 Validation RMSE 21890 : 0.350410497592665 max of weights 2.2712273481941834
Iteration 21900 loss 0.7627250705306873 train RMSE 0.3483825195622092 Validation RMSE 21900 : 0.3544180127133537 max of weights 2.2703229516937014
Iteration 21910 loss 0.7648107773217842 train RMSE 0.3493441609147325 Validation RMSE 21910 : 0.3530422871382387 max of weights 2.273083212893068
Iteration 21920 loss 0.7507268434778548 train RMSE 0.3428583850929745 Validation RMSE 21920 : 0.353118656624683 max of weights 2.268769531802789
Iteration 21930 loss 0.7490818091379767 train RMSE 0.3420926740752923 Validation RMSE 21930 : 0.35457217065629665 max of weights 2.2735058435116247
Iteration 21940 loss 0.766427724645946 train RMSE 0.3500736293617716 Validation RMSE 21940 : 0.353318720576058 max of weights 2.2734921026754993
Iteration 21950 loss 0.7722135890218108 train RMSE 0.35273165707472043 Validation RMSE 21950 : 0.3566402163750774 max of weights 2.275773740425538
Iteration 21960 loss 0.7666774662196909 train RMSE 0.3501824317459782 Validation RMSE 21960 : 0.35193522076539896 max of weights 2.2720405894083138
Iteration 21970 loss 0.7726962176295126 train RMSE 0.35294490413446605 Validation RMSE 21970 : 0.35438179763070043 max of weights 2.268740908623228
Iteration 21980 loss 0.7758943954234404 train RMSE 0.3544121009917816 Validation RMSE 21980 : 0.35183906380732216 max of weights 2.2683109765679887
Iteration 21990 loss 0.7634440981347642 train RMSE 0.3486819916159513 Validation RMSE 21990 : 0.35505333345453716 max of weights 2.2752995464292405
Iteration 22000 loss 0.7441076479848421 train RMSE 0.3397807442438482 Validation RMSE 22000 : 0.3516397533386952 max of weights 2.2759965272088603
Iteration 22010 loss 0.742125950164288 train RMSE 0.33886003353893196 Validation RMSE 22010 : 0.3524154100985417 max of weights 2.2717967184688503
Iteration 22020 loss 0.7436719726309706 train RMSE 0.33957186561052544 Validation RMSE 22020 : 0.34982914556723593 max of weights 2.2713108083427724
Iteration 22030 loss 0.750878494734864 train RMSE 0.34288488274291307 Validation RMSE 22030 : 0.3502771768566632 max of weights 2.263428993963279
Iteration 22040 loss 0.7642892828258183 train RMSE 0.3490517709849686 Validation RMSE 22040 : 0.3505544036222643 max of weights 2.2648491549729637
Iteration 22050 loss 0.778242591606802 train RMSE 0.35546141886235816 Validation RMSE 22050 : 0.3521492773479147 max of weights 2.274209364133694
Iteration 22060 loss 0.7869604469703955 train RMSE 0.3594707137150622 Validation RMSE 22060 : 0.3548146615028131 max of weights 2.2759440702895852
Iteration 22070 loss 0.7812597353594969 train RMSE 0.356844515188846 Validation RMSE 22070 : 0.3560322946657257 max of weights 2.2846625578841
Iteration 22080 loss 0.7733157607004789 train RMSE 0.3531910444376498 Validation RMSE 22080 : 0.3554222750941646 max of weights 2.287108361574584
Iteration 22090 loss 0.7729570489528514 train RMSE 0.353033292941385 Validation RMSE 22090 : 0.3542242247283402 max of weights 2.281863207665374
Iteration 22100 loss 0.7613951839911411 train RMSE 0.3477131087159172 Validation RMSE 22100 : 0.3542033211222969 max of weights 2.276317448964907
Iteration 22110 loss 0.7384745090248764 train RMSE 0.337170830761692 Validation RMSE 22110 : 0.35123127571525026 max of weights 2.2782562968037046
Iteration 22120 loss 0.7058958320526616 train RMSE 0.32217842536322694 Validation RMSE 22120 : 0.3529566508694498 max of weights 2.278288471388229
Iteration 22130 loss 0.7225900159938183 train RMSE 0.32985704249052 Validation RMSE 22130 : 0.35472829577657616 max of weights 2.2804437328339695
Iteration 22140 loss 0.7359451901728017 train RMSE 0.33599691415734684 Validation RMSE 22140 : 0.3577963709115997 max of weights 2.276537746452946
Iteration 22150 loss 0.7229408286119305 train RMSE 0.33001411727255126 Validation RMSE 22150 : 0.3520999441326601 max of weights 2.270881017193096
Iteration 22160 loss 0.7295825755371214 train RMSE 0.3330673997406254 Validation RMSE 22160 : 0.35306269750937364 max of weights 2.2693637346309834
Iteration 22170 loss 0.7215961002461181 train RMSE 0.3293950683348351 Validation RMSE 22170 : 0.350718357841846 max of weights 2.2636253847853776
Iteration 22180 loss 0.7289444668034135 train RMSE 0.3327791539519153 Validation RMSE 22180 : 0.35220026399366006 max of weights 2.25879777160839
Iteration 22190 loss 0.7281130071612887 train RMSE 0.33240007473857597 Validation RMSE 22190 : 0.3519450028034665 max of weights 2.251740411455938
Iteration 22200 loss 0.7249942317934251 train RMSE 0.33096168337143467 Validation RMSE 22200 : 0.35296020125536576 max of weights 2.2496081749417836
Iteration 22210 loss 0.7142865502149358 train RMSE 0.32602861657651644 Validation RMSE 22210 : 0.3510226767138994 max of weights 2.2439540268009774
Iteration 22220 loss 0.7345109419927343 train RMSE 0.3353244037063379 Validation RMSE 22220 : 0.35095509068926545 max of weights 2.2414993236694043
Iteration 22230 loss 0.7330921314811503 train RMSE 0.3346709732208607 Validation RMSE 22230 : 0.35076956655778163 max of weights 2.245191415419969
Iteration 22240 loss 0.722793418315598 train RMSE 0.3299311469243976 Validation RMSE 22240 : 0.35198740878039464 max of weights 2.252483977135408
Iteration 22250 loss 0.7389690364993805 train RMSE 0.33737604487382855 Validation RMSE 22250 : 0.35038754386333504 max of weights 2.2632202783654756
Iteration 22260 loss 0.7539170739460413 train RMSE 0.3442490677398751 Validation RMSE 22260 : 0.35399888987296324 max of weights 2.267991679981246
Iteration 22270 loss 0.7679159422525503 train RMSE 0.35068770264378685 Validation RMSE 22270 : 0.3539393260350656 max of weights 2.26820504444747
Iteration 22280 loss 0.7826930770874018 train RMSE 0.3574916673040297 Validation RMSE 22280 : 0.3535528061182653 max of weights 2.257427732169039
Iteration 22290 loss 0.7949149331581851 train RMSE 0.3631168274115601 Validation RMSE 22290 : 0.35385271117924205 max of weights 2.247286233693696
Iteration 22300 loss 0.7717917376526855 train RMSE 0.35247122220145216 Validation RMSE 22300 : 0.3524723143725122 max of weights 2.250649296254314
Iteration 22310 loss 0.7598063765901018 train RMSE 0.34695901898112425 Validation RMSE 22310 : 0.3497693084770354 max of weights 2.252990865977827
Iteration 22320 loss 0.78274877568119 train RMSE 0.3575191912941056 Validation RMSE 22320 : 0.3539374616229715 max of weights 2.250359943277408
Iteration 22330 loss 0.8146642906436169 train RMSE 0.372204777861326 Validation RMSE 22330 : 0.36227382941512914 max of weights 2.246556317751524
Iteration 22340 loss 0.7881917327705076 train RMSE 0.36002353141638915 Validation RMSE 22340 : 0.3516160345364231 max of weights 2.248459957532305
Iteration 22350 loss 0.781105885409991 train RMSE 0.3567555515698386 Validation RMSE 22350 : 0.3560085047380469 max of weights 2.251218855743043
Iteration 22360 loss 0.7823861715558966 train RMSE 0.35734695481857043 Validation RMSE 22360 : 0.3515206668282494 max of weights 2.267908593641982
Iteration 22370 loss 0.8007124582176907 train RMSE 0.36578089150907317 Validation RMSE 22370 : 0.35417422326905695 max of weights 2.276947274210947
Iteration 22380 loss 0.7760020628169751 train RMSE 0.35440146108299264 Validation RMSE 22380 : 0.3530236937279659 max of weights 2.2760543855525053
Iteration 22390 loss 0.7697822783077355 train RMSE 0.35153437400773696 Validation RMSE 22390 : 0.3509356208230021 max of weights 2.2736898601585014
Iteration 22400 loss 0.8062585354641679 train RMSE 0.3683103573379195 Validation RMSE 22400 : 0.3585745033965347 max of weights 2.2711520248623978
Iteration 22410 loss 0.7992569626415155 train RMSE 0.3650796712602249 Validation RMSE 22410 : 0.3661307472411214 max of weights 2.2744934094813325
Iteration 22420 loss 0.7637865200543876 train RMSE 0.348762485975348 Validation RMSE 22420 : 0.35029176750084945 max of weights 2.281129334786574
Iteration 22430 loss 0.7797088939198097 train RMSE 0.3560972046666706 Validation RMSE 22430 : 0.35065413265485 max of weights 2.28252643041664
Iteration 22440 loss 0.7673568143816031 train RMSE 0.35041775306593476 Validation RMSE 22440 : 0.3514490735767093 max of weights 2.28525217008389
Iteration 22450 loss 0.7463752280063933 train RMSE 0.34076183728199 Validation RMSE 22450 : 0.3482784118598267 max of weights 2.286220536180713
Iteration 22460 loss 0.7467004546889489 train RMSE 0.3409100254395826 Validation RMSE 22460 : 0.3497047286411154 max of weights 2.2835904978529653
Iteration 22470 loss 0.7529086832466012 train RMSE 0.3437781313744522 Validation RMSE 22470 : 0.34997495610863855 max of weights 2.2856061395206497
Iteration 22480 loss 0.7459483238621343 train RMSE 0.3405746354815595 Validation RMSE 22480 : 0.352993788774588 max of weights 2.2828266411961606
Iteration 22490 loss 0.7463352767454442 train RMSE 0.34074780258917814 Validation RMSE 22490 : 0.34882215833401764 max of weights 2.2787822125312434
Iteration 22500 loss 0.752205013757364 train RMSE 0.34344834999391954 Validation RMSE 22500 : 0.3497006887598382 max of weights 2.279865488520959
Iteration 22510 loss 0.738422293758661 train RMSE 0.33710838724884495 Validation RMSE 22510 : 0.3493505732087074 max of weights 2.2811897060749895
Iteration 22520 loss 0.7282676716957102 train RMSE 0.33243224795414195 Validation RMSE 22520 : 0.34737470191887176 max of weights 2.2801431377541235
Iteration 22530 loss 0.7551403481159648 train RMSE 0.34479809363869346 Validation RMSE 22530 : 0.3520811968584446 max of weights 2.2833739620096245
Iteration 22540 loss 0.7552980149013554 train RMSE 0.34487234838745423 Validation RMSE 22540 : 0.34998162721176923 max of weights 2.2832002991183074
Iteration 22550 loss 0.7384139024712298 train RMSE 0.3370987265350544 Validation RMSE 22550 : 0.34707586901629495 max of weights 2.2755456676237618
Iteration 22560 loss 0.7571170606647812 train RMSE 0.34570531553848066 Validation RMSE 22560 : 0.35081309028064306 max of weights 2.276318413636989
Iteration 22570 loss 0.7533140747991701 train RMSE 0.3439560567267015 Validation RMSE 22570 : 0.35096499532000264 max of weights 2.273606454480992
Iteration 22580 loss 0.7457206982081808 train RMSE 0.3404633504314475 Validation RMSE 22580 : 0.3485700985581888 max of weights 2.2744528742938765
Iteration 22590 loss 0.7517163312157392 train RMSE 0.34322107625278253 Validation RMSE 22590 : 0.3477409553408083 max of weights 2.2767995497204456
Iteration 22600 loss 0.7355685170044892 train RMSE 0.3357894666858203 Validation RMSE 22600 : 0.3452860549878136 max of weights 2.269850649078284
Iteration 22610 loss 0.7355906609373001 train RMSE 0.33578881955666906 Validation RMSE 22610 : 0.35234686411924476 max of weights 2.2716416924060483
Iteration 22620 loss 0.7536324459157921 train RMSE 0.3440857701887595 Validation RMSE 22620 : 0.34824487277659427 max of weights 2.276347665245197
Iteration 22630 loss 0.7662907661044083 train RMSE 0.3499106053236189 Validation RMSE 22630 : 0.347467085501731 max of weights 2.278443027882326
Iteration 22640 loss 0.7671855593721807 train RMSE 0.350329304256801 Validation RMSE 22640 : 0.3463231768940257 max of weights 2.2761228854317115
Iteration 22650 loss 0.7540070605318776 train RMSE 0.3442658423443859 Validation RMSE 22650 : 0.3465129024674497 max of weights 2.2783042835596103
Iteration 22660 loss 0.7606741823084023 train RMSE 0.3473321017537121 Validation RMSE 22660 : 0.3480373192703719 max of weights 2.2809709710948964
Iteration 22670 loss 0.7588473819203887 train RMSE 0.34648339065076467 Validation RMSE 22670 : 0.3485108881993938 max of weights 2.28161505192549
Iteration 22680 loss 0.7445538900829549 train RMSE 0.33990716244665364 Validation RMSE 22680 : 0.34712646209009296 max of weights 2.2813426726647066
Iteration 22690 loss 0.7547632043516275 train RMSE 0.34461073002465076 Validation RMSE 22690 : 0.34765114684830273 max of weights 2.2881064516773364
Iteration 22700 loss 0.7641710986865033 train RMSE 0.3489405536411981 Validation RMSE 22700 : 0.34930219867923235 max of weights 2.2898039642757135
Iteration 22710 loss 0.7770634739896627 train RMSE 0.3548733519741223 Validation RMSE 22710 : 0.3522348337806829 max of weights 2.292988746750255
Iteration 22720 loss 0.7661161198486576 train RMSE 0.3498347234619046 Validation RMSE 22720 : 0.347073016053747 max of weights 2.2899132993086635
Iteration 22730 loss 0.7628397508842387 train RMSE 0.34832882879319915 Validation RMSE 22730 : 0.34772307384514173 max of weights 2.289862843876675
Iteration 22740 loss 0.7567495547901977 train RMSE 0.3455222929345126 Validation RMSE 22740 : 0.3516487720013844 max of weights 2.2996074012173233
Iteration 22750 loss 0.7459195181300168 train RMSE 0.3405391192488553 Validation RMSE 22750 : 0.3508984826528228 max of weights 2.302204134747946
Iteration 22760 loss 0.7485179923570883 train RMSE 0.34173864807662485 Validation RMSE 22760 : 0.3487177724148478 max of weights 2.300773936247153
Iteration 22770 loss 0.7371405816681101 train RMSE 0.33650500547250733 Validation RMSE 22770 : 0.35479668298047257 max of weights 2.304003237599027
Iteration 22780 loss 0.7534458807897085 train RMSE 0.3440129825590165 Validation RMSE 22780 : 0.3551782528430339 max of weights 2.3072487056001916
Iteration 22790 loss 0.7413349410665258 train RMSE 0.3384373541664905 Validation RMSE 22790 : 0.35603726212789505 max of weights 2.31339465450625
Iteration 22800 loss 0.7508543778330526 train RMSE 0.34281609015468884 Validation RMSE 22800 : 0.35206174196172624 max of weights 2.3148314746692495
Iteration 22810 loss 0.7750397316730381 train RMSE 0.353940148448986 Validation RMSE 22810 : 0.3505536969715868 max of weights 2.3135754011475558
Iteration 22820 loss 0.787747954709634 train RMSE 0.35978812265662075 Validation RMSE 22820 : 0.3508421448973957 max of weights 2.3067168855890645
Iteration 22830 loss 0.7761933601336032 train RMSE 0.3544632110223317 Validation RMSE 22830 : 0.35084877523259156 max of weights 2.2987942001094273
Iteration 22840 loss 0.7828710478157999 train RMSE 0.3575270315583519 Validation RMSE 22840 : 0.3563064376471572 max of weights 2.283494228841661
Iteration 22850 loss 0.7840644838790487 train RMSE 0.3580807543250129 Validation RMSE 22850 : 0.3543198476509904 max of weights 2.272821256272327
Iteration 22860 loss 0.7671299708909228 train RMSE 0.35029063084240264 Validation RMSE 22860 : 0.34882245635153497 max of weights 2.268100114203385
Iteration 22870 loss 0.7645243890285353 train RMSE 0.3490916217297114 Validation RMSE 22870 : 0.34677307831372883 max of weights 2.2650173915162033
Iteration 22880 loss 0.7647305513838797 train RMSE 0.3491833052734709 Validation RMSE 22880 : 0.3480475206649066 max of weights 2.2589108661506487
Iteration 22890 loss 0.7507097732526392 train RMSE 0.3427308532890649 Validation RMSE 22890 : 0.34703357577621063 max of weights 2.2575293204026696
Iteration 22900 loss 0.7723175426463564 train RMSE 0.35267959775130153 Validation RMSE 22900 : 0.3534893429673957 max of weights 2.2595821040812925
Iteration 22910 loss 0.7664223981446623 train RMSE 0.3499654596686388 Validation RMSE 22910 : 0.3498861142126422 max of weights 2.2584056640293184
Iteration 22920 loss 0.7671994477746744 train RMSE 0.35032334820005095 Validation RMSE 22920 : 0.3493528707421245 max of weights 2.268465916318042
Iteration 22930 loss 0.7552879793036751 train RMSE 0.3448422868620892 Validation RMSE 22930 : 0.3497231222889354 max of weights 2.2843591671739345
Iteration 22940 loss 0.7173241543245659 train RMSE 0.32737067305241235 Validation RMSE 22940 : 0.3508262115205313 max of weights 2.2805527079742562
Iteration 22950 loss 0.7272483839382847 train RMSE 0.331935566390777 Validation RMSE 22950 : 0.3474764353258295 max of weights 2.281384215077075
Iteration 22960 loss 0.7339960328005573 train RMSE 0.33503959198752803 Validation RMSE 22960 : 0.34864249947733333 max of weights 2.282502371283397
Iteration 22970 loss 0.7392787505653426 train RMSE 0.3374717066209437 Validation RMSE 22970 : 0.35040417256510925 max of weights 2.2806352277106074
Iteration 22980 loss 0.7447589143307823 train RMSE 0.3399882763886324 Validation RMSE 22980 : 0.34935610571761144 max of weights 2.2770188856111386
Iteration 22990 loss 0.7351320991226976 train RMSE 0.33555456363295083 Validation RMSE 22990 : 0.3535910729770962 max of weights 2.2789703727121733
Iteration 23000 loss 0.7412055132724134 train RMSE 0.33834834455707596 Validation RMSE 23000 : 0.3508466593153311 max of weights 2.2833072987559158
Iteration 23010 loss 0.7742208154015585 train RMSE 0.3535441037047415 Validation RMSE 23010 : 0.35170231248296474 max of weights 2.2913335352716633
Iteration 23020 loss 0.7819545130005792 train RMSE 0.3571050861914825 Validation RMSE 23020 : 0.3541469641208093 max of weights 2.294848837297013
Iteration 23030 loss 0.7657494097037167 train RMSE 0.34964859800746695 Validation RMSE 23030 : 0.3533289039983478 max of weights 2.2991690473934505
Iteration 23040 loss 0.7461895934799235 train RMSE 0.3406437135700187 Validation RMSE 23040 : 0.3536158672015888 max of weights 2.3023277065092542
Iteration 23050 loss 0.7663772282254633 train RMSE 0.34993847673432027 Validation RMSE 23050 : 0.34997846487493156 max of weights 2.30769253624925
Iteration 23060 loss 0.7625747789460949 train RMSE 0.34818808810240304 Validation RMSE 23060 : 0.35117193923738943 max of weights 2.3114628028574256
Iteration 23070 loss 0.7458084078837176 train RMSE 0.34046364522028427 Validation RMSE 23070 : 0.3507987393790735 max of weights 2.3060401587750006
Iteration 23080 loss 0.7614545460943546 train RMSE 0.3476594860417069 Validation RMSE 23080 : 0.3508369109618998 max of weights 2.3002244052902414
Iteration 23090 loss 0.7789769276499796 train RMSE 0.3557251380379243 Validation RMSE 23090 : 0.35140936862167593 max of weights 2.2982577811140956
Iteration 23100 loss 0.755148300086003 train RMSE 0.3447570407144002 Validation RMSE 23100 : 0.35016935519798825 max of weights 2.2940528223727497
Iteration 23110 loss 0.7564556561241256 train RMSE 0.3453519423048402 Validation RMSE 23110 : 0.35198589081229914 max of weights 2.2985144290871498
Iteration 23120 loss 0.7477168171006041 train RMSE 0.3413310864972087 Validation RMSE 23120 : 0.3501241618806255 max of weights 2.3001822976816575
Iteration 23130 loss 0.7444980733310963 train RMSE 0.33985115566993235 Validation RMSE 23130 : 0.3508685970805201 max of weights 2.2966687486158963
Iteration 23140 loss 0.7246126656925873 train RMSE 0.3307098343220789 Validation RMSE 23140 : 0.35011442032171525 max of weights 2.292104884089645
Iteration 23150 loss 0.7282622448863574 train RMSE 0.3323930338549769 Validation RMSE 23150 : 0.34844301792287863 max of weights 2.2816080879411382
Iteration 23160 loss 0.7126606827040981 train RMSE 0.32521284319585353 Validation RMSE 23160 : 0.3499004960257544 max of weights 2.275089624612909
Iteration 23170 loss 0.7164317774449318 train RMSE 0.3269548214041548 Validation RMSE 23170 : 0.35074300241866657 max of weights 2.271363307921974
Iteration 23180 loss 0.7283483673571114 train RMSE 0.3324420120092088 Validation RMSE 23180 : 0.3479228897529829 max of weights 2.2680708722648575
Iteration 23190 loss 0.7438137687019193 train RMSE 0.33955161140907836 Validation RMSE 23190 : 0.3529501347239796 max of weights 2.2750547155239937
Iteration 23200 loss 0.7601026342324593 train RMSE 0.347053123742096 Validation RMSE 23200 : 0.3517117442718213 max of weights 2.2878672176943566
Iteration 23210 loss 0.7670613217643462 train RMSE 0.35025509752026446 Validation RMSE 23210 : 0.35237618221750544 max of weights 2.3013736464403696
Iteration 23220 loss 0.764193497726816 train RMSE 0.34893145439507295 Validation RMSE 23220 : 0.35194127695310035 max of weights 2.3046476469890136
Iteration 23230 loss 0.7658649937671513 train RMSE 0.3497032004993346 Validation RMSE 23230 : 0.35415721043535864 max of weights 2.311589082022604
Iteration 23240 loss 0.7393400004591176 train RMSE 0.33749799885298437 Validation RMSE 23240 : 0.3538344663782348 max of weights 2.3145208021101946
Iteration 23250 loss 0.7205047141192726 train RMSE 0.32882774757277683 Validation RMSE 23250 : 0.35217615082490356 max of weights 2.308571405542167
Iteration 23260 loss 0.732286024035133 train RMSE 0.33424351062617125 Validation RMSE 23260 : 0.3547801697143137 max of weights 2.293074738481211
Iteration 23270 loss 0.7604433989190298 train RMSE 0.3471987428360708 Validation RMSE 23270 : 0.35365953621774315 max of weights 2.2885183871238053
Iteration 23280 loss 0.7669722069872372 train RMSE 0.3502014165541764 Validation RMSE 23280 : 0.3536181695317988 max of weights 2.2909531809657624
Iteration 23290 loss 0.7619039432124406 train RMSE 0.3478668053640479 Validation RMSE 23290 : 0.35147280286280563 max of weights 2.3006156189976763
Iteration 23300 loss 0.760184188710172 train RMSE 0.3470786812937414 Validation RMSE 23300 : 0.3524439371796361 max of weights 2.302912404222869
Iteration 23310 loss 0.7415806817002102 train RMSE 0.3385152151067122 Validation RMSE 23310 : 0.352743283004353 max of weights 2.2994110941963597
Iteration 23320 loss 0.7367924260657968 train RMSE 0.3363063064257912 Validation RMSE 23320 : 0.35361461831040497 max of weights 2.295884835077896
Iteration 23330 loss 0.7380688961564026 train RMSE 0.33689836738880113 Validation RMSE 23330 : 0.35248479062483323 max of weights 2.2987732389748343
Iteration 23340 loss 0.7481372275364746 train RMSE 0.3415441792175784 Validation RMSE 23340 : 0.3506085427860735 max of weights 2.295938658653913
Iteration 23350 loss 0.7606361699522235 train RMSE 0.34730327238785597 Validation RMSE 23350 : 0.35369670106876955 max of weights 2.3007685649485707
Iteration 23360 loss 0.7650709250559821 train RMSE 0.34934373737650093 Validation RMSE 23360 : 0.35256249992809674 max of weights 2.3032647932155537
Iteration 23370 loss 0.7459638949830318 train RMSE 0.3405445092463189 Validation RMSE 23370 : 0.3511665718578345 max of weights 2.3010069519519596
Iteration 23380 loss 0.7566114246334347 train RMSE 0.3454378864719719 Validation RMSE 23380 : 0.35252405647114216 max of weights 2.305828868156133
Iteration 23390 loss 0.7687481270919905 train RMSE 0.35102030395507766 Validation RMSE 23390 : 0.35296210845901616 max of weights 2.3060514838213955
Iteration 23400 loss 0.7686195402899427 train RMSE 0.350958426939732 Validation RMSE 23400 : 0.35534499380598966 max of weights 2.3091732098699986
Iteration 23410 loss 0.7655419898433232 train RMSE 0.3495407702543827 Validation RMSE 23410 : 0.35292034676767275 max of weights 2.3049900243320414
Iteration 23420 loss 0.7656769962472488 train RMSE 0.3495954687397431 Validation RMSE 23420 : 0.35077261145357486 max of weights 2.3024195478086105
Iteration 23430 loss 0.7708796090510255 train RMSE 0.35198555952640753 Validation RMSE 23430 : 0.3527045325859712 max of weights 2.301657683062537
Iteration 23440 loss 0.7503373689178183 train RMSE 0.34253176660724327 Validation RMSE 23440 : 0.3525631508157681 max of weights 2.306964746318897
Iteration 23450 loss 0.7392018651276191 train RMSE 0.3374014816503295 Validation RMSE 23450 : 0.35183325965677237 max of weights 2.3051622507574083
Iteration 23460 loss 0.7345995031306335 train RMSE 0.33527661897812927 Validation RMSE 23460 : 0.351673022577563 max of weights 2.303033431984824
Iteration 23470 loss 0.7438843589061295 train RMSE 0.3395506639161323 Validation RMSE 23470 : 0.3500734668208612 max of weights 2.3020235786943846
Iteration 23480 loss 0.7525588016591787 train RMSE 0.3435399965021006 Validation RMSE 23480 : 0.3494209950305453 max of weights 2.297408652592851
Iteration 23490 loss 0.7641454681572891 train RMSE 0.3488662292360447 Validation RMSE 23490 : 0.34989625639340066 max of weights 2.30487641378532
Iteration 23500 loss 0.7798929765521888 train RMSE 0.35610230462481957 Validation RMSE 23500 : 0.3527068097168566 max of weights 2.311827329762501
Iteration 23510 loss 0.7933275311389553 train RMSE 0.3622823522254394 Validation RMSE 23510 : 0.35552296481012385 max of weights 2.3158824693311155
Iteration 23520 loss 0.7760709305890505 train RMSE 0.35434141612935904 Validation RMSE 23520 : 0.35274120245165547 max of weights 2.324480305427902
Iteration 23530 loss 0.7713840005498873 train RMSE 0.35218709661235653 Validation RMSE 23530 : 0.354121616954241 max of weights 2.320958241658999
Iteration 23540 loss 0.7715172500891903 train RMSE 0.3522510974328496 Validation RMSE 23540 : 0.35324939772489045 max of weights 2.3165392600852233
Iteration 23550 loss 0.7587427091183347 train RMSE 0.34637537813871194 Validation RMSE 23550 : 0.352643984192379 max of weights 2.3158166904719395
Iteration 23560 loss 0.7259615904091193 train RMSE 0.3312950221212867 Validation RMSE 23560 : 0.34986705949317215 max of weights 2.3185172640587033
Iteration 23570 loss 0.7105550967994081 train RMSE 0.3242017418962635 Validation RMSE 23570 : 0.35418115869858274 max of weights 2.3191133949420073
Iteration 23580 loss 0.7360229659276346 train RMSE 0.3359171215416933 Validation RMSE 23580 : 0.3574071116435971 max of weights 2.318549843387413
Iteration 23590 loss 0.7396415455874173 train RMSE 0.33758093443875103 Validation RMSE 23590 : 0.35406943927963347 max of weights 2.310470396234421
Iteration 23600 loss 0.7270516638682503 train RMSE 0.33178698896272474 Validation RMSE 23600 : 0.35208965714084095 max of weights 2.3093980081301826
Iteration 23610 loss 0.7353546229462706 train RMSE 0.33560519989547505 Validation RMSE 23610 : 0.3530304475567117 max of weights 2.3071368045611904
Iteration 23620 loss 0.7242964593104931 train RMSE 0.33052009587836584 Validation RMSE 23620 : 0.350667644415659 max of weights 2.3023986342190157
Iteration 23630 loss 0.7302084683213027 train RMSE 0.3332444345154074 Validation RMSE 23630 : 0.3517762173357074 max of weights 2.2997758324099893
Iteration 23640 loss 0.7323204399493224 train RMSE 0.33421950852535987 Validation RMSE 23640 : 0.35229677743563886 max of weights 2.2964000277416967
Iteration 23650 loss 0.7291366696929795 train RMSE 0.33275037775811384 Validation RMSE 23650 : 0.3530558021891304 max of weights 2.295429929070475
Iteration 23660 loss 0.7252908958056082 train RMSE 0.3309724444497949 Validation RMSE 23660 : 0.3512415046478162 max of weights 2.290589087103638
Iteration 23670 loss 0.7433961308954892 train RMSE 0.3392946143084795 Validation RMSE 23670 : 0.3505876299191363 max of weights 2.291370694908636
Iteration 23680 loss 0.7274284832682639 train RMSE 0.3319498537958479 Validation RMSE 23680 : 0.3502132854581687 max of weights 2.2965613196266292
Iteration 23690 loss 0.7216315353602037 train RMSE 0.32928246452467574 Validation RMSE 23690 : 0.3499861812578583 max of weights 2.3045950895763987
Iteration 23700 loss 0.7453726768936111 train RMSE 0.3402079271050168 Validation RMSE 23700 : 0.3504102077254876 max of weights 2.3117252033588565
Iteration 23710 loss 0.7598702117094045 train RMSE 0.34687148768356996 Validation RMSE 23710 : 0.35347894167721344 max of weights 2.3126548036092895
Iteration 23720 loss 0.7724868500386761 train RMSE 0.3526799897990163 Validation RMSE 23720 : 0.35255744899728975 max of weights 2.308178620021851
Iteration 23730 loss 0.7889804680565053 train RMSE 0.3602720605439206 Validation RMSE 23730 : 0.3517452918812197 max of weights 2.2966246043149967
Iteration 23740 loss 0.7883877501590398 train RMSE 0.36000086920969937 Validation RMSE 23740 : 0.3505706157766571 max of weights 2.2961375005281406
Iteration 23750 loss 0.7719435199169875 train RMSE 0.3524285209125754 Validation RMSE 23750 : 0.3507255484505072 max of weights 2.3001823651752122
Iteration 23760 loss 0.7685404474565246 train RMSE 0.3508667903465557 Validation RMSE 23760 : 0.34903018607771397 max of weights 2.300653234999412
Iteration 23770 loss 0.7913280891165665 train RMSE 0.36135463892465947 Validation RMSE 23770 : 0.35635824407545247 max of weights 2.296454101896535
Iteration 23780 loss 0.7992433318533916 train RMSE 0.3649967070792651 Validation RMSE 23780 : 0.3550494933227337 max of weights 2.296419045431568
Iteration 23790 loss 0.7801667566949976 train RMSE 0.3562151063965901 Validation RMSE 23790 : 0.35090599110186893 max of weights 2.297039999161249
Iteration 23800 loss 0.7736122675425903 train RMSE 0.35319538788777344 Validation RMSE 23800 : 0.35397474997394607 max of weights 2.2999365585297413
Iteration 23810 loss 0.783734469265069 train RMSE 0.3578559594668327 Validation RMSE 23810 : 0.3520196437556557 max of weights 2.313168065634707
Iteration 23820 loss 0.7914413852099048 train RMSE 0.361400885319245 Validation RMSE 23820 : 0.3530425630715589 max of weights 2.3163930336424454
Iteration 23830 loss 0.7649071991194559 train RMSE 0.34918292829312864 Validation RMSE 23830 : 0.3506379005280039 max of weights 2.318702331433545
Iteration 23840 loss 0.768200556245917 train RMSE 0.35069306597097233 Validation RMSE 23840 : 0.3497116776477272 max of weights 2.3195231620289887
Iteration 23850 loss 0.7994432336611518 train RMSE 0.36506122231113664 Validation RMSE 23850 : 0.3575908045341902 max of weights 2.3247547475851285
Iteration 23860 loss 0.7934652536122766 train RMSE 0.3623037756411793 Validation RMSE 23860 : 0.3636669475340132 max of weights 2.3259840352473797
Iteration 23870 loss 0.7745672993036237 train RMSE 0.35361844489984834 Validation RMSE 23870 : 0.3497437365882188 max of weights 2.331108595233634
Iteration 23880 loss 0.7855345544067608 train RMSE 0.3586736708658721 Validation RMSE 23880 : 0.35292195517868347 max of weights 2.335776656432875
Iteration 23890 loss 0.7635314188593767 train RMSE 0.34855066151199116 Validation RMSE 23890 : 0.35029200374727776 max of weights 2.3362866311124866
Iteration 23900 loss 0.7473965079065409 train RMSE 0.341121567877485 Validation RMSE 23900 : 0.34815718973391635 max of weights 2.334807721178934
Iteration 23910 loss 0.7442503734896777 train RMSE 0.3396749640978492 Validation RMSE 23910 : 0.3478388198991552 max of weights 2.3336890960832184
Iteration 23920 loss 0.7542353414480787 train RMSE 0.34427580752681236 Validation RMSE 23920 : 0.3508971778142955 max of weights 2.3382115101469894
Iteration 23930 loss 0.740074330486083 train RMSE 0.33775737092335634 Validation RMSE 23930 : 0.34822808139416855 max of weights 2.3350535888881323
Iteration 23940 loss 0.7559346042900632 train RMSE 0.345048399846892 Validation RMSE 23940 : 0.3484330186139332 max of weights 2.330376647353848
Iteration 23950 loss 0.7535268848855898 train RMSE 0.3439435648256134 Validation RMSE 23950 : 0.34908793941976773 max of weights 2.324244065485201
Iteration 23960 loss 0.7371398027691891 train RMSE 0.3364047557324401 Validation RMSE 23960 : 0.3473424523225241 max of weights 2.316909073223994
Iteration 23970 loss 0.735577383976813 train RMSE 0.3356820846107093 Validation RMSE 23970 : 0.34703665911927456 max of weights 2.315327660437841
Iteration 23980 loss 0.7575229954073426 train RMSE 0.3457840769856944 Validation RMSE 23980 : 0.3514965188756428 max of weights 2.314276419346066
Iteration 23990 loss 0.7478430475016744 train RMSE 0.341327868707999 Validation RMSE 23990 : 0.34780208541955787 max of weights 2.3151986258088297
Iteration 24000 loss 0.7454473651025155 train RMSE 0.3402242282500475 Validation RMSE 24000 : 0.3470126582926593 max of weights 2.322536467217084
Iteration 24010 loss 0.7564196675205855 train RMSE 0.34527167598427966 Validation RMSE 24010 : 0.3499451272642409 max of weights 2.325813091947718
Iteration 24020 loss 0.7532333100750772 train RMSE 0.3438041599111533 Validation RMSE 24020 : 0.3510040733030448 max of weights 2.3219263471408444
Iteration 24030 loss 0.7450434657666387 train RMSE 0.34003581072580036 Validation RMSE 24030 : 0.3479040117258771 max of weights 2.32605702881959
Iteration 24040 loss 0.7468992375519354 train RMSE 0.34088770210148245 Validation RMSE 24040 : 0.34660315684781207 max of weights 2.3287401132584584
Iteration 24050 loss 0.7299129425169412 train RMSE 0.3330665292769692 Validation RMSE 24050 : 0.3458178966226296 max of weights 2.340551184160098
Iteration 24060 loss 0.736606123894016 train RMSE 0.3361358502824959 Validation RMSE 24060 : 0.3508176949001162 max of weights 2.3526019739675457
Iteration 24070 loss 0.7618822591481426 train RMSE 0.34776293644387646 Validation RMSE 24070 : 0.34750968297360324 max of weights 2.3553706264078333
Iteration 24080 loss 0.7703297221486957 train RMSE 0.35165411651325346 Validation RMSE 24080 : 0.3466040501735208 max of weights 2.3569863221631295
Iteration 24090 loss 0.762995109763154 train RMSE 0.34828397820955576 Validation RMSE 24090 : 0.34528194438822607 max of weights 2.354478895016727
Iteration 24100 loss 0.7615202405463857 train RMSE 0.3476072725173397 Validation RMSE 24100 : 0.34847113947112207 max of weights 2.355749156918468
Iteration 24110 loss 0.760554917256053 train RMSE 0.34715820230220584 Validation RMSE 24110 : 0.34768900070593695 max of weights 2.357548353717991
Iteration 24120 loss 0.7573253630287617 train RMSE 0.3456656012420292 Validation RMSE 24120 : 0.3482123982721867 max of weights 2.3563718717515596
Iteration 24130 loss 0.750131451827822 train RMSE 0.3423583388142549 Validation RMSE 24130 : 0.34714519439039754 max of weights 2.3558869200340027
Iteration 24140 loss 0.7562407334795236 train RMSE 0.34517419023058415 Validation RMSE 24140 : 0.34757535147930463 max of weights 2.3609578906670383
Iteration 24150 loss 0.7727930431561894 train RMSE 0.3527901559528257 Validation RMSE 24150 : 0.35065065795188877 max of weights 2.360248425283304
Iteration 24160 loss 0.7697042874110064 train RMSE 0.3513698961236685 Validation RMSE 24160 : 0.3483604578085593 max of weights 2.361000296425127
Iteration 24170 loss 0.7672938547050329 train RMSE 0.35026055787770205 Validation RMSE 24170 : 0.3467482661540785 max of weights 2.3584654988325333
Iteration 24180 loss 0.7639084894182278 train RMSE 0.34870408239149536 Validation RMSE 24180 : 0.34847387924438755 max of weights 2.3605021272302227
Iteration 24190 loss 0.7535487919076141 train RMSE 0.3439314199896433 Validation RMSE 24190 : 0.35413619653330397 max of weights 2.3665776352846426
Iteration 24200 loss 0.7561390460887205 train RMSE 0.3451250929927681 Validation RMSE 24200 : 0.35292483649328255 max of weights 2.365353035573212
Iteration 24210 loss 0.7462670940299666 train RMSE 0.3405888714364786 Validation RMSE 24210 : 0.3496002269672775 max of weights 2.3645812321426
Iteration 24220 loss 0.7315744024890275 train RMSE 0.33382922934073406 Validation RMSE 24220 : 0.3523562340542999 max of weights 2.367178503265913
Iteration 24230 loss 0.7429930142068641 train RMSE 0.33908702087670795 Validation RMSE 24230 : 0.353376673524848 max of weights 2.370178343998425
Iteration 24240 loss 0.7442386916260261 train RMSE 0.339659401884755 Validation RMSE 24240 : 0.35391992300128633 max of weights 2.3766238835644606
Iteration 24250 loss 0.7592567626707506 train RMSE 0.3465648114172366 Validation RMSE 24250 : 0.35183656867500573 max of weights 2.3771804662488325
Iteration 24260 loss 0.7848319917984657 train RMSE 0.3583291437071731 Validation RMSE 24260 : 0.35111151336664576 max of weights 2.3715904816173023
Iteration 24270 loss 0.7813354775080337 train RMSE 0.3567216983126393 Validation RMSE 24270 : 0.3481676919632536 max of weights 2.36380289054579
Iteration 24280 loss 0.7808476809625445 train RMSE 0.3564860215728953 Validation RMSE 24280 : 0.35226602917328204 max of weights 2.353116524570488
Iteration 24290 loss 0.7872728298725233 train RMSE 0.3594398013318866 Validation RMSE 24290 : 0.353803795773693 max of weights 2.336545074834203
Iteration 24300 loss 0.7739837176697565 train RMSE 0.3533293643832368 Validation RMSE 24300 : 0.35127333993508564 max of weights 2.3306052428480624
Iteration 24310 loss 0.7671607638527128 train RMSE 0.35019135187355105 Validation RMSE 24310 : 0.34871775605962785 max of weights 2.32805247340205
Iteration 24320 loss 0.7699251156727975 train RMSE 0.3514620072655892 Validation RMSE 24320 : 0.3493657748846376 max of weights 2.3250074433072383
Iteration 24330 loss 0.7627478676040476 train RMSE 0.34815768551587783 Validation RMSE 24330 : 0.34787826185056847 max of weights 2.3219514159532335
Iteration 24340 loss 0.7572727923769982 train RMSE 0.34564226921291735 Validation RMSE 24340 : 0.3487460955699533 max of weights 2.3208952940506267
Iteration 24350 loss 0.7711280885345155 train RMSE 0.3520229423105038 Validation RMSE 24350 : 0.3499219796842911 max of weights 2.322265171217062
Iteration 24360 loss 0.7697875413248801 train RMSE 0.35140494088879487 Validation RMSE 24360 : 0.3485096144386684 max of weights 2.311275100577722
Iteration 24370 loss 0.7591053429839869 train RMSE 0.3464900856010623 Validation RMSE 24370 : 0.34818280004048974 max of weights 2.3121796398232464
Iteration 24380 loss 0.7431202523000362 train RMSE 0.3391332105997951 Validation RMSE 24380 : 0.3459230763796695 max of weights 2.319205296714693
Iteration 24390 loss 0.7214183244790944 train RMSE 0.3291440344689576 Validation RMSE 24390 : 0.35296609968737735 max of weights 2.313250993470444
Iteration 24400 loss 0.7310955091249972 train RMSE 0.3335958081279041 Validation RMSE 24400 : 0.34703677799897575 max of weights 2.3193012664532775
Iteration 24410 loss 0.7421139205165755 train RMSE 0.3386652044777782 Validation RMSE 24410 : 0.34862195967374826 max of weights 2.3179224013825532
Iteration 24420 loss 0.7506852467952567 train RMSE 0.34260936777159573 Validation RMSE 24420 : 0.35076113767345146 max of weights 2.3150084724088353
Iteration 24430 loss 0.740638445326451 train RMSE 0.33797890888717663 Validation RMSE 24430 : 0.3485046638614509 max of weights 2.3108197741267538
Iteration 24440 loss 0.73791052613356 train RMSE 0.3367184839188889 Validation RMSE 24440 : 0.35703450942201975 max of weights 2.3113988469374998
Iteration 24450 loss 0.7470441596820315 train RMSE 0.34092337065541384 Validation RMSE 24450 : 0.3482494084228961 max of weights 2.314316594441408
Iteration 24460 loss 0.7806028757256755 train RMSE 0.356366186117565 Validation RMSE 24460 : 0.35346384560860367 max of weights 2.322077348996432
Iteration 24470 loss 0.7768582777594655 train RMSE 0.35464535665698804 Validation RMSE 24470 : 0.3532928241737618 max of weights 2.3239533792113813
Iteration 24480 loss 0.7506451970607967 train RMSE 0.34258344498690907 Validation RMSE 24480 : 0.3523191035160592 max of weights 2.325979499087391
Iteration 24490 loss 0.7394522306984074 train RMSE 0.337430006617929 Validation RMSE 24490 : 0.351378417184852 max of weights 2.3271696049756563
Iteration 24500 loss 0.7662674811946669 train RMSE 0.34977443968593225 Validation RMSE 24500 : 0.3505667594939112 max of weights 2.330677978341498
Iteration 24510 loss 0.7537382220931041 train RMSE 0.3440042957316774 Validation RMSE 24510 : 0.3505512156793255 max of weights 2.331128718798246
Iteration 24520 loss 0.7460934282101546 train RMSE 0.3404789600569715 Validation RMSE 24520 : 0.3493010681470042 max of weights 2.3250307994162385
Iteration 24530 loss 0.7682338087224038 train RMSE 0.3506631451416772 Validation RMSE 24530 : 0.349825074803022 max of weights 2.3228430456079066
Iteration 24540 loss 0.7777971308979786 train RMSE 0.35506623648246516 Validation RMSE 24540 : 0.35064906548369146 max of weights 2.3237166828445766
Iteration 24550 loss 0.7582903343871279 train RMSE 0.34608256167453705 Validation RMSE 24550 : 0.35074846162158146 max of weights 2.322741657506777
Iteration 24560 loss 0.7605923090532597 train RMSE 0.34713687470311877 Validation RMSE 24560 : 0.3516584963624811 max of weights 2.329001068814783
Iteration 24570 loss 0.7493043734712045 train RMSE 0.3419442870168376 Validation RMSE 24570 : 0.35037780307986127 max of weights 2.3274515034812815
Iteration 24580 loss 0.736046397260484 train RMSE 0.335846892061059 Validation RMSE 24580 : 0.349495238231108 max of weights 2.3222153497913696
Iteration 24590 loss 0.7197919410114627 train RMSE 0.3283760501091482 Validation RMSE 24590 : 0.35076736010518933 max of weights 2.314842239735472
Iteration 24600 loss 0.7269553778190638 train RMSE 0.3316709481653331 Validation RMSE 24600 : 0.3483257345380929 max of weights 2.313209324934335
Iteration 24610 loss 0.7021433655283194 train RMSE 0.32025950370735934 Validation RMSE 24610 : 0.34796618571465726 max of weights 2.315639639566142
Iteration 24620 loss 0.7104115373784402 train RMSE 0.3240703245804557 Validation RMSE 24620 : 0.3501673554445091 max of weights 2.313342405675189
Iteration 24630 loss 0.7271451147482466 train RMSE 0.33176976095118377 Validation RMSE 24630 : 0.3486473653121034 max of weights 2.3128973954996175
Iteration 24640 loss 0.7406657892428733 train RMSE 0.33798784547907684 Validation RMSE 24640 : 0.3518146172125238 max of weights 2.3189972939266235
Iteration 24650 loss 0.7509642173513735 train RMSE 0.34273370723065943 Validation RMSE 24650 : 0.34932470420556194 max of weights 2.322222972840792
Iteration 24660 loss 0.7618414591818488 train RMSE 0.34773718283739374 Validation RMSE 24660 : 0.35176652577616124 max of weights 2.3273366694488167
Iteration 24670 loss 0.7694271747211985 train RMSE 0.351222522456931 Validation RMSE 24670 : 0.353556688485887 max of weights 2.325447574380658
Iteration 24680 loss 0.7563492562004743 train RMSE 0.34520732647781316 Validation RMSE 24680 : 0.3526269490832178 max of weights 2.325884836425686
Iteration 24690 loss 0.7315119599881506 train RMSE 0.3337748567080685 Validation RMSE 24690 : 0.35388301076472456 max of weights 2.3254492126374195
Iteration 24700 loss 0.7231357432028882 train RMSE 0.32991456832382904 Validation RMSE 24700 : 0.3513465552156479 max of weights 2.322191967740512
Iteration 24710 loss 0.7419755303614685 train RMSE 0.3385760776837092 Validation RMSE 24710 : 0.3571724116224843 max of weights 2.312956237952318
Iteration 24720 loss 0.7622075841694393 train RMSE 0.3478896281965522 Validation RMSE 24720 : 0.35266207016835416 max of weights 2.3055967789014824
Iteration 24730 loss 0.7655142604902463 train RMSE 0.349409857664772 Validation RMSE 24730 : 0.35306602695173617 max of weights 2.30277661584105
Iteration 24740 loss 0.7610842769563824 train RMSE 0.3473693222486016 Validation RMSE 24740 : 0.35075663876519464 max of weights 2.3008341338950795
Iteration 24750 loss 0.7606941885079077 train RMSE 0.34719428828737403 Validation RMSE 24750 : 0.3525826000048619 max of weights 2.296908384571889
Iteration 24760 loss 0.73937594611923 train RMSE 0.33737970984601445 Validation RMSE 24760 : 0.3517858031311708 max of weights 2.2976364781047596
Iteration 24770 loss 0.7391453203138291 train RMSE 0.3372697135528699 Validation RMSE 24770 : 0.35520222033076426 max of weights 2.3032820634480284
Iteration 24780 loss 0.7387653532609296 train RMSE 0.3371011054976791 Validation RMSE 24780 : 0.3502056345142474 max of weights 2.3067333732251134
Iteration 24790 loss 0.7537482445861454 train RMSE 0.34400795268388573 Validation RMSE 24790 : 0.35049714326396997 max of weights 2.3115079543583628
Iteration 24800 loss 0.7619741469894308 train RMSE 0.3477985669882205 Validation RMSE 24800 : 0.35272089508474425 max of weights 2.3177341044351905
Iteration 24810 loss 0.7600717901592442 train RMSE 0.34691946660109213 Validation RMSE 24810 : 0.3506054840496444 max of weights 2.3227831944425743
Iteration 24820 loss 0.7425280660988924 train RMSE 0.3388387348026726 Validation RMSE 24820 : 0.350127624435413 max of weights 2.3223437290783804
Iteration 24830 loss 0.7620914248674991 train RMSE 0.3478387355339182 Validation RMSE 24830 : 0.35111105197723125 max of weights 2.315875502032068
Iteration 24840 loss 0.7751065886984134 train RMSE 0.3538242343599849 Validation RMSE 24840 : 0.3541169018351615 max of weights 2.3135073528423926
Iteration 24850 loss 0.759851756103437 train RMSE 0.34680511303400946 Validation RMSE 24850 : 0.35241073059539835 max of weights 2.3236585140659116
Iteration 24860 loss 0.761197127012993 train RMSE 0.3474209698060083 Validation RMSE 24860 : 0.3547636078691599 max of weights 2.3280097085924
Iteration 24870 loss 0.7650622379362122 train RMSE 0.3491935976677952 Validation RMSE 24870 : 0.34982305496483135 max of weights 2.329552280952256
Iteration 24880 loss 0.7636512997933038 train RMSE 0.34854101076002364 Validation RMSE 24880 : 0.3533393196148917 max of weights 2.3331623375593895
Iteration 24890 loss 0.7433840042140708 train RMSE 0.339214226168802 Validation RMSE 24890 : 0.35038161131497675 max of weights 2.330358506472124
Iteration 24900 loss 0.7404729344926831 train RMSE 0.3378665241237282 Validation RMSE 24900 : 0.35063583772730067 max of weights 2.331872101188215
Iteration 24910 loss 0.7371386932431313 train RMSE 0.33632914403934006 Validation RMSE 24910 : 0.3491058650175346 max of weights 2.326332251149929
Iteration 24920 loss 0.7493225552873726 train RMSE 0.3419354732378615 Validation RMSE 24920 : 0.34958694898388604 max of weights 2.3236346033374686
Iteration 24930 loss 0.762161393562645 train RMSE 0.34784046085309234 Validation RMSE 24930 : 0.34946737191631677 max of weights 2.32757489647478
Iteration 24940 loss 0.7711402528878818 train RMSE 0.35196548936665645 Validation RMSE 24940 : 0.34900853008487054 max of weights 2.3314068050245056
Iteration 24950 loss 0.7832755163237944 train RMSE 0.35754260934077425 Validation RMSE 24950 : 0.35245702609447493 max of weights 2.3293570247054234
Iteration 24960 loss 0.7968275394762355 train RMSE 0.36377505723746995 Validation RMSE 24960 : 0.35675753670007365 max of weights 2.326377304768842
Iteration 24970 loss 0.7717828278253193 train RMSE 0.35225152958345185 Validation RMSE 24970 : 0.3526343452393204 max of weights 2.32622012575955
Iteration 24980 loss 0.7730002048226666 train RMSE 0.3528151492107907 Validation RMSE 24980 : 0.35376642365342703 max of weights 2.3357411630303075
Iteration 24990 loss 0.7706667489292374 train RMSE 0.351742271859256 Validation RMSE 24990 : 0.3529444247986518 max of weights 2.3323544293483773
Iteration 25000 loss 0.7557348596711829 train RMSE 0.3448761382156608 Validation RMSE 25000 : 0.35210126459344726 max of weights 2.3279360924130756
Iteration 25010 loss 0.7183389277341952 train RMSE 0.3276706702059179 Validation RMSE 25010 : 0.35024869078023213 max of weights 2.3270482617614876
Iteration 25020 loss 0.7230541108265368 train RMSE 0.3298353390615258 Validation RMSE 25020 : 0.3527901430839347 max of weights 2.323716080584383
Iteration 25030 loss 0.74583065007154 train RMSE 0.34031139160001606 Validation RMSE 25030 : 0.36015522287997925 max of weights 2.314451695451713
Iteration 25040 loss 0.7414013000578893 train RMSE 0.3382731198116132 Validation RMSE 25040 : 0.3524239550309815 max of weights 2.3044476038917834
Iteration 25050 loss 0.7372440499562601 train RMSE 0.3363567999127207 Validation RMSE 25050 : 0.3526033294409076 max of weights 2.299964290202882
Iteration 25060 loss 0.7316612596888661 train RMSE 0.33378802075823616 Validation RMSE 25060 : 0.3509809971589653 max of weights 2.301721191629261
Iteration 25070 loss 0.7287022137482976 train RMSE 0.33242815687093413 Validation RMSE 25070 : 0.35126426442728304 max of weights 2.3066631371835213
Iteration 25080 loss 0.7321377927108376 train RMSE 0.33401321724846716 Validation RMSE 25080 : 0.35088456361554404 max of weights 2.3055548656668914
Iteration 25090 loss 0.7356650491743091 train RMSE 0.33563674785152314 Validation RMSE 25090 : 0.35263662823909125 max of weights 2.3038137927350335
Iteration 25100 loss 0.7308728997983969 train RMSE 0.33342646260510783 Validation RMSE 25100 : 0.3515358232641291 max of weights 2.304817059655984
Iteration 25110 loss 0.7366020112558602 train RMSE 0.3360527200902606 Validation RMSE 25110 : 0.3498074385544783 max of weights 2.29898613154662
Iteration 25120 loss 0.7547996528850706 train RMSE 0.3444204516715316 Validation RMSE 25120 : 0.35126671090703954 max of weights 2.29957031342923
Iteration 25130 loss 0.7342627555872456 train RMSE 0.33497225871285546 Validation RMSE 25130 : 0.35097297324216903 max of weights 2.307488740620145
Iteration 25140 loss 0.7382857907114517 train RMSE 0.3368256513927422 Validation RMSE 25140 : 0.349235359898071 max of weights 2.3145352039676235
Iteration 25150 loss 0.759042728190467 train RMSE 0.34637648146577604 Validation RMSE 25150 : 0.3512680440059613 max of weights 2.3095301854723127
Iteration 25160 loss 0.7719520697963105 train RMSE 0.3523094634003642 Validation RMSE 25160 : 0.3540665223995851 max of weights 2.3076337503767883
Iteration 25170 loss 0.7784781555102641 train RMSE 0.3553188448464627 Validation RMSE 25170 : 0.3521385460322604 max of weights 2.312249687577899
Iteration 25180 loss 0.7953663246509544 train RMSE 0.36309170066048446 Validation RMSE 25180 : 0.3509910418703889 max of weights 2.317383728629212
Iteration 25190 loss 0.7852521949202962 train RMSE 0.3584361337564989 Validation RMSE 25190 : 0.34881043727209393 max of weights 2.3241671093519742
Iteration 25200 loss 0.7651815159440835 train RMSE 0.34919841728960765 Validation RMSE 25200 : 0.34769400632580916 max of weights 2.3278652623965668
Iteration 25210 loss 0.772830407302083 train RMSE 0.35272306507351575 Validation RMSE 25210 : 0.34923295801332166 max of weights 2.3300171587710867
Iteration 25220 loss 0.8068090533421453 train RMSE 0.368358084631523 Validation RMSE 25220 : 0.36137761256579165 max of weights 2.3350059089170365
Iteration 25230 loss 0.7904401598858041 train RMSE 0.36082458468696654 Validation RMSE 25230 : 0.3521146388239673 max of weights 2.3390513483820468
Iteration 25240 loss 0.774049696698215 train RMSE 0.3532757339897801 Validation RMSE 25240 : 0.35279020240882664 max of weights 2.3421091600386474
Iteration 25250 loss 0.767501366843578 train RMSE 0.3502615240034764 Validation RMSE 25250 : 0.3519770098178796 max of weights 2.345148101045358
Iteration 25260 loss 0.7911274427804358 train RMSE 0.36113615016682277 Validation RMSE 25260 : 0.35249490282022866 max of weights 2.3531561094200164
Iteration 25270 loss 0.7835644415888116 train RMSE 0.3576507741563516 Validation RMSE 25270 : 0.351328442722902 max of weights 2.358886183989134
Iteration 25280 loss 0.7627875654065502 train RMSE 0.34808533708132594 Validation RMSE 25280 : 0.3495739392234981 max of weights 2.364882295909841
Iteration 25290 loss 0.7777145597183633 train RMSE 0.3549485658879269 Validation RMSE 25290 : 0.3507116735027496 max of weights 2.366135481834348
Iteration 25300 loss 0.8003543921937708 train RMSE 0.36535832401376295 Validation RMSE 25300 : 0.35976581784602824 max of weights 2.3706407756439685
Iteration 25310 loss 0.7808581227352059 train RMSE 0.35638521587026195 Validation RMSE 25310 : 0.3560670232993628 max of weights 2.36862008711289
Iteration 25320 loss 0.781186074150855 train RMSE 0.35654657010687885 Validation RMSE 25320 : 0.3495230165687465 max of weights 2.369062557632338
Iteration 25330 loss 0.7840143506002207 train RMSE 0.35785550391485105 Validation RMSE 25330 : 0.3537154288951647 max of weights 2.3690150775113286
Iteration 25340 loss 0.7542741018870345 train RMSE 0.34416910537406525 Validation RMSE 25340 : 0.34756138280341936 max of weights 2.3712860855613807
Iteration 25350 loss 0.7467755076450523 train RMSE 0.34071378040322603 Validation RMSE 25350 : 0.34756145339742606 max of weights 2.3705322280444006
Iteration 25360 loss 0.7443082467777946 train RMSE 0.33958748191223603 Validation RMSE 25360 : 0.3465210406029919 max of weights 2.371180555158909
Iteration 25370 loss 0.7397703737025207 train RMSE 0.3374997768062657 Validation RMSE 25370 : 0.346247567685271 max of weights 2.3753701743748254
Iteration 25380 loss 0.7420248495458964 train RMSE 0.33853166210761204 Validation RMSE 25380 : 0.3456081585598547 max of weights 2.369300818974762
Iteration 25390 loss 0.7563106069645892 train RMSE 0.34509942504634267 Validation RMSE 25390 : 0.3476141492247302 max of weights 2.3643340266680277
Iteration 25400 loss 0.7510883099470506 train RMSE 0.34270053996527355 Validation RMSE 25400 : 0.34814894837761834 max of weights 2.3541369143901636
Iteration 25410 loss 0.736207093736962 train RMSE 0.3358535398916125 Validation RMSE 25410 : 0.3464519984590476 max of weights 2.347742191561604
Iteration 25420 loss 0.7469264120739323 train RMSE 0.34078356919854247 Validation RMSE 25420 : 0.348052700855531 max of weights 2.3441741558700957
Iteration 25430 loss 0.7631161301210158 train RMSE 0.34823680912051347 Validation RMSE 25430 : 0.35000396480492885 max of weights 2.3438188144785213
Iteration 25440 loss 0.7460111865270994 train RMSE 0.3403587478195297 Validation RMSE 25440 : 0.3485801975066784 max of weights 2.348561073941317
Iteration 25450 loss 0.7587984384515526 train RMSE 0.3462444446368962 Validation RMSE 25450 : 0.34861443923712254 max of weights 2.3571640237160216
Iteration 25460 loss 0.7578638236506968 train RMSE 0.34581467448375497 Validation RMSE 25460 : 0.34908140062410503 max of weights 2.3569970755339806
Iteration 25470 loss 0.7493019517436232 train RMSE 0.3418754509012282 Validation RMSE 25470 : 0.3495721086256414 max of weights 2.356144803951543
Iteration 25480 loss 0.7493864140689964 train RMSE 0.3419139493551975 Validation RMSE 25480 : 0.3474913283352027 max of weights 2.3620926311673434
Iteration 25490 loss 0.7404641336590341 train RMSE 0.33780789939568573 Validation RMSE 25490 : 0.3451580031820851 max of weights 2.3674559535016324
Iteration 25500 loss 0.7278540361855862 train RMSE 0.33199736998977897 Validation RMSE 25500 : 0.3467010721762802 max of weights 2.381166454095426
Iteration 25510 loss 0.7370988429761849 train RMSE 0.3362439913050604 Validation RMSE 25510 : 0.34699478398799766 max of weights 2.3926864763669595
Iteration 25520 loss 0.7653644706214029 train RMSE 0.3492467045763374 Validation RMSE 25520 : 0.347013965191314 max of weights 2.39488234986961
Iteration 25530 loss 0.7664813332416022 train RMSE 0.34976740665718514 Validation RMSE 25530 : 0.3450384635221285 max of weights 2.3961594510606052
Iteration 25540 loss 0.7571281079105521 train RMSE 0.3454671608874925 Validation RMSE 25540 : 0.3448195563841714 max of weights 2.3994728026427854
Iteration 25550 loss 0.7681760107321126 train RMSE 0.350550626815689 Validation RMSE 25550 : 0.3487543965424296 max of weights 2.402367500385902
Iteration 25560 loss 0.7587284771831314 train RMSE 0.34619706473038653 Validation RMSE 25560 : 0.34706843204843024 max of weights 2.403865316528149
Iteration 25570 loss 0.7493219157212864 train RMSE 0.3418646168434542 Validation RMSE 25570 : 0.34637394801520655 max of weights 2.4058855039389497
Iteration 25580 loss 0.7507983244143359 train RMSE 0.34254868487107526 Validation RMSE 25580 : 0.34621819769726264 max of weights 2.408571599576111
Iteration 25590 loss 0.7577761359684656 train RMSE 0.3457647820770437 Validation RMSE 25590 : 0.34620670961911837 max of weights 2.41171329774355
Iteration 25600 loss 0.7759982501932617 train RMSE 0.3541492967556331 Validation RMSE 25600 : 0.350314426411836 max of weights 2.4101847761650785
Iteration 25610 loss 0.7687583030975451 train RMSE 0.35081827616141753 Validation RMSE 25610 : 0.34647248650395934 max of weights 2.4090375296768127
Iteration 25620 loss 0.7626424539413525 train RMSE 0.348004035909556 Validation RMSE 25620 : 0.34565285380076705 max of weights 2.4042720221700997
Iteration 25630 loss 0.7577060009696638 train RMSE 0.3457311288356261 Validation RMSE 25630 : 0.34741627979485573 max of weights 2.4102594516370326
Iteration 25640 loss 0.7452760895605747 train RMSE 0.3400083278943757 Validation RMSE 25640 : 0.35264654665670186 max of weights 2.415913975584157
Iteration 25650 loss 0.7547291570661533 train RMSE 0.3443610751933884 Validation RMSE 25650 : 0.34834589875323985 max of weights 2.414673689189008
Iteration 25660 loss 0.7420843596757973 train RMSE 0.3385478398707153 Validation RMSE 25660 : 0.3494922428725036 max of weights 2.417452085584681
Iteration 25670 loss 0.7299236937474578 train RMSE 0.3329577490348224 Validation RMSE 25670 : 0.34904010960336357 max of weights 2.421013857455646
Iteration 25680 loss 0.7348252877125485 train RMSE 0.3352124599356207 Validation RMSE 25680 : 0.35255301028779024 max of weights 2.4245649561610034
Iteration 25690 loss 0.7439264854959261 train RMSE 0.33939900730836176 Validation RMSE 25690 : 0.35181220503160543 max of weights 2.4273465429587135
Iteration 25700 loss 0.7632587481306053 train RMSE 0.3482869933366595 Validation RMSE 25700 : 0.34974899365440143 max of weights 2.4324724686492556
Iteration 25710 loss 0.7909469467829614 train RMSE 0.3610236858792447 Validation RMSE 25710 : 0.35180612273573775 max of weights 2.428249155086517
Iteration 25720 loss 0.7769299500627056 train RMSE 0.35457223476743294 Validation RMSE 25720 : 0.34699839396575505 max of weights 2.4194882814692136
Iteration 25730 loss 0.786279893630608 train RMSE 0.3588626739191501 Validation RMSE 25730 : 0.35310093772592027 max of weights 2.4066113616774367
Iteration 25740 loss 0.7987737116304244 train RMSE 0.36461059740874624 Validation RMSE 25740 : 0.3555510397727432 max of weights 2.3941728201449806
Iteration 25750 loss 0.7713528686446933 train RMSE 0.3519974604886755 Validation RMSE 25750 : 0.34999312202946536 max of weights 2.3891175005049647
Iteration 25760 loss 0.7634511322814186 train RMSE 0.3483644257383638 Validation RMSE 25760 : 0.34788919471002416 max of weights 2.386193593349933
Iteration 25770 loss 0.7704019506954705 train RMSE 0.3515608066852962 Validation RMSE 25770 : 0.35201376501960885 max of weights 2.380259127810519
Iteration 25780 loss 0.7603493599066 train RMSE 0.3469345752976858 Validation RMSE 25780 : 0.34796249876286456 max of weights 2.378335092629167
Iteration 25790 loss 0.7697554281842327 train RMSE 0.35126819056497305 Validation RMSE 25790 : 0.3524680132654379 max of weights 2.3782270350718937
Iteration 25800 loss 0.7687233224406619 train RMSE 0.3507945210504138 Validation RMSE 25800 : 0.3488169503376258 max of weights 2.378499044026254
Iteration 25810 loss 0.7724784915040638 train RMSE 0.35252024381865577 Validation RMSE 25810 : 0.3489713584195464 max of weights 2.364827351330262
Iteration 25820 loss 0.7558921879889567 train RMSE 0.3448881862800966 Validation RMSE 25820 : 0.34660236743961825 max of weights 2.3641584076559283
Iteration 25830 loss 0.7322296778308929 train RMSE 0.33400020631384725 Validation RMSE 25830 : 0.3454219580818503 max of weights 2.3686883970861072
Iteration 25840 loss 0.7304587644343616 train RMSE 0.3331854230253167 Validation RMSE 25840 : 0.34733798903783564 max of weights 2.3657281950107243
Iteration 25850 loss 0.7418958728081808 train RMSE 0.3384458495807223 Validation RMSE 25850 : 0.3462862101697142 max of weights 2.363862946320827
Iteration 25860 loss 0.749665011185247 train RMSE 0.3420204246412875 Validation RMSE 25860 : 0.34733285224711447 max of weights 2.3600106185557292
Iteration 25870 loss 0.7587299985055136 train RMSE 0.3461905631379881 Validation RMSE 25870 : 0.3499023990623035 max of weights 2.3567078115306943
Iteration 25880 loss 0.7467866160833923 train RMSE 0.34068944945349455 Validation RMSE 25880 : 0.34845521680892516 max of weights 2.357885836608931
Iteration 25890 loss 0.7482675183220577 train RMSE 0.3413665981105518 Validation RMSE 25890 : 0.3558736508414544 max of weights 2.361284942078882
Iteration 25900 loss 0.7626334659664311 train RMSE 0.3479807437572027 Validation RMSE 25900 : 0.3483528643240113 max of weights 2.364726252370702
Iteration 25910 loss 0.782503063508027 train RMSE 0.35712626386635066 Validation RMSE 25910 : 0.35242584644182773 max of weights 2.3574684181735024
Iteration 25920 loss 0.7733801573869233 train RMSE 0.3529323118694893 Validation RMSE 25920 : 0.351726289861152 max of weights 2.3580010604081965
Iteration 25930 loss 0.7525758548817228 train RMSE 0.34335807486140413 Validation RMSE 25930 : 0.3520544883874819 max of weights 2.361590550780003
Iteration 25940 loss 0.7481210832015092 train RMSE 0.3413081254216984 Validation RMSE 25940 : 0.34811589967803436 max of weights 2.3654937298240033
Iteration 25950 loss 0.766859652114051 train RMSE 0.34993284052010876 Validation RMSE 25950 : 0.34947325994609263 max of weights 2.369363797824077
Iteration 25960 loss 0.7549297822031722 train RMSE 0.3444306608913616 Validation RMSE 25960 : 0.3568705217299857 max of weights 2.367129736825272
Iteration 25970 loss 0.7506823975248877 train RMSE 0.34247208068758356 Validation RMSE 25970 : 0.348761672200312 max of weights 2.3619016874968253
Iteration 25980 loss 0.7799708120191327 train RMSE 0.3559483334235923 Validation RMSE 25980 : 0.35151133290716474 max of weights 2.359868135992261
Iteration 25990 loss 0.7617906610328313 train RMSE 0.34758355545092373 Validation RMSE 25990 : 0.3486664721663736 max of weights 2.3609486300289744
Iteration 26000 loss 0.7563364274032987 train RMSE 0.3450672475161269 Validation RMSE 26000 : 0.350614660819675 max of weights 2.3659211615878974
Iteration 26010 loss 0.7604459503917468 train RMSE 0.34695721289237386 Validation RMSE 26010 : 0.34993224063910616 max of weights 2.3687737688727295
Iteration 26020 loss 0.7531505224134015 train RMSE 0.3436026102947494 Validation RMSE 26020 : 0.34996300796664254 max of weights 2.374891219750265
Iteration 26030 loss 0.7313478446526566 train RMSE 0.3335762384679108 Validation RMSE 26030 : 0.3489864992692096 max of weights 2.375498668272497
Iteration 26040 loss 0.7243190219748615 train RMSE 0.33034894477206933 Validation RMSE 26040 : 0.34961746813742245 max of weights 2.3748813710694923
Iteration 26050 loss 0.7250168965353714 train RMSE 0.3306666654305001 Validation RMSE 26050 : 0.3491812959982805 max of weights 2.3732418451492716
Iteration 26060 loss 0.7096696294382989 train RMSE 0.32361482806297676 Validation RMSE 26060 : 0.3480259788673938 max of weights 2.3667892098578838
Iteration 26070 loss 0.7182438192039546 train RMSE 0.3275667667830042 Validation RMSE 26070 : 0.34800113497379614 max of weights 2.3623029371128994
Iteration 26080 loss 0.7370925105233662 train RMSE 0.33623626534811946 Validation RMSE 26080 : 0.34947282561404075 max of weights 2.3681707136449117
Iteration 26090 loss 0.7487938300259038 train RMSE 0.3416213073529349 Validation RMSE 26090 : 0.349367937692481 max of weights 2.37626670607173
Iteration 26100 loss 0.7596761060182822 train RMSE 0.34663110809798925 Validation RMSE 26100 : 0.3493674315606087 max of weights 2.381928853790829
Iteration 26110 loss 0.764386353987793 train RMSE 0.34879381471498977 Validation RMSE 26110 : 0.3508919381767197 max of weights 2.3847516769147292
Iteration 26120 loss 0.7804096761549575 train RMSE 0.35616502236091924 Validation RMSE 26120 : 0.35440312644286703 max of weights 2.3825808236062205
Iteration 26130 loss 0.7549271536019582 train RMSE 0.34443971438504084 Validation RMSE 26130 : 0.3522707311521925 max of weights 2.3825396510705676
Iteration 26140 loss 0.7313902443370816 train RMSE 0.3336034788507716 Validation RMSE 26140 : 0.3535518365849464 max of weights 2.3811922540422383
Iteration 26150 loss 0.7331070384518217 train RMSE 0.33438801719656314 Validation RMSE 26150 : 0.3510598348466411 max of weights 2.3793605422630386
Iteration 26160 loss 0.7520622573508252 train RMSE 0.3431039003355474 Validation RMSE 26160 : 0.3549537460148001 max of weights 2.3708632650335
Iteration 26170 loss 0.7690656172395058 train RMSE 0.3509318710263952 Validation RMSE 26170 : 0.3520325213116576 max of weights 2.3799063979361526
Iteration 26180 loss 0.7670942034922511 train RMSE 0.3500228478544829 Validation RMSE 26180 : 0.35111703066941535 max of weights 2.380394866366817
Iteration 26190 loss 0.7708928001409738 train RMSE 0.3517695811679462 Validation RMSE 26190 : 0.3521853882532043 max of weights 2.385454581941744
Iteration 26200 loss 0.7583166553615548 train RMSE 0.34598510330789434 Validation RMSE 26200 : 0.3516197444905038 max of weights 2.383859930505927
Iteration 26210 loss 0.743572903168955 train RMSE 0.33919414487564287 Validation RMSE 26210 : 0.34968729556752265 max of weights 2.389669627003657
Iteration 26220 loss 0.7469336158174963 train RMSE 0.34073765793441557 Validation RMSE 26220 : 0.3534196306192082 max of weights 2.4015282938308333
Iteration 26230 loss 0.7419996371550781 train RMSE 0.33847529658035275 Validation RMSE 26230 : 0.34813572058949477 max of weights 2.402087355365017
Iteration 26240 loss 0.7592423167880336 train RMSE 0.34641974125271907 Validation RMSE 26240 : 0.35137709185065713 max of weights 2.3981535459561845
Iteration 26250 loss 0.7603039351867337 train RMSE 0.34691111415251064 Validation RMSE 26250 : 0.3516298689660912 max of weights 2.3918116594352856
Iteration 26260 loss 0.7478569597456368 train RMSE 0.3411794319380811 Validation RMSE 26260 : 0.3499478233276879 max of weights 2.3954432726407755
Iteration 26270 loss 0.7484051272390341 train RMSE 0.34142245468269944 Validation RMSE 26270 : 0.3530679502701385 max of weights 2.3997164925049486
Iteration 26280 loss 0.7678741986176204 train RMSE 0.35038367227975464 Validation RMSE 26280 : 0.35156720474757 max of weights 2.3904815061811915
Iteration 26290 loss 0.7787223673941294 train RMSE 0.35537466670297013 Validation RMSE 26290 : 0.35576035206737056 max of weights 2.393553239866406
Iteration 26300 loss 0.7597289202747144 train RMSE 0.3466387649303982 Validation RMSE 26300 : 0.34907116103844915 max of weights 2.3966955419161304
Iteration 26310 loss 0.7638420757371818 train RMSE 0.3485247947519638 Validation RMSE 26310 : 0.3526624845851358 max of weights 2.399663147121771
Iteration 26320 loss 0.7710925985134668 train RMSE 0.3518567559656728 Validation RMSE 26320 : 0.3496076723528391 max of weights 2.408335886138713
Iteration 26330 loss 0.7607081713493061 train RMSE 0.34707739558071654 Validation RMSE 26330 : 0.35159141350860973 max of weights 2.4075911962673575
Iteration 26340 loss 0.7462724123741196 train RMSE 0.3404320374548057 Validation RMSE 26340 : 0.34929028655530675 max of weights 2.4008839031476725
Iteration 26350 loss 0.7426583846057847 train RMSE 0.3387617410688464 Validation RMSE 26350 : 0.3500261054718013 max of weights 2.3986603139482487
Iteration 26360 loss 0.7434080010777679 train RMSE 0.33910843872392527 Validation RMSE 26360 : 0.3479024208460835 max of weights 2.3967189096303607
Iteration 26370 loss 0.7513160350122148 train RMSE 0.3427462786363011 Validation RMSE 26370 : 0.348364904610228 max of weights 2.3944965199334582
Iteration 26380 loss 0.7636376113876152 train RMSE 0.34841392575028096 Validation RMSE 26380 : 0.3487451933693706 max of weights 2.3941616080390102
Iteration 26390 loss 0.7744135786439613 train RMSE 0.35336204256827697 Validation RMSE 26390 : 0.3501205178370984 max of weights 2.3933650000156717
Iteration 26400 loss 0.7793530225939458 train RMSE 0.35563047461532454 Validation RMSE 26400 : 0.3518299414778822 max of weights 2.3971337028266335
Iteration 26410 loss 0.7830119672862912 train RMSE 0.35731105618133424 Validation RMSE 26410 : 0.3536857823181555 max of weights 2.399844120629714
Iteration 26420 loss 0.7718990244174145 train RMSE 0.3521984272688748 Validation RMSE 26420 : 0.3540293844535459 max of weights 2.4021954232682976
Iteration 26430 loss 0.7698925065694976 train RMSE 0.3512805802667254 Validation RMSE 26430 : 0.35192680115384484 max of weights 2.4004161204777845
Iteration 26440 loss 0.7627398088191745 train RMSE 0.34798685452039474 Validation RMSE 26440 : 0.3524270629038468 max of weights 2.401787813069655
Iteration 26450 loss 0.7426596007811079 train RMSE 0.33875160813576394 Validation RMSE 26450 : 0.35085751935951703 max of weights 2.4063759711835213
Iteration 26460 loss 0.7104258114839374 train RMSE 0.32391881660670163 Validation RMSE 26460 : 0.3515418861302459 max of weights 2.403513196422841
Iteration 26470 loss 0.7208102403209332 train RMSE 0.3286937651275328 Validation RMSE 26470 : 0.3522625332493859 max of weights 2.3994727907505533
Iteration 26480 loss 0.7408242317168129 train RMSE 0.33789744352328094 Validation RMSE 26480 : 0.35758432595059175 max of weights 2.3997249893584223
Iteration 26490 loss 0.7323183342742728 train RMSE 0.333984980250143 Validation RMSE 26490 : 0.3514980851243381 max of weights 2.400081237916428
Iteration 26500 loss 0.7350439256511648 train RMSE 0.3352354207283757 Validation RMSE 26500 : 0.3521757196878947 max of weights 2.4002226723758184
Iteration 26510 loss 0.7255149188968416 train RMSE 0.33085236611742896 Validation RMSE 26510 : 0.3495060573244009 max of weights 2.399377757414527
Iteration 26520 loss 0.7339559080244011 train RMSE 0.33473774337181766 Validation RMSE 26520 : 0.350997252239129 max of weights 2.4022798597617587
Iteration 26530 loss 0.7354824550431405 train RMSE 0.33544399972272443 Validation RMSE 26530 : 0.35083271340684574 max of weights 2.398718716503931
Iteration 26540 loss 0.7380303492870599 train RMSE 0.33661601511685185 Validation RMSE 26540 : 0.35284394183139456 max of weights 2.400969967647076
Iteration 26550 loss 0.729420033247944 train RMSE 0.33264922450725687 Validation RMSE 26550 : 0.35046520887417837 max of weights 2.411013263327166
Iteration 26560 loss 0.7478292202467726 train RMSE 0.34111049794474463 Validation RMSE 26560 : 0.3497379308000207 max of weights 2.4154130235765354
Iteration 26570 loss 0.7535026041883073 train RMSE 0.3437187291577639 Validation RMSE 26570 : 0.3503770560553497 max of weights 2.410228775227715
Iteration 26580 loss 0.739130108632892 train RMSE 0.3371049904760713 Validation RMSE 26580 : 0.3507947709861676 max of weights 2.408867625366599
Iteration 26590 loss 0.7452573462011451 train RMSE 0.33992649350655246 Validation RMSE 26590 : 0.3495130088261286 max of weights 2.416121162754552
Iteration 26600 loss 0.7625878287298593 train RMSE 0.34789865795210473 Validation RMSE 26600 : 0.3525777321285366 max of weights 2.4158975271080685
Iteration 26610 loss 0.769811253528572 train RMSE 0.3512185681289431 Validation RMSE 26610 : 0.35325329778969133 max of weights 2.4121295227358286
Iteration 26620 loss 0.78055306702594 train RMSE 0.3561663320864731 Validation RMSE 26620 : 0.3516752142019032 max of weights 2.4086365213488845
Iteration 26630 loss 0.7939763540627928 train RMSE 0.36234538480987283 Validation RMSE 26630 : 0.351649392676245 max of weights 2.404970503130595
Iteration 26640 loss 0.7737479227737318 train RMSE 0.3530354999138207 Validation RMSE 26640 : 0.3498016857252943 max of weights 2.408286743176632
Iteration 26650 loss 0.7617625673150115 train RMSE 0.34752320829493843 Validation RMSE 26650 : 0.34806454344544424 max of weights 2.410245189279946
Iteration 26660 loss 0.7721977695281077 train RMSE 0.3523290472090663 Validation RMSE 26660 : 0.34933622197498976 max of weights 2.410426950221822
Iteration 26670 loss 0.8110569255677565 train RMSE 0.37020779397402065 Validation RMSE 26670 : 0.36194157849558967 max of weights 2.408467939144531
Iteration 26680 loss 0.785313896825593 train RMSE 0.3583598822829659 Validation RMSE 26680 : 0.35086638265284736 max of weights 2.404407021055689
Iteration 26690 loss 0.7712728216600016 train RMSE 0.3518904443327694 Validation RMSE 26690 : 0.35345648792904377 max of weights 2.409457782984874
Iteration 26700 loss 0.7686689554208729 train RMSE 0.3506933104356582 Validation RMSE 26700 : 0.3503111843623824 max of weights 2.4162084917204396
Iteration 26710 loss 0.786172665313437 train RMSE 0.35875094067058844 Validation RMSE 26710 : 0.3517815620780611 max of weights 2.417258667028442
Iteration 26720 loss 0.769912101194794 train RMSE 0.35126033322057115 Validation RMSE 26720 : 0.3513015532592849 max of weights 2.413085852508034
Iteration 26730 loss 0.7604215311666446 train RMSE 0.34689146763113016 Validation RMSE 26730 : 0.34927615801565837 max of weights 2.4094514628104067
Iteration 26740 loss 0.7893939194614378 train RMSE 0.3602172871756458 Validation RMSE 26740 : 0.3527249863556606 max of weights 2.4138183832507214
Iteration 26750 loss 0.800106132928791 train RMSE 0.36513767849920975 Validation RMSE 26750 : 0.36033487839259815 max of weights 2.4203160109570985
Iteration 26760 loss 0.7702603806457614 train RMSE 0.35140513116619054 Validation RMSE 26760 : 0.35147668403469534 max of weights 2.423813762560333
Iteration 26770 loss 0.7779987048400955 train RMSE 0.35497686095332653 Validation RMSE 26770 : 0.3485076785614265 max of weights 2.4246342061652495
Iteration 26780 loss 0.7726720813265465 train RMSE 0.3525314415191177 Validation RMSE 26780 : 0.35155167484252103 max of weights 2.4209572065130205
Iteration 26790 loss 0.7517486707281342 train RMSE 0.34290114034487407 Validation RMSE 26790 : 0.3473565796191555 max of weights 2.4181975322776954
Iteration 26800 loss 0.7482507744112719 train RMSE 0.34128841922703373 Validation RMSE 26800 : 0.3471091552663429 max of weights 2.418130316552741
Iteration 26810 loss 0.7506001825023346 train RMSE 0.34238055699480247 Validation RMSE 26810 : 0.34659262793164586 max of weights 2.4201097662827307
Iteration 26820 loss 0.7389307857552374 train RMSE 0.33700692057977244 Validation RMSE 26820 : 0.34753524307356803 max of weights 2.416401187992143
Iteration 26830 loss 0.7429996835643763 train RMSE 0.3388717119984681 Validation RMSE 26830 : 0.3462301170642198 max of weights 2.4130985700949728
Iteration 26840 loss 0.7530177488056369 train RMSE 0.343479062511177 Validation RMSE 26840 : 0.347649031286931 max of weights 2.4109407620709917
Iteration 26850 loss 0.7416988866026938 train RMSE 0.3382746919308116 Validation RMSE 26850 : 0.3467546684658432 max of weights 2.4083320374859603
Iteration 26860 loss 0.7320866250609908 train RMSE 0.3338502500227523 Validation RMSE 26860 : 0.34529393952415394 max of weights 2.4103310489912126
Iteration 26870 loss 0.7566093984678095 train RMSE 0.3451336571492576 Validation RMSE 26870 : 0.34981857100856223 max of weights 2.4174051565883574
Iteration 26880 loss 0.7581108589661845 train RMSE 0.3458256336112474 Validation RMSE 26880 : 0.34862262794640386 max of weights 2.4196669606455306
Iteration 26890 loss 0.7410071459207966 train RMSE 0.3379485178714103 Validation RMSE 26890 : 0.34702743825522564 max of weights 2.4213945934825762
Iteration 26900 loss 0.7535045976467837 train RMSE 0.3436996796295219 Validation RMSE 26900 : 0.3496812537464857 max of weights 2.429671451205614
Iteration 26910 loss 0.7482241142976385 train RMSE 0.34126946245841827 Validation RMSE 26910 : 0.3497901256080077 max of weights 2.4341652439689936
Iteration 26920 loss 0.7383885187082986 train RMSE 0.3367458730854852 Validation RMSE 26920 : 0.3483654859690443 max of weights 2.4376980084588196
Iteration 26930 loss 0.7425930215022258 train RMSE 0.3386785667234653 Validation RMSE 26930 : 0.34716711481343243 max of weights 2.438545301902833
Iteration 26940 loss 0.7253089054173635 train RMSE 0.3307242048513119 Validation RMSE 26940 : 0.3432760744131291 max of weights 2.439655949519023
Iteration 26950 loss 0.7297974962138881 train RMSE 0.3327813571700144 Validation RMSE 26950 : 0.3522536480912606 max of weights 2.440221011144523
Iteration 26960 loss 0.7385585691969035 train RMSE 0.33681044707853974 Validation RMSE 26960 : 0.3454031126371638 max of weights 2.4419130327137415
Iteration 26970 loss 0.7613186987944999 train RMSE 0.3472805057320028 Validation RMSE 26970 : 0.3477624835385879 max of weights 2.443849443588794
Iteration 26980 loss 0.7553670610033432 train RMSE 0.34454921056362103 Validation RMSE 26980 : 0.34417290877195655 max of weights 2.440895851674877
Iteration 26990 loss 0.7444757663612438 train RMSE 0.33953978716178196 Validation RMSE 26990 : 0.34577610911132395 max of weights 2.443944049253456
Iteration 27000 loss 0.7528314213669124 train RMSE 0.3433842986279472 Validation RMSE 27000 : 0.3468541669647094 max of weights 2.4476570489962
Iteration 27010 loss 0.7484233210522809 train RMSE 0.3413475773680805 Validation RMSE 27010 : 0.3469768714999273 max of weights 2.4477443397233922
Iteration 27020 loss 0.7335803038429944 train RMSE 0.3345169107828483 Validation RMSE 27020 : 0.34615964452694586 max of weights 2.45187836968305
Iteration 27030 loss 0.7442204782317808 train RMSE 0.33941883560055797 Validation RMSE 27030 : 0.347165528315293 max of weights 2.457344645807373
Iteration 27040 loss 0.7625323878385198 train RMSE 0.34784858569850585 Validation RMSE 27040 : 0.3490189123321153 max of weights 2.4601675176870774
Iteration 27050 loss 0.7782771766721458 train RMSE 0.3550944049799896 Validation RMSE 27050 : 0.35245650837860515 max of weights 2.4617828812787748
Iteration 27060 loss 0.7566295885829708 train RMSE 0.3451314347344558 Validation RMSE 27060 : 0.34473278949742014 max of weights 2.4573925193388093
Iteration 27070 loss 0.7543262905897333 train RMSE 0.34407183410540854 Validation RMSE 27070 : 0.34576085473753226 max of weights 2.4562378111084016
Iteration 27080 loss 0.74763396631031 train RMSE 0.34098859259970177 Validation RMSE 27080 : 0.3489811270548844 max of weights 2.4615229771462066
Iteration 27090 loss 0.73721245304566 train RMSE 0.3361949856114925 Validation RMSE 27090 : 0.3490935648680219 max of weights 2.4631699565314755
Iteration 27100 loss 0.7471234618483807 train RMSE 0.340761953331687 Validation RMSE 27100 : 0.3465129911815617 max of weights 2.463788531292982
Iteration 27110 loss 0.7298481890390528 train RMSE 0.3328147258544558 Validation RMSE 27110 : 0.35111126401497617 max of weights 2.4675437574259877
Iteration 27120 loss 0.7363025540285343 train RMSE 0.33578786745997596 Validation RMSE 27120 : 0.35229931208322735 max of weights 2.470188815985625
Iteration 27130 loss 0.7264544790289036 train RMSE 0.33125326152910883 Validation RMSE 27130 : 0.35212531324848123 max of weights 2.4727454114821414
Iteration 27140 loss 0.7386474647249918 train RMSE 0.3368617136095656 Validation RMSE 27140 : 0.35002035086943895 max of weights 2.472722250983034
Iteration 27150 loss 0.7695737783536326 train RMSE 0.35108511620326727 Validation RMSE 27150 : 0.34928480407440143 max of weights 2.46887382635306
Iteration 27160 loss 0.7886971814663662 train RMSE 0.3598827499259551 Validation RMSE 27160 : 0.34970571693330965 max of weights 2.460143451816036
Iteration 27170 loss 0.7805590642400091 train RMSE 0.35613208026450865 Validation RMSE 27170 : 0.348653526424782 max of weights 2.4528354517159436
Iteration 27180 loss 0.7813569742347138 train RMSE 0.3564884433802655 Validation RMSE 27180 : 0.3517028505234558 max of weights 2.437825260166623
Iteration 27190 loss 0.788759018479263 train RMSE 0.3598952857308091 Validation RMSE 27190 : 0.35333715358401846 max of weights 2.4287789226274032
Iteration 27200 loss 0.7623465909920353 train RMSE 0.34774368357981816 Validation RMSE 27200 : 0.3482701916649059 max of weights 2.4279512536545766
Iteration 27210 loss 0.7578962114175206 train RMSE 0.34569910450542707 Validation RMSE 27210 : 0.3456680104450536 max of weights 2.42751037680793
Iteration 27220 loss 0.7619739217217666 train RMSE 0.3475741129018448 Validation RMSE 27220 : 0.34744502725414644 max of weights 2.4242621470125654
Iteration 27230 loss 0.7577555869036908 train RMSE 0.34563259740450786 Validation RMSE 27230 : 0.34593446289314433 max of weights 2.425697589555633
Iteration 27240 loss 0.7786356837131622 train RMSE 0.35524617522740914 Validation RMSE 27240 : 0.3535719116645879 max of weights 2.428872166774305
Iteration 27250 loss 0.769411055404795 train RMSE 0.351000788642383 Validation RMSE 27250 : 0.3485346450762944 max of weights 2.422505640285844
Iteration 27260 loss 0.774994635760208 train RMSE 0.35357169543136857 Validation RMSE 27260 : 0.3486917450816078 max of weights 2.408332083035549
Iteration 27270 loss 0.7662088918862152 train RMSE 0.3495296643372978 Validation RMSE 27270 : 0.3481457111267551 max of weights 2.4185540948141337
Iteration 27280 loss 0.7335977019945635 train RMSE 0.33452234104316964 Validation RMSE 27280 : 0.3473656538870592 max of weights 2.4093764825463437
Iteration 27290 loss 0.7393986740309142 train RMSE 0.3371905813357492 Validation RMSE 27290 : 0.3450616977750433 max of weights 2.4086306996796707
Iteration 27300 loss 0.7454700310252632 train RMSE 0.3399822054275411 Validation RMSE 27300 : 0.3464740917954659 max of weights 2.4131061836030017
Iteration 27310 loss 0.7482013876869033 train RMSE 0.3412400062000852 Validation RMSE 27310 : 0.3479662066700303 max of weights 2.4242229785995506
Iteration 27320 loss 0.7522148120470824 train RMSE 0.34308149022008344 Validation RMSE 27320 : 0.3480279515862453 max of weights 2.421378672638307
Iteration 27330 loss 0.7376154473152324 train RMSE 0.3363594623443207 Validation RMSE 27330 : 0.3494502732505397 max of weights 2.4211283150724445
Iteration 27340 loss 0.7421672561264353 train RMSE 0.33845135304037327 Validation RMSE 27340 : 0.3505515923313741 max of weights 2.4215745661890957
Iteration 27350 loss 0.7752389882663259 train RMSE 0.3536715599103719 Validation RMSE 27350 : 0.35146219148254365 max of weights 2.422868792210173
Iteration 27360 loss 0.7860501181516679 train RMSE 0.3586485550852486 Validation RMSE 27360 : 0.35276565899993967 max of weights 2.429847476145944
Iteration 27370 loss 0.7653961711063128 train RMSE 0.34914584345902644 Validation RMSE 27370 : 0.351654387814734 max of weights 2.4341914261691153
Iteration 27380 loss 0.7401687333274913 train RMSE 0.33753421057927296 Validation RMSE 27380 : 0.35189459599912004 max of weights 2.4343427967254545
Iteration 27390 loss 0.751806217247547 train RMSE 0.3428936169516386 Validation RMSE 27390 : 0.34776248234115564 max of weights 2.4341851127756273
Iteration 27400 loss 0.7562128299346308 train RMSE 0.34492223857393184 Validation RMSE 27400 : 0.34836109259984366 max of weights 2.4390469104361325
Iteration 27410 loss 0.7444344035738707 train RMSE 0.3394908451597774 Validation RMSE 27410 : 0.3498663505934752 max of weights 2.439295385978993
Iteration 27420 loss 0.7577800922338682 train RMSE 0.3456278792516454 Validation RMSE 27420 : 0.3483301841284834 max of weights 2.440177218220883
Iteration 27430 loss 0.7842398851995172 train RMSE 0.3578053739566847 Validation RMSE 27430 : 0.3506512019356573 max of weights 2.4551864063334894
Iteration 27440 loss 0.7607753368006164 train RMSE 0.34700584470594187 Validation RMSE 27440 : 0.34742451750286096 max of weights 2.4669069499219085
Iteration 27450 loss 0.7597156448918737 train RMSE 0.3465104923395814 Validation RMSE 27450 : 0.34999003584504407 max of weights 2.4744532844860156
Iteration 27460 loss 0.759955715320764 train RMSE 0.3466236886861359 Validation RMSE 27460 : 0.34879633608992 max of weights 2.4781647555181845
Iteration 27470 loss 0.7538891981786977 train RMSE 0.3438343297528718 Validation RMSE 27470 : 0.3501935243097475 max of weights 2.481813541485279
Iteration 27480 loss 0.725910457748344 train RMSE 0.33096671288480056 Validation RMSE 27480 : 0.34984659233025206 max of weights 2.4766536722852
Iteration 27490 loss 0.7233347032677294 train RMSE 0.32978539495391035 Validation RMSE 27490 : 0.3486306168133172 max of weights 2.4793433872189095
Iteration 27500 loss 0.7117706457054991 train RMSE 0.32446150352224673 Validation RMSE 27500 : 0.3489611541470674 max of weights 2.471955031269632
Iteration 27510 loss 0.713373949935882 train RMSE 0.32520555573940446 Validation RMSE 27510 : 0.35002806425557653 max of weights 2.461281462400954
Iteration 27520 loss 0.7278550700505328 train RMSE 0.3318738834289001 Validation RMSE 27520 : 0.3483034660074831 max of weights 2.4532663322823716
Iteration 27530 loss 0.7418759719457291 train RMSE 0.33832016543161847 Validation RMSE 27530 : 0.3510794601930419 max of weights 2.448398516677625
Iteration 27540 loss 0.7457387650582019 train RMSE 0.34010322931577364 Validation RMSE 27540 : 0.3494374972858873 max of weights 2.448469229828906
Iteration 27550 loss 0.7552696998185915 train RMSE 0.3444877785565561 Validation RMSE 27550 : 0.3509928269336401 max of weights 2.446379729161754
Iteration 27560 loss 0.7565024197046335 train RMSE 0.34504862568265743 Validation RMSE 27560 : 0.3508155454002729 max of weights 2.4546148386538404
Iteration 27570 loss 0.7689395556844658 train RMSE 0.350773491624001 Validation RMSE 27570 : 0.35352877840238733 max of weights 2.468308520972084
Iteration 27580 loss 0.7426309983768979 train RMSE 0.3386655845715106 Validation RMSE 27580 : 0.35229906087773377 max of weights 2.472570520630723
Iteration 27590 loss 0.7222088594727148 train RMSE 0.32926249812072345 Validation RMSE 27590 : 0.35145357899582685 max of weights 2.4749279463551046
Iteration 27600 loss 0.7365979664046364 train RMSE 0.3358784440724021 Validation RMSE 27600 : 0.35291345260923995 max of weights 2.4701070871985817
Iteration 27610 loss 0.7639533882875496 train RMSE 0.3484659329760348 Validation RMSE 27610 : 0.3539282985107528 max of weights 2.4630563027165078
Iteration 27620 loss 0.7694952952949644 train RMSE 0.35101873189302946 Validation RMSE 27620 : 0.35202883222168074 max of weights 2.4690445037139974
Iteration 27630 loss 0.7654142195351978 train RMSE 0.34913948436937736 Validation RMSE 27630 : 0.3499039508437481 max of weights 2.4726843605318085
Iteration 27640 loss 0.7676391165836565 train RMSE 0.35016533612488526 Validation RMSE 27640 : 0.3511224633480562 max of weights 2.475421473375436
Iteration 27650 loss 0.7508752050735368 train RMSE 0.3424506072094182 Validation RMSE 27650 : 0.3507349950637141 max of weights 2.474464408780367
Iteration 27660 loss 0.7433528957024248 train RMSE 0.33898217723690527 Validation RMSE 27660 : 0.35038461963529993 max of weights 2.4842201538965756
Iteration 27670 loss 0.7481208434234973 train RMSE 0.34117201912715944 Validation RMSE 27670 : 0.3524884767318191 max of weights 2.4941918602920747
Iteration 27680 loss 0.7476748450331752 train RMSE 0.34097625680295535 Validation RMSE 27680 : 0.3478605529089013 max of weights 2.495829151021792
Iteration 27690 loss 0.7572457745272618 train RMSE 0.3453862028226608 Validation RMSE 27690 : 0.3505887671180622 max of weights 2.489216579919156
Iteration 27700 loss 0.7646378083856247 train RMSE 0.3487889252903818 Validation RMSE 27700 : 0.35172245129458385 max of weights 2.48516044129014
Iteration 27710 loss 0.7434320655826236 train RMSE 0.33902630129333744 Validation RMSE 27710 : 0.34891137087353463 max of weights 2.4902059944349215
Iteration 27720 loss 0.7528835971566238 train RMSE 0.3433693593195018 Validation RMSE 27720 : 0.3512220268910821 max of weights 2.488191045109095
Iteration 27730 loss 0.7635178253670394 train RMSE 0.3482638015620417 Validation RMSE 27730 : 0.35024882504324734 max of weights 2.482091296398154
Iteration 27740 loss 0.7683438237301532 train RMSE 0.35048692030173934 Validation RMSE 27740 : 0.3540590176030233 max of weights 2.484276984183294
Iteration 27750 loss 0.764694682294091 train RMSE 0.3488128509118534 Validation RMSE 27750 : 0.35272406216410834 max of weights 2.4838309318311538
Iteration 27760 loss 0.7645076470977339 train RMSE 0.34872022239837214 Validation RMSE 27760 : 0.3501731501531815 max of weights 2.4895439874650878
Iteration 27770 loss 0.7660898248865015 train RMSE 0.34944555519242265 Validation RMSE 27770 : 0.3502726443227054 max of weights 2.4947164328025546
Iteration 27780 loss 0.7473826829868065 train RMSE 0.34083749422846726 Validation RMSE 27780 : 0.35041005022798427 max of weights 2.4908623866170365
Iteration 27790 loss 0.737860087102035 train RMSE 0.33644848422149903 Validation RMSE 27790 : 0.35101914805427076 max of weights 2.4844036990489666
Iteration 27800 loss 0.7334027422580862 train RMSE 0.33439193462954153 Validation RMSE 27800 : 0.3498425459147618 max of weights 2.484052280038997
Iteration 27810 loss 0.7416235197802276 train RMSE 0.33817673825019967 Validation RMSE 27810 : 0.34737067633299523 max of weights 2.4830273192468955
Iteration 27820 loss 0.7476768530086797 train RMSE 0.34095991025393985 Validation RMSE 27820 : 0.3479162249779098 max of weights 2.4836470104619752
Iteration 27830 loss 0.7571145874855165 train RMSE 0.34529897599771503 Validation RMSE 27830 : 0.34876874560094967 max of weights 2.485684623425736
Iteration 27840 loss 0.7655790085468868 train RMSE 0.34918409964438996 Validation RMSE 27840 : 0.3506716180311293 max of weights 2.4853373302533566
Iteration 27850 loss 0.7785102177890983 train RMSE 0.35513127417958623 Validation RMSE 27850 : 0.3527543240785251 max of weights 2.4858529955960824
Iteration 27860 loss 0.7675940205328131 train RMSE 0.3501062090055683 Validation RMSE 27860 : 0.3510503456053562 max of weights 2.4844863605324314
Iteration 27870 loss 0.7626197645358053 train RMSE 0.3478170535225739 Validation RMSE 27870 : 0.3531641011934269 max of weights 2.4855011256508948
Iteration 27880 loss 0.761281706303116 train RMSE 0.3472018140969487 Validation RMSE 27880 : 0.3513097661295941 max of weights 2.487623026309852
Iteration 27890 loss 0.7514076794185268 train RMSE 0.3426575783422518 Validation RMSE 27890 : 0.3511608101397604 max of weights 2.4939971091656017
Iteration 27900 loss 0.7270763628682251 train RMSE 0.33146556983523595 Validation RMSE 27900 : 0.34991091037118244 max of weights 2.4970268966820544
Iteration 27910 loss 0.71283519228673 train RMSE 0.32491103050389086 Validation RMSE 27910 : 0.35486177898777216 max of weights 2.4920607304396465
Iteration 27920 loss 0.7302560309462419 train RMSE 0.33292661041445043 Validation RMSE 27920 : 0.3549371091473326 max of weights 2.4878513394361086
Iteration 27930 loss 0.7392909725106837 train RMSE 0.33708300141907305 Validation RMSE 27930 : 0.3534075611942701 max of weights 2.4866102372254337
Iteration 27940 loss 0.7284263474964457 train RMSE 0.33208427215938086 Validation RMSE 27940 : 0.3512745068404727 max of weights 2.486646797136805
Iteration 27950 loss 0.7358091975329802 train RMSE 0.33547748249793796 Validation RMSE 27950 : 0.3509029501377893 max of weights 2.484248713732832
Iteration 27960 loss 0.7256722059817999 train RMSE 0.3308146903889994 Validation RMSE 27960 : 0.349044807782354 max of weights 2.4855104794176173
Iteration 27970 loss 0.7340708078917358 train RMSE 0.33468134633294094 Validation RMSE 27970 : 0.3505912899133724 max of weights 2.489839671574711
Iteration 27980 loss 0.7360122416483811 train RMSE 0.33557897609665743 Validation RMSE 27980 : 0.3502054887515791 max of weights 2.4892522569392503
Iteration 27990 loss 0.7291637025228553 train RMSE 0.33242473087530905 Validation RMSE 27990 : 0.35100161340260316 max of weights 2.4972448042597972
Iteration 28000 loss 0.727311987516579 train RMSE 0.33156614091926967 Validation RMSE 28000 : 0.3490624320580205 max of weights 2.509471431745995
Iteration 28010 loss 0.7505951818887533 train RMSE 0.34227093305149847 Validation RMSE 28010 : 0.3491193065894716 max of weights 2.5136531159524473
Iteration 28020 loss 0.7478376115532712 train RMSE 0.34100230672070353 Validation RMSE 28020 : 0.3499724636370382 max of weights 2.5085715392429058
Iteration 28030 loss 0.7372674416284803 train RMSE 0.3361375480583476 Validation RMSE 28030 : 0.3497305246331869 max of weights 2.5123146294951124
Iteration 28040 loss 0.7545664277867016 train RMSE 0.34409792546486057 Validation RMSE 28040 : 0.34902644447125597 max of weights 2.518413998414341
Iteration 28050 loss 0.7668163028780414 train RMSE 0.3497282273446043 Validation RMSE 28050 : 0.3524280395488208 max of weights 2.5163674497279813
Iteration 28060 loss 0.7751981729251917 train RMSE 0.3535853570973958 Validation RMSE 28060 : 0.35261828360660763 max of weights 2.511781248995143
Iteration 28070 loss 0.7832773185080258 train RMSE 0.35730559936173373 Validation RMSE 28070 : 0.35080641419513925 max of weights 2.506555626407535
Iteration 28080 loss 0.7846485427829905 train RMSE 0.3579396477685556 Validation RMSE 28080 : 0.35016620740791893 max of weights 2.502965750302664
Iteration 28090 loss 0.7690186396091679 train RMSE 0.3507427099763912 Validation RMSE 28090 : 0.35086317091725583 max of weights 2.505341584424015
Iteration 28100 loss 0.7593916398765002 train RMSE 0.34631814938369976 Validation RMSE 28100 : 0.34759363047829944 max of weights 2.509772245044566
Iteration 28110 loss 0.7740563271144916 train RMSE 0.3530688499678405 Validation RMSE 28110 : 0.3514188234541074 max of weights 2.5115023678086867
Iteration 28120 loss 0.7946447988885369 train RMSE 0.36253966355888173 Validation RMSE 28120 : 0.3546890542971581 max of weights 2.5107631041907346
Iteration 28130 loss 0.7765161939080057 train RMSE 0.35419312720242335 Validation RMSE 28130 : 0.34870636331711663 max of weights 2.509762247902484
Iteration 28140 loss 0.7727514993317948 train RMSE 0.35245625136059655 Validation RMSE 28140 : 0.35233107651193196 max of weights 2.516737952629604
Iteration 28150 loss 0.7867037569439104 train RMSE 0.35887904978652563 Validation RMSE 28150 : 0.34990986446556055 max of weights 2.52433240023995
Iteration 28160 loss 0.7918222172076276 train RMSE 0.36123471782084215 Validation RMSE 28160 : 0.3526211244675699 max of weights 2.524566854263909
Iteration 28170 loss 0.7597331354256924 train RMSE 0.34646101781074023 Validation RMSE 28170 : 0.3504280791674992 max of weights 2.518061765655704
Iteration 28180 loss 0.760736496772962 train RMSE 0.3469192642294147 Validation RMSE 28180 : 0.3486116618372358 max of weights 2.5122543114950417
Iteration 28190 loss 0.7919732578976245 train RMSE 0.36128499010135684 Validation RMSE 28190 : 0.35678120248825057 max of weights 2.516299858892299
Iteration 28200 loss 0.7881732539837969 train RMSE 0.359528993362686 Validation RMSE 28200 : 0.36231345316126146 max of weights 2.5163197842758906
Iteration 28210 loss 0.7682431854502262 train RMSE 0.350365444174445 Validation RMSE 28210 : 0.34958899740709304 max of weights 2.514555995861142
Iteration 28220 loss 0.7770824623548281 train RMSE 0.3544424766127078 Validation RMSE 28220 : 0.35060587705330915 max of weights 2.5121923676227182
Iteration 28230 loss 0.7569075727343366 train RMSE 0.3451615982615255 Validation RMSE 28230 : 0.3490584727382911 max of weights 2.5067931812422897
Iteration 28240 loss 0.743734577116983 train RMSE 0.33909770235586084 Validation RMSE 28240 : 0.3462585503856919 max of weights 2.502780202968329
Iteration 28250 loss 0.7501779685221349 train RMSE 0.34206287331540963 Validation RMSE 28250 : 0.34618912023617643 max of weights 2.5046160932402497
Iteration 28260 loss 0.7584916856536043 train RMSE 0.3458970956801069 Validation RMSE 28260 : 0.34986026472730736 max of weights 2.5043279367298243
Iteration 28270 loss 0.7447833333914071 train RMSE 0.339584054131665 Validation RMSE 28270 : 0.34794646740312724 max of weights 2.4985088071347996
Iteration 28280 loss 0.7568682385337956 train RMSE 0.3451366279138408 Validation RMSE 28280 : 0.3466294551883672 max of weights 2.4957579822924325
Iteration 28290 loss 0.756609137227243 train RMSE 0.34501849599970613 Validation RMSE 28290 : 0.34764483985686184 max of weights 2.4924068959197605
Iteration 28300 loss 0.7408174605149609 train RMSE 0.33775473344460283 Validation RMSE 28300 : 0.34593402729569156 max of weights 2.4903771873746994
Iteration 28310 loss 0.7407064380934952 train RMSE 0.33770011134340366 Validation RMSE 28310 : 0.3451979218326156 max of weights 2.4937224920295664
Iteration 28320 loss 0.76719508570565 train RMSE 0.3498914105283577 Validation RMSE 28320 : 0.3501870571976862 max of weights 2.497209642218907
Iteration 28330 loss 0.7589481076349455 train RMSE 0.3460935550103831 Validation RMSE 28330 : 0.34765189886719 max of weights 2.49777042137949
Iteration 28340 loss 0.7478262421289588 train RMSE 0.34097343887875536 Validation RMSE 28340 : 0.3455728726590146 max of weights 2.502701688307824
Iteration 28350 loss 0.7555668844254898 train RMSE 0.34453457196722964 Validation RMSE 28350 : 0.3482052810587801 max of weights 2.509491166197896
Iteration 28360 loss 0.7514356930115376 train RMSE 0.3426322179048477 Validation RMSE 28360 : 0.3494133125940356 max of weights 2.515761385079502
Iteration 28370 loss 0.7415094219800216 train RMSE 0.33806480175605574 Validation RMSE 28370 : 0.34651947863824306 max of weights 2.5187078294268472
Iteration 28380 loss 0.7418287466202416 train RMSE 0.33820998019852194 Validation RMSE 28380 : 0.34480145180444477 max of weights 2.521673127847298
Iteration 28390 loss 0.7287323643704344 train RMSE 0.3321805279033975 Validation RMSE 28390 : 0.34327306360355736 max of weights 2.5277711430170844
Iteration 28400 loss 0.7287130735462183 train RMSE 0.332165311594989 Validation RMSE 28400 : 0.34834203951676945 max of weights 2.528192728693805
Iteration 28410 loss 0.74692155756596 train RMSE 0.34054304816695935 Validation RMSE 28410 : 0.344843231639861 max of weights 2.5292563879192707
Iteration 28420 loss 0.7506238060864421 train RMSE 0.34224821902413793 Validation RMSE 28420 : 0.34408978514970473 max of weights 2.5308179253918395
Iteration 28430 loss 0.7478784323876738 train RMSE 0.3409887618200842 Validation RMSE 28430 : 0.3429945255622813 max of weights 2.5313848797066782
Iteration 28440 loss 0.7457290647805623 train RMSE 0.34000168275880577 Validation RMSE 28440 : 0.3457689694835823 max of weights 2.5292356741798967
Iteration 28450 loss 0.7476805262029111 train RMSE 0.3408958328049031 Validation RMSE 28450 : 0.3462940344011832 max of weights 2.524174915399704
Iteration 28460 loss 0.7454502200973067 train RMSE 0.33986235553748295 Validation RMSE 28460 : 0.34692474907718307 max of weights 2.5238912034199767
Iteration 28470 loss 0.7369408425387105 train RMSE 0.3359493332600323 Validation RMSE 28470 : 0.34511153861418276 max of weights 2.523451588326882
Iteration 28480 loss 0.7497515742283922 train RMSE 0.3418515269618014 Validation RMSE 28480 : 0.3468826547537925 max of weights 2.5281462654912947
Iteration 28490 loss 0.7705775117682302 train RMSE 0.35143902485308515 Validation RMSE 28490 : 0.3533505734102465 max of weights 2.529614126666732
Iteration 28500 loss 0.7615788040342563 train RMSE 0.3472971126335015 Validation RMSE 28500 : 0.3477077808630188 max of weights 2.5313901607362106
Iteration 28510 loss 0.7491727803025549 train RMSE 0.341584318043258 Validation RMSE 28510 : 0.3438993203339274 max of weights 2.5283753801219704
Iteration 28520 loss 0.7486246996553917 train RMSE 0.341331782375709 Validation RMSE 28520 : 0.3455776643835002 max of weights 2.530319809854184
Iteration 28530 loss 0.74689306740655 train RMSE 0.3405300828792899 Validation RMSE 28530 : 0.35057858247838003 max of weights 2.5371392859470068
Iteration 28540 loss 0.7504402625243428 train RMSE 0.34216766687669375 Validation RMSE 28540 : 0.34991076659852066 max of weights 2.53927948360026
Iteration 28550 loss 0.7440704694844905 train RMSE 0.33924420263393434 Validation RMSE 28550 : 0.3463913221437673 max of weights 2.5430298963368876
Iteration 28560 loss 0.7215544846953537 train RMSE 0.3288826682512669 Validation RMSE 28560 : 0.3516566250631882 max of weights 2.5453551442631848
Iteration 28570 loss 0.7247412891463404 train RMSE 0.330352547961031 Validation RMSE 28570 : 0.35076179692876347 max of weights 2.5474491802056836
Iteration 28580 loss 0.7348083953029972 train RMSE 0.33498522787761575 Validation RMSE 28580 : 0.35266626264548706 max of weights 2.55177215661186
Iteration 28590 loss 0.7485015778267616 train RMSE 0.3412800682968888 Validation RMSE 28590 : 0.34985155501223314 max of weights 2.549868710950283
Iteration 28600 loss 0.7712987162220285 train RMSE 0.35176441226765814 Validation RMSE 28600 : 0.3480229945313131 max of weights 2.543465207830331
Iteration 28610 loss 0.7845537011856503 train RMSE 0.35786291543260057 Validation RMSE 28610 : 0.34699930241493215 max of weights 2.5364643701935563
Iteration 28620 loss 0.7795163539955224 train RMSE 0.35553485553094366 Validation RMSE 28620 : 0.34822710046464805 max of weights 2.529070127628067
Iteration 28630 loss 0.7753415509652369 train RMSE 0.35360750026336674 Validation RMSE 28630 : 0.3493624027577063 max of weights 2.516267441765924
Iteration 28640 loss 0.769487022105709 train RMSE 0.35091589353066843 Validation RMSE 28640 : 0.34849457552874935 max of weights 2.512828603468561
Iteration 28650 loss 0.7591755769883304 train RMSE 0.3461733203949126 Validation RMSE 28650 : 0.3461052201539631 max of weights 2.5129479310806655
Iteration 28660 loss 0.755637727051886 train RMSE 0.34454755142991506 Validation RMSE 28660 : 0.34462933687282066 max of weights 2.511072520042243
Iteration 28670 loss 0.7608038455281144 train RMSE 0.3469227494091269 Validation RMSE 28670 : 0.3483660264308889 max of weights 2.5100010791710217
Iteration 28680 loss 0.7495238302657817 train RMSE 0.34173351798085544 Validation RMSE 28680 : 0.34493948196577673 max of weights 2.509826800288152
Iteration 28690 loss 0.7693853830054475 train RMSE 0.3508758169042651 Validation RMSE 28690 : 0.3501672179441925 max of weights 2.51294539959532
Iteration 28700 loss 0.7659130464209628 train RMSE 0.3492759660572177 Validation RMSE 28700 : 0.34623576260062294 max of weights 2.4998195423815575
Iteration 28710 loss 0.7617961444699624 train RMSE 0.3473798880720128 Validation RMSE 28710 : 0.34546245668875697 max of weights 2.491464649846654
Iteration 28720 loss 0.7512119691367559 train RMSE 0.3425094206210079 Validation RMSE 28720 : 0.34526716136250907 max of weights 2.4938216670113165
Iteration 28730 loss 0.7318945561271342 train RMSE 0.33361853516744316 Validation RMSE 28730 : 0.34996786726436035 max of weights 2.4932714995550542
Iteration 28740 loss 0.7438945877951386 train RMSE 0.33913921644631 Validation RMSE 28740 : 0.3454073858848252 max of weights 2.4962199636558107
Iteration 28750 loss 0.7496994739137771 train RMSE 0.34181069697683286 Validation RMSE 28750 : 0.347027959673908 max of weights 2.5026989397987363
Iteration 28760 loss 0.7523628030373095 train RMSE 0.343037920254516 Validation RMSE 28760 : 0.34878177233488544 max of weights 2.5119064948016043
Iteration 28770 loss 0.7482280404354057 train RMSE 0.34112985965234094 Validation RMSE 28770 : 0.34664814508746716 max of weights 2.5090898938554225
Iteration 28780 loss 0.7470608702558528 train RMSE 0.340586545684472 Validation RMSE 28780 : 0.352593251856818 max of weights 2.5073295306120578
Iteration 28790 loss 0.7528687495125168 train RMSE 0.3432570402602335 Validation RMSE 28790 : 0.3467344430394744 max of weights 2.50480847736332
Iteration 28800 loss 0.7803811706858473 train RMSE 0.35591595827340433 Validation RMSE 28800 : 0.3512045717572387 max of weights 2.5043118500545956
Iteration 28810 loss 0.7812638709444412 train RMSE 0.3563240229441233 Validation RMSE 28810 : 0.3517815029252258 max of weights 2.5127137876658723
Iteration 28820 loss 0.7566401277946956 train RMSE 0.3449942620824238 Validation RMSE 28820 : 0.3505250085272795 max of weights 2.5192846749077322
Iteration 28830 loss 0.7371828492825864 train RMSE 0.33603785091921 Validation RMSE 28830 : 0.35040947499453184 max of weights 2.5186974688130586
Iteration 28840 loss 0.765535279356914 train RMSE 0.3490918447338447 Validation RMSE 28840 : 0.3471944774683073 max of weights 2.520846552358761
Iteration 28850 loss 0.7519521494350614 train RMSE 0.34283701567655805 Validation RMSE 28850 : 0.3473225760277711 max of weights 2.52393301049268
Iteration 28860 loss 0.7458718973656697 train RMSE 0.34003078783929414 Validation RMSE 28860 : 0.34630341934825776 max of weights 2.524122236307734
Iteration 28870 loss 0.7594941557832859 train RMSE 0.3462938028231369 Validation RMSE 28870 : 0.34685939049424735 max of weights 2.5357077087708344
Iteration 28880 loss 0.7686332136597235 train RMSE 0.3505006661133078 Validation RMSE 28880 : 0.3482150463226076 max of weights 2.5481062699383115
Iteration 28890 loss 0.7567197595045005 train RMSE 0.3450131360429649 Validation RMSE 28890 : 0.34890853608125993 max of weights 2.55817208138404
Iteration 28900 loss 0.7622564996802192 train RMSE 0.34755615747039337 Validation RMSE 28900 : 0.34997137368548764 max of weights 2.5641647318061462
Iteration 28910 loss 0.752716888699626 train RMSE 0.3431696949074739 Validation RMSE 28910 : 0.3490801227358427 max of weights 2.570450582161258
Iteration 28920 loss 0.7410986121755853 train RMSE 0.33782588143257586 Validation RMSE 28920 : 0.34878311342374535 max of weights 2.5756683102290494
Iteration 28930 loss 0.7222717976059673 train RMSE 0.32916920613119977 Validation RMSE 28930 : 0.3502312848088999 max of weights 2.570008234749718
Iteration 28940 loss 0.7248454750734161 train RMSE 0.3303531950763416 Validation RMSE 28940 : 0.3471242446299722 max of weights 2.5735746223042533
Iteration 28950 loss 0.7030888168772532 train RMSE 0.32034457818615647 Validation RMSE 28950 : 0.3473282363197441 max of weights 2.5651378055503624
Iteration 28960 loss 0.7101788059215295 train RMSE 0.3236119288630849 Validation RMSE 28960 : 0.34966283682768873 max of weights 2.553233633128568
Iteration 28970 loss 0.7295628427822559 train RMSE 0.33253156916504967 Validation RMSE 28970 : 0.3478323222676327 max of weights 2.5428821722501427
Iteration 28980 loss 0.7419389372654217 train RMSE 0.338222828411294 Validation RMSE 28980 : 0.3513611747946305 max of weights 2.541433605682363
Iteration 28990 loss 0.7489614450054759 train RMSE 0.34146039318401095 Validation RMSE 28990 : 0.3494664885823481 max of weights 2.5394567022401895
Iteration 29000 loss 0.7641026874495317 train RMSE 0.3484263099414871 Validation RMSE 29000 : 0.35230148269286626 max of weights 2.538810921849288
Iteration 29010 loss 0.7747397261687883 train RMSE 0.3533162290097764 Validation RMSE 29010 : 0.35282421249970725 max of weights 2.5512399967343335
Iteration 29020 loss 0.7703810347709348 train RMSE 0.35131325492757226 Validation RMSE 29020 : 0.35196277915243407 max of weights 2.564856376016316
Iteration 29030 loss 0.7388377756264077 train RMSE 0.33679320225707243 Validation RMSE 29030 : 0.3513680912457033 max of weights 2.5659019968873564
Iteration 29040 loss 0.7268548812547264 train RMSE 0.33127157534555834 Validation RMSE 29040 : 0.34926283865645935 max of weights 2.565940913414385
Iteration 29050 loss 0.749893039569904 train RMSE 0.34186456693833406 Validation RMSE 29050 : 0.3554172239852614 max of weights 2.560971945705788
Iteration 29060 loss 0.7754632301658841 train RMSE 0.3536354447367638 Validation RMSE 29060 : 0.3519211269424725 max of weights 2.564354216736849
Iteration 29070 loss 0.7758518379834491 train RMSE 0.3538131497717402 Validation RMSE 29070 : 0.35180376052520757 max of weights 2.5674533406360487
Iteration 29080 loss 0.7682251282479919 train RMSE 0.35030141290771166 Validation RMSE 29080 : 0.35016832824261607 max of weights 2.57534489855016
Iteration 29090 loss 0.763123520702878 train RMSE 0.3479560753295955 Validation RMSE 29090 : 0.3504458743105141 max of weights 2.578156703418533
Iteration 29100 loss 0.7444512684455588 train RMSE 0.33935857842852896 Validation RMSE 29100 : 0.35060195319884396 max of weights 2.578501463738407
Iteration 29110 loss 0.7454386174311566 train RMSE 0.3398062671203983 Validation RMSE 29110 : 0.35361588464516913 max of weights 2.5870159307822727
Iteration 29120 loss 0.7511360949152509 train RMSE 0.3424290686223718 Validation RMSE 29120 : 0.34974542187866764 max of weights 2.5919970066855083
Iteration 29130 loss 0.7587153241653674 train RMSE 0.34592715453314116 Validation RMSE 29130 : 0.3500085566144156 max of weights 2.590684855798095
Iteration 29140 loss 0.7576220159157673 train RMSE 0.345429875765508 Validation RMSE 29140 : 0.3524378866617793 max of weights 2.580764377140239
Iteration 29150 loss 0.7557692534795634 train RMSE 0.344576793475528 Validation RMSE 29150 : 0.34876861667812065 max of weights 2.5781065994248165
Iteration 29160 loss 0.7338202712724357 train RMSE 0.3344707429786477 Validation RMSE 29160 : 0.3480656260352264 max of weights 2.583071081705544
Iteration 29170 loss 0.7566117674318191 train RMSE 0.3449556058295284 Validation RMSE 29170 : 0.34956405411923075 max of weights 2.5753712841000547
Iteration 29180 loss 0.7665566999751865 train RMSE 0.34953011239248194 Validation RMSE 29180 : 0.34929395642226313 max of weights 2.5754145353754505
Iteration 29190 loss 0.7573572455340878 train RMSE 0.3452999098040233 Validation RMSE 29190 : 0.3505812572564593 max of weights 2.5796391205540496
Iteration 29200 loss 0.7573920157203139 train RMSE 0.34531587142106357 Validation RMSE 29200 : 0.3511468315243056 max of weights 2.578203280756842
Iteration 29210 loss 0.7624709410384332 train RMSE 0.3476467157378723 Validation RMSE 29210 : 0.3467610595929742 max of weights 2.586501755076838
Iteration 29220 loss 0.7592894998743478 train RMSE 0.34618073418654727 Validation RMSE 29220 : 0.34863597067089597 max of weights 2.5889012648667413
Iteration 29230 loss 0.7402125353602158 train RMSE 0.33740302807484784 Validation RMSE 29230 : 0.34763404848771606 max of weights 2.5827351217320076
Iteration 29240 loss 0.7388968499907195 train RMSE 0.33679122103045617 Validation RMSE 29240 : 0.3488230983537056 max of weights 2.57808955110498
Iteration 29250 loss 0.7329612541575886 train RMSE 0.33405796519726466 Validation RMSE 29250 : 0.3466904548713191 max of weights 2.5753240531961588
Iteration 29260 loss 0.7382583344612982 train RMSE 0.3364989455201809 Validation RMSE 29260 : 0.3469556922203878 max of weights 2.574956840723484
Iteration 29270 loss 0.7441653063001948 train RMSE 0.3392137503119211 Validation RMSE 29270 : 0.3470837095105604 max of weights 2.575076454811865
Iteration 29280 loss 0.7523427100816578 train RMSE 0.3429707551485507 Validation RMSE 29280 : 0.34713600061190925 max of weights 2.5764304385140755
Iteration 29290 loss 0.7617673113899397 train RMSE 0.3472998995367041 Validation RMSE 29290 : 0.3497281852371124 max of weights 2.5779984522645965
Iteration 29300 loss 0.7772013272773342 train RMSE 0.3543968417722739 Validation RMSE 29300 : 0.35266797928320703 max of weights 2.5806323211777067
Iteration 29310 loss 0.7585861893880019 train RMSE 0.34583167026207573 Validation RMSE 29310 : 0.3501790109668045 max of weights 2.5830840925092504
Iteration 29320 loss 0.7546188599459472 train RMSE 0.3440067390202352 Validation RMSE 29320 : 0.35098425901092345 max of weights 2.585935350089422
Iteration 29330 loss 0.7527420331014106 train RMSE 0.34314071775546906 Validation RMSE 29330 : 0.3498558075260487 max of weights 2.5896726014690357
Iteration 29340 loss 0.748645161857005 train RMSE 0.3412584025559845 Validation RMSE 29340 : 0.3502924791121839 max of weights 2.5989516945459687
Iteration 29350 loss 0.7175516341270243 train RMSE 0.32695467784637056 Validation RMSE 29350 : 0.34782616581470105 max of weights 2.6008571286514095
Iteration 29360 loss 0.7184464783663593 train RMSE 0.3273640941540638 Validation RMSE 29360 : 0.35056119978760725 max of weights 2.595813292852305
Iteration 29370 loss 0.7386817388317357 train RMSE 0.3366728277946966 Validation RMSE 29370 : 0.35683989094869256 max of weights 2.595363858196328
Iteration 29380 loss 0.7361427354296046 train RMSE 0.3355050558502933 Validation RMSE 29380 : 0.35034004301039506 max of weights 2.597984303527614
Iteration 29390 loss 0.7315217869921414 train RMSE 0.33337578750618646 Validation RMSE 29390 : 0.35142185429070466 max of weights 2.5997697792650616
Iteration 29400 loss 0.7289233558437642 train RMSE 0.332179195622334 Validation RMSE 29400 : 0.3493679128241006 max of weights 2.6002494565076044
Iteration 29410 loss 0.7260528376951836 train RMSE 0.33085999379685893 Validation RMSE 29410 : 0.34890306036050217 max of weights 2.6072958571601443
Iteration 29420 loss 0.7282386664192971 train RMSE 0.33186900828318777 Validation RMSE 29420 : 0.34879938953208817 max of weights 2.611376387109866
Iteration 29430 loss 0.7337906231049138 train RMSE 0.3344249201269898 Validation RMSE 29430 : 0.35045298638278066 max of weights 2.61386705541544
Iteration 29440 loss 0.7282247539792813 train RMSE 0.3318586773715382 Validation RMSE 29440 : 0.34971638401703314 max of weights 2.6252579468581816
Iteration 29450 loss 0.734380443711767 train RMSE 0.3346812740907046 Validation RMSE 29450 : 0.3487121580417349 max of weights 2.632747905986453
Iteration 29460 loss 0.7567933420796572 train RMSE 0.3449885974541523 Validation RMSE 29460 : 0.3494238489652656 max of weights 2.635451870964092
Iteration 29470 loss 0.7427479748603281 train RMSE 0.338525948928867 Validation RMSE 29470 : 0.3493269852674977 max of weights 2.631020317617385
Iteration 29480 loss 0.7435014445014372 train RMSE 0.33887270034114686 Validation RMSE 29480 : 0.34866549241314454 max of weights 2.6338492438913996
Iteration 29490 loss 0.76440308472917 train RMSE 0.348488606197185 Validation RMSE 29490 : 0.34986961777702846 max of weights 2.6377170347938095
Iteration 29500 loss 0.7751506004969136 train RMSE 0.35342577944882647 Validation RMSE 29500 : 0.3538491015993912 max of weights 2.6339343013708367
Iteration 29510 loss 0.7761324511074587 train RMSE 0.3538837034208265 Validation RMSE 29510 : 0.35169842966196635 max of weights 2.630122930697209
Iteration 29520 loss 0.7892698375938673 train RMSE 0.3599308247685288 Validation RMSE 29520 : 0.35128235515727724 max of weights 2.6241442516003097
Iteration 29530 loss 0.7807466033240391 train RMSE 0.35600908773344 Validation RMSE 29530 : 0.3494738849270261 max of weights 2.6200455987351243
Iteration 29540 loss 0.7615907366215482 train RMSE 0.3471919532724357 Validation RMSE 29540 : 0.34819884338256807 max of weights 2.6198250376535634
Iteration 29550 loss 0.7675243503939857 train RMSE 0.349927630972922 Validation RMSE 29550 : 0.3488597559291002 max of weights 2.624970545695835
Iteration 29560 loss 0.7892212590417483 train RMSE 0.359911644781934 Validation RMSE 29560 : 0.3569011737158718 max of weights 2.6257078942025673
Iteration 29570 loss 0.7806134873459402 train RMSE 0.3559480115493218 Validation RMSE 29570 : 0.34960279523403753 max of weights 2.6231824718237022
Iteration 29580 loss 0.7660438197058715 train RMSE 0.34923672934032396 Validation RMSE 29580 : 0.35120040751576825 max of weights 2.6210302753800647
Iteration 29590 loss 0.7648681847737411 train RMSE 0.3486950846835628 Validation RMSE 29590 : 0.34972842485596284 max of weights 2.626401591796557
Iteration 29600 loss 0.7883848277607751 train RMSE 0.359519583169653 Validation RMSE 29600 : 0.35081917306657595 max of weights 2.6318132899061326
Iteration 29610 loss 0.7803325345937623 train RMSE 0.35581002177032833 Validation RMSE 29610 : 0.35046410048284166 max of weights 2.6301601468660247
Iteration 29620 loss 0.7564242131135336 train RMSE 0.3448026321661151 Validation RMSE 29620 : 0.3488885401077983 max of weights 2.6253807825664524
Iteration 29630 loss 0.765391798830904 train RMSE 0.3489249247290135 Validation RMSE 29630 : 0.3486269539633639 max of weights 2.6228859594968275
Iteration 29640 loss 0.7815056200646945 train RMSE 0.3563312022832374 Validation RMSE 29640 : 0.3570768135715568 max of weights 2.626411534864637
Iteration 29650 loss 0.7723494759679719 train RMSE 0.35211316431171685 Validation RMSE 29650 : 0.35735901804144654 max of weights 2.6274417809194626
Iteration 29660 loss 0.7690105656537984 train RMSE 0.3505847207423024 Validation RMSE 29660 : 0.3490139271135524 max of weights 2.6264857195220874
Iteration 29670 loss 0.7752008160503607 train RMSE 0.35344136970058937 Validation RMSE 29670 : 0.3531267855105094 max of weights 2.623617313575806
Iteration 29680 loss 0.7446364829075569 train RMSE 0.33937567545120195 Validation RMSE 29680 : 0.34656851213562745 max of weights 2.617925084980061
Iteration 29690 loss 0.7418673568343715 train RMSE 0.3380987692534724 Validation RMSE 29690 : 0.34604539312024185 max of weights 2.6154463394163496
Iteration 29700 loss 0.7420024291922196 train RMSE 0.33816918248783767 Validation RMSE 29700 : 0.3439611354515412 max of weights 2.615235591616217
Iteration 29710 loss 0.7437707419385807 train RMSE 0.3389867614214962 Validation RMSE 29710 : 0.3456535274865685 max of weights 2.614079326195466
Iteration 29720 loss 0.7373023692236196 train RMSE 0.3360040424157795 Validation RMSE 29720 : 0.34430596973055566 max of weights 2.6087639090208894
Iteration 29730 loss 0.7525747413206973 train RMSE 0.34302504664333955 Validation RMSE 29730 : 0.34679108354438687 max of weights 2.6074987455413825
Iteration 29740 loss 0.7501206245956525 train RMSE 0.34190044604233827 Validation RMSE 29740 : 0.34648742516704084 max of weights 2.6016924689322636
Iteration 29750 loss 0.7411089077039924 train RMSE 0.3377554195384124 Validation RMSE 29750 : 0.34543358278956005 max of weights 2.5974668416871616
Iteration 29760 loss 0.745069014043622 train RMSE 0.33957398939891115 Validation RMSE 29760 : 0.3453445487064986 max of weights 2.602719140982735
Iteration 29770 loss 0.7647391758239891 train RMSE 0.34862825162189387 Validation RMSE 29770 : 0.34921949692574833 max of weights 2.6055432332522956
Iteration 29780 loss 0.7502359039371367 train RMSE 0.34194937969191064 Validation RMSE 29780 : 0.3476216403928391 max of weights 2.6076490569750925
Iteration 29790 loss 0.7524910556956097 train RMSE 0.3429888139098296 Validation RMSE 29790 : 0.3474660353260195 max of weights 2.61366158416321
Iteration 29800 loss 0.7531411457611252 train RMSE 0.3432865337085603 Validation RMSE 29800 : 0.3481815255347096 max of weights 2.619413405768321
Iteration 29810 loss 0.7436815525853605 train RMSE 0.33893144047929186 Validation RMSE 29810 : 0.3484094730239363 max of weights 2.626393930601705
Iteration 29820 loss 0.7381579032323871 train RMSE 0.3363867699176941 Validation RMSE 29820 : 0.3460935219032852 max of weights 2.625719216107022
Iteration 29830 loss 0.7366363658098225 train RMSE 0.3356832990161529 Validation RMSE 29830 : 0.3439555862434605 max of weights 2.6286747697003485
Iteration 29840 loss 0.7285638664630395 train RMSE 0.3319642803137817 Validation RMSE 29840 : 0.3459242898099339 max of weights 2.634487798913797
Iteration 29850 loss 0.7295375104589897 train RMSE 0.3324108084187426 Validation RMSE 29850 : 0.34496627268562174 max of weights 2.6326122796289257
Iteration 29860 loss 0.7543463452647362 train RMSE 0.34382344127882564 Validation RMSE 29860 : 0.3456864052001268 max of weights 2.6329700704091055
Iteration 29870 loss 0.7516463599050865 train RMSE 0.3425835755830496 Validation RMSE 29870 : 0.34285558581346803 max of weights 2.6360263609020014
Iteration 29880 loss 0.7394922042873041 train RMSE 0.3369948280547666 Validation RMSE 29880 : 0.3425745064689377 max of weights 2.6355331576023304
Iteration 29890 loss 0.7517404125735255 train RMSE 0.3426330512249666 Validation RMSE 29890 : 0.3469577818770692 max of weights 2.6307190791265467
Iteration 29900 loss 0.7455608633491541 train RMSE 0.3397851604283537 Validation RMSE 29900 : 0.3464635426346905 max of weights 2.6271919325066286
Iteration 29910 loss 0.7384957518150221 train RMSE 0.3365280245009926 Validation RMSE 29910 : 0.346198109116818 max of weights 2.62479179066173
Iteration 29920 loss 0.7373200452384164 train RMSE 0.3359913384802746 Validation RMSE 29920 : 0.3456082262031379 max of weights 2.6209230032870585
Iteration 29930 loss 0.7567416545446927 train RMSE 0.3449369026934576 Validation RMSE 29930 : 0.3488891334414924 max of weights 2.617553002143959
Iteration 29940 loss 0.7712984006694702 train RMSE 0.35163795217794913 Validation RMSE 29940 : 0.3533533800855724 max of weights 2.612789953037378
Iteration 29950 loss 0.7560569913073378 train RMSE 0.34462338851078594 Validation RMSE 29950 : 0.34515422961741377 max of weights 2.603942062465496
Iteration 29960 loss 0.7483053642809221 train RMSE 0.34105406026645624 Validation RMSE 29960 : 0.3436929461288998 max of weights 2.5945161499350844
Iteration 29970 loss 0.7461222249200562 train RMSE 0.340049034322681 Validation RMSE 29970 : 0.34576321681842637 max of weights 2.5898843846424326
Iteration 29980 loss 0.7402355049007247 train RMSE 0.3373361405060827 Validation RMSE 29980 : 0.3505771154157943 max of weights 2.5901908043078685
Iteration 29990 loss 0.7517192246752246 train RMSE 0.3426264746053951 Validation RMSE 29990 : 0.348872478677014
Neural test RMSE: 0.3524911263533894
